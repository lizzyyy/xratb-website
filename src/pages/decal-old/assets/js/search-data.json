{"0": {
    "doc": "How to Update Decal site",
    "title": "How to Update Decal site",
    "content": "Only a few people have access to update the website now as the repo is hosted on the Extended Reality @ Berkeley GitHub organization. Let me know if you need to be added to the organization to update the website. | After previewing your site locally to make sure everything looks good, you will need to build the site by running JEKYLL_ENV=production bundle exec jekyll b. This will build to the directory _site. | Copy all the content inside _site (don’t copy the _site folder itself) into the decal folder in the website GitHub repository. Commit &amp; push to the website repo. | To modify the live website, you will also have to pull the changes from within OCF, our hosting platform. Instructions to do that are on the website repo. | . ",
    "url": "/decal/README/",
    "relUrl": "/README/"
  },"1": {
    "doc": "How to Update Decal site",
    "title": "Building and previewing your site locally",
    "content": "https://just-the-docs.github.io/just-the-docs-template/ . Assuming [Jekyll] and [Bundler] are installed on your computer: . | Change your working directory to the root directory of your site. | Run bundle install. | Run bundle exec jekyll serve to build your site and preview it at localhost:4000. The built site is stored in the directory _site. | . Template Credits: Just the Class . Just the Class is a GitHub Pages template developed for the purpose of quickly deploying course websites. In addition to serving plain web pages and files, it provides a boilerplate for: . | announcements, | a course calendar, | a staff page, | and a weekly schedule. | . Just the Class is a template that extends the popular Just the Docs theme, which provides a robust and thoroughly-tested foundation for your website. Just the Docs include features such as: . | automatic navigation structure, | instant, full-text search and page indexing, | and a set of UI components and authoring utilities. | . ",
    "url": "/decal/README/#building-and-previewing-your-site-locally",
    "relUrl": "/README/#building-and-previewing-your-site-locally"
  },"2": {
    "doc": "Announcements",
    "title": "Announcements",
    "content": "Announcements are stored in the _announcements directory and rendered according to the layout file, _layouts/announcement.html. ",
    "url": "/decal/announcements/",
    "relUrl": "/announcements/"
  },"3": {
    "doc": "Announcements",
    "title": "Week 1 Announcement",
    "content": "Apr 8 &middot; 0 min read . | Create a new repository based on Just the Class. | Configure a publishing source for GitHub Pages. Your course website is now live! | Update _config.yml with your course information. | Edit and create .md Markdown files to add your content. | . ",
    "url": "/decal/announcements/",
    "relUrl": "/announcements/"
  },"4": {
    "doc": "Announcements",
    "title": "Week 0 Announcement",
    "content": "Apr 1 &middot; 0 min read Hello world! . ",
    "url": "/decal/announcements/",
    "relUrl": "/announcements/"
  },"5": {
    "doc": "Calendar",
    "title": "Calendar",
    "content": " ",
    "url": "/decal/calendar/",
    "relUrl": "/calendar/"
  },"6": {
    "doc": "Calendar",
    "title": "Introduction to Java",
    "content": "Sep 28 Java &amp; Git 1.1 Sep 29 SectionIntro to Java Solution Sep 30 Variables &amp; Objects 1.2, 2.1 Oct 1 Lab Intro to Java Oct 2 Tracing, IntLists, &amp; Recursion 2.1 HW 1 due ",
    "url": "/decal/calendar/#introduction-to-java",
    "relUrl": "/calendar/#introduction-to-java"
  },"7": {
    "doc": "Calendar",
    "title": "Basic Data Structures",
    "content": "Oct 5 Linked Lists &amp; Encapsulation 3.1, 2.2, 2.3 Oct 6 SectionLinked Lists Solution Oct 7 Resizing Arrays 2.4, 2.5 Oct 8 Lab Resizing Arrays Oct 9 Runtime Analysis 8.1, 8.2, 8.3, 8.4 HW 2 due ",
    "url": "/decal/calendar/#basic-data-structures",
    "relUrl": "/calendar/#basic-data-structures"
  },"8": {
    "doc": "Extra Resources",
    "title": "Extra Resources",
    "content": ". | Photon Multiplayer Networking . | Write-up | Would recommend looking into Netcode for GameObjects if trying to do multiplayer now. This is the official Unity supported solution for multiplayer and networking. | . | 3D Modeling in Maya (Credits to our friends over at UCBUGG) . | UCBUGG Modeling Lab | Cheat Sheet | . | . ",
    "url": "/decal/extra-resources/",
    "relUrl": "/extra-resources/"
  },"9": {
    "doc": "Homework 1: The Rube Goldberg Ball Machine",
    "title": "Homework 1: The Rube Goldberg Ball Machine",
    "content": " ",
    "url": "/decal/homework/hw1/",
    "relUrl": "/homework/hw1/"
  },"10": {
    "doc": "Homework 1: The Rube Goldberg Ball Machine",
    "title": "Table of contents",
    "content": ". | Getting Started | Gate 1 | Gates 2-4 | Gate 5 | Gate 6 | Gate 7-9 | Submission and Grading | . Your first assignment is to create a Rube Goldberg Ball machine. This will be mainly an exercise in getting familiar with the controls and tools that Unity provides, so for those with prior Unity experience, a lot of it will be review. Just a reminder that the Unity Version we want to use is 2021.3.*. This is the version we tested the homework on; we cannot guarantee it works for other versions of Unity. First download Unity Hub, then you can download specific versions of Unity here: https://unity3d.com/get-unity/download/archive. Click the “Unity Hub” option. ",
    "url": "/decal/homework/hw1/#table-of-contents",
    "relUrl": "/homework/hw1/#table-of-contents"
  },"11": {
    "doc": "Homework 1: The Rube Goldberg Ball Machine",
    "title": "Getting Started",
    "content": "Start off by downloading the skeleton asset package here, and then open up a new Unity project. Import the downloaded package into your project through Assets &gt; Import Package &gt; Custom Package. You’ll see some folders that contain the assets needed for this assignment. Double-click the HW1 scene to get started. As a reminder, you can navigate the scene view by holding down the right mouse button and using WASD + QE to fly around. Your starting scene should look like this: . Note in particular the white ball, the 9 gates, and the green square. You may not move any of the objects already in the scene. Try pressing the play button at the top of the editor. Your ball should roll off the platform and fall indefinitely. Your task for this assignment is to add and modify the scene such that when you press the play button, the ball rolls through all 9 gates and lands on the green square. As long as you follow the rules above, you may skip the next two sections and instead complete the assignment in any way you wish. ",
    "url": "/decal/homework/hw1/#getting-started",
    "relUrl": "/homework/hw1/#getting-started"
  },"12": {
    "doc": "Homework 1: The Rube Goldberg Ball Machine",
    "title": "Gate 1",
    "content": "Let’s start by connecting the starting platform with the first gate. Right click an empty spot within the hierarchy view and select 3D Object &gt; Cube to create a cube. Select it, then within the Inspector view modify its transform component so that it forms a ramp from the first platform to the gate. For convenience, here are the transform values we used: . Your scene should then look like this: . Now click play. Our ball now makes it through the first gate! . ",
    "url": "/decal/homework/hw1/#gate-1",
    "relUrl": "/homework/hw1/#gate-1"
  },"13": {
    "doc": "Homework 1: The Rube Goldberg Ball Machine",
    "title": "Gates 2-4",
    "content": "Create another cube. Transform and place it so it acts as another ramp: the ball should will roll off the first gate, land on the ramp and roll into the second gate. It should look like this: . We suggest transforming the cube using the position (w), rotate (e), and scale (r) tools, instead of directly modifying the transform component values. These tools can also be selected in the top left of the screen. After doing this, take a look at the whole wall. You can see that the ball is supposed to roll in a zig-zag platform that moves it through the three gates and onto the next platform. This will require 5 more ramps like the one you just created. For the remaining 5 ramps, try using the duplicate tool instead of re-transforming a new cube each time. Select the ramp you just made and use ctrl + d to duplicate it, then modify it from there. The result should look like this: . Tip: you can duplicate multiple objects at once by holding shift while selecting them. ",
    "url": "/decal/homework/hw1/#gates-2-4",
    "relUrl": "/homework/hw1/#gates-2-4"
  },"14": {
    "doc": "Homework 1: The Rube Goldberg Ball Machine",
    "title": "Gate 5",
    "content": "After completing the wall, you’ll notice the ball is supposed to get onto a spinning platform to make it to the other side. However, the spinner is flat - there’s nothing to catch the ball with as it spins. We’ll attach railings to the spinner to remedy this. Before this, however, we need understand parenting. Parenting is where we define an object’s transform to be relative to that of a different object in the scene. For instance, the cubes we’ve been placing in the scene thus far have no parents. Their transforms are relative to the world space, which never moves. But if we were to parent one of these cubes under another, the child’s transform would then be relative to its parent instead. More importantly, if the parent moves, the child moves with it (since it must maintain its relative positioning to its parent). Parenting is an essential tool for both creating complex structures and keeping your project organized. You can do it by dragging one object in the Hierarchy tab onto another. Place cubes as the picture below shows around the spinner to catch the ball during the spin. Make sure these cubes are parented under the Spinner object in the hierarchy. You’ll want to make the walls thick to make sure the ball doesn’t glitch through the walls when the spinner moves. Warning: Unity’s default physics are non-deterministic and somewhat glitchy. You may need to finesse parts of the scene to make things work, such as making the walls thicker, adjusting the speed of the spinner (check out the script attached to it), or adding more guide-rails. Tip: it might be hard to see how far the spinner extends, as it clips into the other blocks on the left. To remedy this, select the blocks obstructing your view and click the checkmark near the top of the Inspector view. This will disable them temporarily and allow you to work better. Just remember to enable them again when you’re done! . You might notice that while testing, the physics interaction between your ball and the railings you place don’t look right. To help remedy this, for each of your 4 railings, go to the inspector panel and add a Rigidbody component. This will tell Unity to treat them as proper moving physical objects. You’ll also want to uncheck gravity so they don’t drop when you start the game, and check Is Kinematic, which tells Unity that you only want to move these objects via script or animation (which we do). ",
    "url": "/decal/homework/hw1/#gate-5",
    "relUrl": "/homework/hw1/#gate-5"
  },"15": {
    "doc": "Homework 1: The Rube Goldberg Ball Machine",
    "title": "Gate 6",
    "content": "For the next section, we want to complete another spinner to push the ball into the railings. We could duplicate we made on the original spinner, but we’ll do it a different way: with prefabs. Prefabs are Unity’s way of storing GameObjects for future use. With a prefab, you can take a complex object you’ve created and store it outside of the scene itself. This lets you easily bring it into the same scene, a different scene, or a different project entirely. Prefabs also give a couple of useful utilities, which we will now explore. In your Project tab, go into the prefabs folder and look for an object called Spinner. The two spinners in our scene are instances of this prefab. Now select the Spinner you just modified in your hierarchy. Notice the three buttons near the top next to the word “Prefab”: Select, Revert, and Apply. These buttons do the following: . | “Select” will dig into your Project tab and select the prefab your object is using, just like the image above. This can save a lot of time in large projects. | Overrides &gt; “Revert All” will change your selected instance of a prefab you’ve selected to a clone of the prefab itself. Useful for undoing your work. | Overrides &gt; “Apply All” will save your selected instance to the prefab in the Project view. The opposite of reverting. | “Open” will open the prefab editor to allow for more fine grained changes. | . For our purposes, since we’ve added railings to an instance of the Spinner prefab, we want to apply those changes to the prefab itself. Click “Apply” to do so. Notice that when you did so, not only did the prefab in the Project view change, but also the second Spinner in the scene - thus saving you some work. If you test it now, your ball should make it onto the railings and through the 6th gate. ",
    "url": "/decal/homework/hw1/#gate-6",
    "relUrl": "/homework/hw1/#gate-6"
  },"16": {
    "doc": "Homework 1: The Rube Goldberg Ball Machine",
    "title": "Gate 7-9",
    "content": "This marks the end of the guided section! There are a couple more gates before the goal - put in whatever you want to complete the Rube Goldberg machine! . A tip: Don’t be scared to add additional railings or walls to the course. Unity’s physics aren’t perfect and small changes to your ramps can lead to different behaviors down the line, so it’s better to be safe than sorry. ",
    "url": "/decal/homework/hw1/#gate-7-9",
    "relUrl": "/homework/hw1/#gate-7-9"
  },"17": {
    "doc": "Homework 1: The Rube Goldberg Ball Machine",
    "title": "Submission and Grading",
    "content": "For this and all future homework (except homework 2), submissions will be done through WebGL builds. If you don’t have the WebGL module, go to the Installs tab in the Unity Hub. On the upper right of the version, click Add Modules. Here, add “WebGL Build Support”. Next, we need to disable compression because simmer.io can only process uncompressed builds. To do this, File &gt; Build Settings &gt; Player Settings (bottom right of build menu) &gt; Publishing Settings &gt; Disable “Compression Format” (Video) . To create a build of your project, go to File &gt; Build Settings. Make sure the scene is selected, then click Build to create a WebGL build. You can submit your build on bCourses with a simmer.io link. For grading, we will test your simmer.io project. We will run it up to 5 times - if the ball goes through all 9 gates and hits the green square to get the “You Win” message, you’ll receive full points. Otherwise we will give partial credit for effort made. ",
    "url": "/decal/homework/hw1/#submission-and-grading",
    "relUrl": "/homework/hw1/#submission-and-grading"
  },"18": {
    "doc": "Homework 2: Music Visualizer",
    "title": "Homework 2: Music Visualizer",
    "content": " ",
    "url": "/decal/homework/hw2/",
    "relUrl": "/homework/hw2/"
  },"19": {
    "doc": "Homework 2: Music Visualizer",
    "title": "Table of contents",
    "content": ". | Introducing Spectrum Theory | Extracting Spectrum Data | Visualizing Spectrum Data | Introducing Frequency Bands | 8 Bin Separation | Visualizing 8 Bins | Add Your Own Flair | Submission and Grading | . Your second assignment is to create your very own music visualizer! It will look something like this: . This assignment will be a review of some of the Unity editor tools you have practiced in HW1, but more importantly, an introduction on using C# scripts to manipulate gameobjects. First off, download the skeleton asset package here and import it into a new project. Create a new scene called HW2 to work in. In the meantime, take a look at these amazing music visualizer examples created with Unity by other people. This homework only goes over the basics, but you could take it to another level by adding your own flair. Links: 1, 2, 3, 4, 5. ",
    "url": "/decal/homework/hw2/#table-of-contents",
    "relUrl": "/homework/hw2/#table-of-contents"
  },"20": {
    "doc": "Homework 2: Music Visualizer",
    "title": "Introducing Spectrum Theory",
    "content": "Every sound that enters your ear is actually a sum of different frequencies. Pure waveforms from various sources combine together into a single complex waveform. This complex waveform is then processed by your brain to create music, conversation, and everything else you hear. The Fast Fourier Transform algorithm is the exact reverse - it takes a complex waveform and decomposes it into its base frequencies. Take the picture below as an example, which looks at a simple song from various perspectives. What you physically hear is the result, which is the sum of the pure bass, kick, synth, and harmonics waveforms. Performing FFT on the result returns an array of weights, which represent how much of each base frequency is being used in the result. You’ll notice there are 4 peaks, one for each of the pure waveforms. The leftmost peak represents the lowest frequency (the bass), and is the tallest because the bass has the greatest amplitude out of the four waveforms. You might have noticed the FFT graph looks a little bit like a music visualization - and in fact it is. Music visualizations are nothing more than visual representations of the FFT for a song and how it changes over time. In our case, we will be representing the values of the FFT with the heights of various cubes. If you’d like to learn more, EE16A covers this subject in much more detail. ",
    "url": "/decal/homework/hw2/#introducing-spectrum-theory",
    "relUrl": "/homework/hw2/#introducing-spectrum-theory"
  },"21": {
    "doc": "Homework 2: Music Visualizer",
    "title": "Extracting Spectrum Data",
    "content": "Let’s start off the homework by creating a script that allows you to extract spectrum data from any audio source. We will start by creating an empty gameobject named “SpectrumAnalyzer” and a C# script named “SpectrumAnalyzer”. Add both an Audio Source and the script to the gameobject. Then open the script in the text editor of your choice, which will likely be Visual Studio or Monodevelop. As a side tangent, you may change your script editor by going to Edit &gt; Preferences &gt; External Tools. Start off by adding two variables to the script, above the Start() function. AudioSource audioSource; public static float[] samples = new float[512]; . As you remember from roll-a-ball, the Start() function is called once, when the script is enabled. This makes it a good place to instantiate and/or initialize variables. We’ll initialize our audio source component here. Additionally, stub in a new function called GetSpectrumAudioSource(). void Start () { audioSource = GetComponent&lt;AudioSource&gt;(); } void GetSpectrumAudioSource() { } . We’ll use this function to analyze the spectrum data from audioSource and save it in variable samples every frame. Fortunately, Unity has a built in function that does this for us, GetSpectrumData. We’ll use channel 0 since we’re only playing one thing at a time, and use Blackman for our spectrum analysis window due to its overall robust behaviour. void GetSpectrumAudioSource() { audioSource.GetSpectrumData(samples, 0, FFTWindow.Blackman); } . Since we’ll want to update our spectrum samples every frame, put GetSpectrumAudioSource() in the Update function. void Update () { GetSpectrumAudioSource(); } . Save your work and switch back to Unity. Select your SpectrumAnalyzer gameobject and set the AudioClip to whichever audio file you want to visualize. We have provided a sample audiofile in the Audio folder, in case you don’t have any. Here are some links to music if you’d like to download some: 1, 2, 3, 4. ",
    "url": "/decal/homework/hw2/#extracting-spectrum-data",
    "relUrl": "/homework/hw2/#extracting-spectrum-data"
  },"22": {
    "doc": "Homework 2: Music Visualizer",
    "title": "Visualizing Spectrum Data",
    "content": "Next, we’re going to visualize each of the 512 spectrum samples using cubes. In Assets &gt; Scripts, find and open the script “Instantiate512cubes”. This script starts off by spawning 512 cubes in a circle such that they all face the center. It then takes the sample data every frame and represents it using the heights of the cubes. The effect will be something like this: . There are two sections of this script for you to complete on your own. Read the comments for more details on what each section does and hints on how to do it. When you’re done, save your work and switch back to Unity. Create a gameobject called “InstantiateCubes” and attach the script to this object. You’ll notice the Cube Prefab isn’t assigned - you can find a prefab for it in Assets &gt; Prefabs. Press play! You’ll notice that the camera location isn’t great. Change the position and rotation so that the camera is showing the scene correctly. Remember that while you can edit anything while the game is playing by switching back to the scene view, none of it will save once the game stops playing. To work around this, move your camera to where you want it, then click the gear icon in the transform component’s top right to copy component. Then stop play mode (which will move your camera back), click the gear, and paste the component values you just copied. Congrats! You now have a working music visualizer. ",
    "url": "/decal/homework/hw2/#visualizing-spectrum-data",
    "relUrl": "/homework/hw2/#visualizing-spectrum-data"
  },"23": {
    "doc": "Homework 2: Music Visualizer",
    "title": "Introducing Frequency Bands",
    "content": "After testing out your visualizer, you might have noticed that most of the movement happens in the first couple cubes (the lower frequencies) while most of the other cubes (higher frequencies) barely move. The reason for this is that the lower frequency sounds are much closer together, while the higher frequencies are much more spread out. This means all the low frequencies get shoved into a couple of cubes, while the high frequencies are spread out across a whole bunch of them. We’re now going to fix this issue by collating the 512 samples into just 8 bins, which will represent different frequency bands. Audio specialists have grouped the range of human detectable frequencies into 7 broad regions. They are as follows: . | Sub Bass: 20 - 60 Hz | Bass: 60 - 250 Hz | Low Midrange: 250 - 500 Hz | Midrange: 500 - 2k Hz | Upper Midrange: 2k - 4k Hz | Presence: 4k - 6k Hz | Brilliance: 6k- 20k Hz | . Notice how the regions roughly increase in size as they increase in frequency. Inspired by this, we’ll create 8 bins where higher frequency bins absorb more samples. We have a total range of 20k - 20 = 19980 Hz to cover, and with 512 samples each sample covers 19980 / 512 = 39 Hz. We’ll define the bins as follows: . | bin index | # samples used | hertz range | range size | . | 0 | 2 | 20 - 98 | 78 | . | 1 | 4 | 99 - 225 | 156 | . | 2 | 8 | 256 - 568 | 312 | . | 3 | 16 | 569 - 1193 | 624 | . | 4 | 32 | 1194 - 2442 | 1248 | . | 5 | 64 | 2443 - 4939 | 2496 | . | 6 | 128 | 4940 - 9932 | 4992 | . | 7 | 258* | 9933 - 19995 | 10062 | . *We stick the two last samples into the final bin, hence why it’s 258 and not 256. ",
    "url": "/decal/homework/hw2/#introducing-frequency-bands",
    "relUrl": "/homework/hw2/#introducing-frequency-bands"
  },"24": {
    "doc": "Homework 2: Music Visualizer",
    "title": "8 Bin Separation",
    "content": "Switch to editing SpectrumAnalyzer. Add a variable for array freqBand, which will contain the collated sample data bins. Also add a function called MakeFrequencyBands(). As filling out this function is rather tedious, we’ve done it for you. public static float[] freqBand = new float[8]; void MakeFrequencyBands() { int count = 0; // Iterate through the 8 bins. for (int i = 0; i &lt; 8; i++) { float average = 0; int sampleCount = (int)Mathf.Pow (2, i + 1); // Adding the remaining two samples into the last bin. if (i == 7) { sampleCount += 2; } // Go through the number of samples for each bin, add the data to the average for (int j = 0; j &lt; sampleCount; j++) { average += samples [count]; count++; } // Divide to create the average, and scale it appropriately. average /= count; freqBand[i] = (i+1) * 100 * average; } } . Add a call to MakeFrequencyBands() to Update() so it gets called every frame. If you ran and debugged this updated script now, you’d find that the value range for each bin vary greatly. To make it easier to work with the values, we’ll scale each bin’s value into a number between 0 and 1. Add the following variables and function to SpectrumAnalyzer. float[] freqBandHighest = new float[8]; public static float[] audioBands = new float[8]; void CreateAudioBands() { } . Fill out CreateAudioBands() on your own. This function should first update freqBandHighest, which contains the highest-yet-seen values for each bin. Then it divides each current band value by the highest-yet-seen to get us a number between 0 and 1. This result is saved to array audioBands. Once you’ve completed CreateAudioBands(), add it to the end of Update() so it gets called each frame. ",
    "url": "/decal/homework/hw2/#8-bin-separation",
    "relUrl": "/homework/hw2/#8-bin-separation"
  },"25": {
    "doc": "Homework 2: Music Visualizer",
    "title": "Visualizing 8 Bins",
    "content": "Finally, let’s create cubes to visualize the calculated values for each bin. Let’s use the cube prefab again, and place eight of them in the middle of the scene. You can simply drag the prefab into the Hierarchy or the scene view. Scale them so they’re visible in the game view. We’ll need a script to read the values from audioBands in SpectrumAnalyzer and represent them as heights for each cube. Create a C# script named “Cube”, and add the following variables to it: . public int band; public float startScale; public float scaleMultiplier; . The variable band represents which bin this cube represents. startScale represents the height of the cube when its audioBand value is 0, and scaleMultiplier is how much to multiply the audioBand value by. Fill out the needed functionality on your own. You can refer to Instantiate512cube for help, since the functionality is similar. When you’re done, attach the script to each of the cubes and set the editor values appropriately (remember, you can modify multiple objects at once via shift/ctrl select). You do not have to use the values shown below. Now try out your music visualizer! . ",
    "url": "/decal/homework/hw2/#visualizing-8-bins",
    "relUrl": "/homework/hw2/#visualizing-8-bins"
  },"26": {
    "doc": "Homework 2: Music Visualizer",
    "title": "Add Your Own Flair",
    "content": "Your final task is to add your own feature to the music visualizer. This is completely open-ended - you may go as crazy as you’d like. We only request that you do not remove the functionality you’ve implemented thus far. Here are some suggestions on what you could add: . | Lights | Colors | Different Kinds of Visualization (spheres, rotation, etc.) | Band Buffering (removing the choppy movement of the bands) | . ",
    "url": "/decal/homework/hw2/#add-your-own-flair",
    "relUrl": "/homework/hw2/#add-your-own-flair"
  },"27": {
    "doc": "Homework 2: Music Visualizer",
    "title": "Submission and Grading",
    "content": "Upload the project via Google Drive and submit the link to bCourses. (Instructions on Ed.) Completion of the functionality described in this homework will get you 4 points (out of 5), and adding your own improvements will get you the last point. There will be extra credit given to those whom we deemed went above and beyond with their improvements. ",
    "url": "/decal/homework/hw2/#submission-and-grading",
    "relUrl": "/homework/hw2/#submission-and-grading"
  },"28": {
    "doc": "Homework 2: Music Visualizer",
    "title": "Credits",
    "content": "This assignment was taken and adapted from Peter Olthof’s brilliant music visualizer tutorial on Youtube. You can find it on his channel, Peer Play. ",
    "url": "/decal/homework/hw2/#credits",
    "relUrl": "/homework/hw2/#credits"
  },"29": {
    "doc": "Homework 3: Fractal Generation",
    "title": "Homework 3: Fractal Generation",
    "content": " ",
    "url": "/decal/homework/hw3/",
    "relUrl": "/homework/hw3/"
  },"30": {
    "doc": "Homework 3: Fractal Generation",
    "title": "Table of contents",
    "content": ". | Getting Started | Creating the Children | Setting Children Transforms | Recursive Attributes | Further Exploration | Submission and Grading | . This homework assignment is to create your own fractal generator. It will look something like this: . In this assignment, we will explore recursion within Unity by writing scripts that’ll build fractals for us! Fractals pair great with recursion because recursion can exploit and represent its hierarchical and repetitive characteristic very naturally. The fractal we want to construct for this assignment is fairly simple. Consider a single cube as the starting point. Our fractal will spawn new cubes half its size on five of its faces. Each of those cubes will then do the same thing, and so on until we reach the maximum recursion depth. Finally, every cube will slowly rotate on its y-axis, and thus children need to be oriented such that they do not clip significantly into their parent. Consider a top down view of a parent and its direct children: . As you can see, the light grey children are half the size as the dark grey parent. Note that each child is right next to the parent - its face touches the parent’s face, but the two don’t overlap. The child in the center is no exception; it sits on top of the parent. ",
    "url": "/decal/homework/hw3/#table-of-contents",
    "relUrl": "/homework/hw3/#table-of-contents"
  },"31": {
    "doc": "Homework 3: Fractal Generation",
    "title": "Getting Started",
    "content": "First off, download the skeleton asset package here and import it into a new project. Create a new scene called HW3 to work in. For testing purposes, we’ve provided you with a script to let you to zoom/pan your camera via mouse while in Game Mode. Attach the CameraController script to your Main Camera to do so. Within the Main Camera’s inspector, we would also recommend that you change the Clear Flags option from “Skybox” to “Solid Color”. This will make your fractal easier to see. You’ll also want to enable automatic lighting so your scene gets proper lighting. Do so through Windows &gt; Lighting &gt; Settings &gt; Auto Generate. Next, create an empty gameobject called “Fractal”, center it at the origin, and attach the Fractal script to it. You’ll notice there are some unpopulated fields in the Fractal component. Populate the fields with the following: . | Mesh: Cube (standard Unity asset, click the circle next to the field to select it) . | Material: Fractal (included in the package) . | MaxDepth: 1 . | Child Scale: 0.5 . | Max Rotation Speed: 15 . | . Before jumping into the code writing parts of the homework, we recommend reading through Fractal.cs and understanding what the script is trying to do. ",
    "url": "/decal/homework/hw3/#getting-started",
    "relUrl": "/homework/hw3/#getting-started"
  },"32": {
    "doc": "Homework 3: Fractal Generation",
    "title": "Creating the Children",
    "content": "In the first section, we’ll be filling in the CreateChildren() function of Fractal.cs. The CreateChildren() function currently runs a for-loop through the length of the childDirections array, which contain all the directions in which the children of this fractal will be growing. We’ll use this for-loop to spawn our children. In your code, you’ll want to do the following: . Create a new gameobject. Add a Fractal instance to the new gameobject. Call the Initialize() function on the new Fractal. Once you’ve successfully done this, press play and look at your hierarchy - you should see five additional gameobjects with Fractal components attached. You’ll want to look into creating new gameobjects and the AddComponent() function. Additional hints: . | You’d want to use the generic version of the AddComponent function. | Pay careful attention to what’s being passed into Initialize(). | It’s possible to do all this in one line! . | . ",
    "url": "/decal/homework/hw3/#creating-the-children",
    "relUrl": "/homework/hw3/#creating-the-children"
  },"33": {
    "doc": "Homework 3: Fractal Generation",
    "title": "Setting Children Transforms",
    "content": "In this section, we’ll be working on modifying the transforms of our fractal children within the Initialize() function of Fractal.cs. In particular, you’ll have to modify the gameobject’s transform such that it matches the requirements described at the beginning of the homework. Specifically, there are three attributes you’ll want to change: . | transform.localScale. Use the childScale variable. | transform.localPosition. Use the childDirections array and childIndex variable. | transform.localRotation. Use the childOrientations array and childIndex variable. You will not be able to tell whether your rotation is correct until the next section. | . Once you’ve successfully completed this section, you’ll see something very similar to the image below. Notice how there’s no visible gaps between the children and parent. ",
    "url": "/decal/homework/hw3/#setting-children-transforms",
    "relUrl": "/homework/hw3/#setting-children-transforms"
  },"34": {
    "doc": "Homework 3: Fractal Generation",
    "title": "Recursive Attributes",
    "content": "In the first section, you wrote the recursive call. You might not have realized it back then, but you did! Now, we will complete the recursive structure. Since we’re building fractals, the children will need to inherit attributes from their parents to enforce the recursive, repetitive nature of fractals. We’ve already completed three of the attributes for you: the mesh, materials, and childScale. You must figure out the values for: . | maxDepth. This should be the same as its parent. | maxRotationSpeed. This should be the same as its parent. | depth. This should be one higher than its parent. | transform.parent. This should be the transform associated with the Fractal parent. | . Once you’ve done so, start by verifying that your implementation for transform.parent is correct. If you’ve implemented it correctly, your children will correctly “nest” within your parent in the hierarchy. Your hierarchy should look something like the one below! . Now, we can test everything else. Change the maxDepth in scene’s Fractal gameobject from 1 to 5. Assuming everything was implemented correctly, you should see something very similar to the image below. Notice the beautiful nesting structure that we’ve created! . Finally, verify that your implementation for localRotation is correct. As you can observe from the image above, the children are rotating along the face of the parent. Make sure your children are doing so as well, and not rotating “into” the parent. To make it more clear, here is an example where the localRotation was set incorrectly: . Congratulations! You now have a fully operating fractal! . ",
    "url": "/decal/homework/hw3/#recursive-attributes",
    "relUrl": "/homework/hw3/#recursive-attributes"
  },"35": {
    "doc": "Homework 3: Fractal Generation",
    "title": "Further Exploration",
    "content": "Now that you’ve completed the assignment, there’s lots of cool things that you can add to it. I’ve provided a few suggestions below! . | Adding support for spawning different sorts of meshes. | Irregular spawning of meshes? (i.e. only spawns if it’s greater than a certain number?) . | Right now, our fractal has an upwards growing pattern. We can add support for it to grow towards the bottom as well. | . Something cool to both try and be wary for: increasing the maxDepth! Due to how this fractal grows exponentially in size, increasing maxDepth can easily cause Unity to overload and crash. See how far you can push it! . IMPORTANT NOTE: You should SAVE before attempting to do this experiment. You may be unlucky and lose all of your work. ",
    "url": "/decal/homework/hw3/#further-exploration",
    "relUrl": "/homework/hw3/#further-exploration"
  },"36": {
    "doc": "Homework 3: Fractal Generation",
    "title": "Submission and Grading",
    "content": "Use simmer.io to submit your work to bCourses. Completion of the “operational fractal” that we guided you in creating will get 4 points (out of 5), and adding your own improvements will get you the last point. There will be extra credit given to those whom we deemed went above and beyond with their improvements. ",
    "url": "/decal/homework/hw3/#submission-and-grading",
    "relUrl": "/homework/hw3/#submission-and-grading"
  },"37": {
    "doc": "Homework 3: Fractal Generation",
    "title": "Credits",
    "content": "Original assignment concept taken from Jasper Flick from catlikecoding. ",
    "url": "/decal/homework/hw3/#credits",
    "relUrl": "/homework/hw3/#credits"
  },"38": {
    "doc": "Homework 4: Pong",
    "title": "Homework 4: Pong",
    "content": " ",
    "url": "/decal/homework/hw4/",
    "relUrl": "/homework/hw4/"
  },"39": {
    "doc": "Homework 4: Pong",
    "title": "Table of contents",
    "content": ". | Your Task | Puck Physics . | Implementation Hints | . | Player Interactions . | Implementation Hints | . | Artificial Intelligence . | Implementation Hints | . | Game Logic . | Implementation Hints | . | Submission and Grading | . By now, you should have a pretty good grasp on Unity from the labs and the other homework assignments. Unlike these past assignments, however, your final project is completely free-form, with no set instructions to follow. As a way to bridge this gap, this final assignment will be a lot less guided than the previous ones. You’ll be building a clone of Pong, the classic Atari game. Download the skeleton package here. ",
    "url": "/decal/homework/hw4/#table-of-contents",
    "relUrl": "/homework/hw4/#table-of-contents"
  },"40": {
    "doc": "Homework 4: Pong",
    "title": "Your Task",
    "content": "Everyone has heard of Pong, and for good reason - it was the first financially successful video game of all time and kick-started the industry as we know it today. It is also an extremely simple game (out of necessity, considering it had to fit on 128 bytes of ram). The combination of these two factors makes it a traditional programming exercise for anyone learning a new language or tool. Your task is to implement a game of Pong such that it meets the specifications, which are described below. If you look at the skeleton package, you’ll notice that while we’ve built the scene for you, there’s almost no starter code. You recommend using the scene provided, but you are free to start from scratch. Now, let’s break down a game of Pong. What are the components that work together to make the game tick? . ",
    "url": "/decal/homework/hw4/#your-task",
    "relUrl": "/homework/hw4/#your-task"
  },"41": {
    "doc": "Homework 4: Pong",
    "title": "Puck Physics",
    "content": ". The puck moves across the table, bouncing off of the walls and paddles. With respect to movement, we expect the following from your puck: . | It moves in straight lines at constant velocity, and doesn’t change speed after bouncing off an object. | The angle it reflects to after bouncing off an object is the same angle as when it came in (imagine a laser bouncing off a mirror). | . This isn’t faithful to the original games. In other versions of Pong, the puck would speed up after every collision until somebody lost. The angle that which the puck would reflect off the paddle would also change depending on which part of the paddle was hit. You are free to implement this more advanced version for extra credit. ",
    "url": "/decal/homework/hw4/#puck-physics",
    "relUrl": "/homework/hw4/#puck-physics"
  },"42": {
    "doc": "Homework 4: Pong",
    "title": "Implementation Hints",
    "content": "In the scene provided, we’ve taken advantage of Unity physics to both specifications by attaching a physics material with full bounciness to the puck gameobject. We’ve also changed its rigidbody’s collision detection to “Continuous Dynamic”, which tells Unity that this object is going to move around a lot and should be treated accordingly. ",
    "url": "/decal/homework/hw4/#implementation-hints",
    "relUrl": "/homework/hw4/#implementation-hints"
  },"43": {
    "doc": "Homework 4: Pong",
    "title": "Player Interactions",
    "content": ". The player controls the blue paddle on the left side of the screen. Pressing the up or w keys on the keyboard should move the paddle up, while pressing down or s should move it down. The paddle should move at a constant, reasonable speed, and shouldn’t clip into or move through the walls. ",
    "url": "/decal/homework/hw4/#player-interactions",
    "relUrl": "/homework/hw4/#player-interactions"
  },"44": {
    "doc": "Homework 4: Pong",
    "title": "Implementation Hints",
    "content": "Utilize Unity’s input manager to access keyboard input (you used it in roll-a-ball to move the ball). Instead of using physics to move the paddle around, it’d be easier to directly modify its transform. ",
    "url": "/decal/homework/hw4/#implementation-hints-1",
    "relUrl": "/homework/hw4/#implementation-hints-1"
  },"45": {
    "doc": "Homework 4: Pong",
    "title": "Artificial Intelligence",
    "content": ". An AI agent controls the red paddle on the right side of the screen. The movement of this paddle is subject to the same constraints as the player - it must move at the same speed as the player, cannot clip or pass through walls, and cannot accelerate. You must script an AI for this paddle so that one person can play against the computer. The AI doesn’t have to be perfect by any means - it’s fine if it’s able to hit the puck roughly ~50% of the time. ",
    "url": "/decal/homework/hw4/#artificial-intelligence",
    "relUrl": "/homework/hw4/#artificial-intelligence"
  },"46": {
    "doc": "Homework 4: Pong",
    "title": "Implementation Hints",
    "content": "There are many possible solutions for this part. One simple approach is comparing the paddle’s z position with that of the puck’s, and choosing a direction to move in off of that. Since this is Berkeley though, for full credit we require that AI agents be run by multi-layer convolutional neural nets fed by the data of every pong, air hockey, and beer pong game ever played*. *This is a joke. But we will give extra credit to anyone who manages to implement an ML powered pong AI into this assignment. To get started, you could look into Unity’s recently released ML Agents. Want to go even further? Do it off of purely pixel values with OpenAI Universe with deep reinforcement learning. ",
    "url": "/decal/homework/hw4/#implementation-hints-2",
    "relUrl": "/homework/hw4/#implementation-hints-2"
  },"47": {
    "doc": "Homework 4: Pong",
    "title": "Game Logic",
    "content": "When the game begins, the puck should receive an impulse that gets it moving across the table. This can be either hard-coded to move towards a certain player or completely randomized. It must, however, have a decent amount of movement on the x-axis so that the game doesn’t get stuck. At this time, the score will be 0 to 0. This is reflected in the ScoreUI object which we’ve scripted and put into the scene for you already. Changes in game logic occur when the puck passes by a paddle and reaches the goal behind it. The following things occur: . | The scoring player receives a point (update ScoreUI accordingly). | The puck is moved back to the center of the table. | The puck receives an impulse that gets it moving towards the player who was scored on. | . When the winning score of 5 is reached, a message must be displayed on screen indicating who won. ScoreUI does this for you already. ",
    "url": "/decal/homework/hw4/#game-logic",
    "relUrl": "/homework/hw4/#game-logic"
  },"48": {
    "doc": "Homework 4: Pong",
    "title": "Implementation Hints",
    "content": "There are many ways you could detect a goal being scored: triggers, collision detection with the border, or a simple distance check on the x-axis. Since the puck has a rigidbody, you can use AddForce to apply an initial impulse to it. ",
    "url": "/decal/homework/hw4/#implementation-hints-3",
    "relUrl": "/homework/hw4/#implementation-hints-3"
  },"49": {
    "doc": "Homework 4: Pong",
    "title": "Submission and Grading",
    "content": "Use simmer.io to submit your work to bCourses. Grading will be done by whether or not the submission meets the described specifications. For full credit, a facilitator must be able to actually play the game. Partial credit will be given if some components (puck, player, AI, logic) work but others don’t. Unlike HW2 and HW3, making additional improvements is not required for this assignment. We will, however, still give extra credit to those we deem went above and beyond with their submission. ",
    "url": "/decal/homework/hw4/#submission-and-grading",
    "relUrl": "/homework/hw4/#submission-and-grading"
  },"50": {
    "doc": "Homework 5: Collisions, Raycasting, and Triggers",
    "title": "Homework 5: Collisions, Raycasting, and Triggers",
    "content": " ",
    "url": "/decal/homework/hw5/",
    "relUrl": "/homework/hw5/"
  },"51": {
    "doc": "Homework 5: Collisions, Raycasting, and Triggers",
    "title": "Table of contents",
    "content": ". | Overview | Part 1 . | The Scene | The Scene | . | Part 2 . | The Laser Gun | Pressure Plate | . | Submission and Grading | . While the previous homework was very open-ended, this homework has slightly more structure in order to help you get ready for developing your own final project. This homework focuses on collisions, raycasting, and triggers which are staples of user-world interaction in Unity. You’ll be building the functionality of two different guns: one of which is the flare gun which will rely on Unity physics and collisions, and the other is the laser gun which will use raycasting to detect its target. You will also make a pressure plate that detects when the user has stepped on it using triggers. This homework is split into two parts. You can download the skeleton project here. ",
    "url": "/decal/homework/hw5/#table-of-contents",
    "relUrl": "/homework/hw5/#table-of-contents"
  },"52": {
    "doc": "Homework 5: Collisions, Raycasting, and Triggers",
    "title": "Overview",
    "content": "While the labs have taken you through some of this work already, most of this homework is implementation from the ground up. We don’t expect you to know everything from the start to complete this homework; rather we’d like for you to search online for how some of these things work. Results from stackoverflow, the Unity forums, and Reddit are usually helpful. Searching things like “how to detect object collision unity” is bound to give you pertinent results. It’s important to get used to this since it’s very helpful for the final project, as well as any independent projects you may do later on. When you’re done with both parts of the homework, you should have: . | A flare gun that fires a flare bullet with working sound, and increments the target text counter when a bullet hits the target. | A laser gun that fires a ray with working sounds, and increments, the target text counter when the ray hits the target. | A pressure plate that displays the “Stepped on Trigger!” message on the wall when stepped on. | . You may find this chart helpful: . You can learn more here: https://docs.unity3d.com/Manual/CollidersOverview.html . ",
    "url": "/decal/homework/hw5/#overview",
    "relUrl": "/homework/hw5/#overview"
  },"53": {
    "doc": "Homework 5: Collisions, Raycasting, and Triggers",
    "title": "Part 1",
    "content": " ",
    "url": "/decal/homework/hw5/#part-1",
    "relUrl": "/homework/hw5/#part-1"
  },"54": {
    "doc": "Homework 5: Collisions, Raycasting, and Triggers",
    "title": "The Scene",
    "content": "When you load the SampleScene given in the package, you will notice that there are two floating gun models, a target with a text counter over it, and a green square on the ground. Your task for the first part will be to implement the firing and hit detection mechanics for the flare gun and the target. Moving and turning have already been implemented for you, with WASD controlling movement and your mouse controlling rotation. Press Q to switch between the two guns. Some advanced movement options are holding the shift key while moving to sprint and pressing the spacebar to jump. They use key bindings in Project Settings&gt;Input. Before you can use these built in controls, go to Edit&gt;Project Settings&gt;Input and change the size under axes to 20. This will allow you to create two new Input bindings. Name one SwapGuns and set the Positive Button to q. Name the other FireGun and set the Positive Button to mouse 0. Our controls implementation relies on these Inputs so make sure you do this or else shooting and swapping guns won’t work. If you’re curious or want to change the movement scripting, you can find the source code in Assets/Standard Assets/Characters/FirstPersonCharacter/Scripts. ",
    "url": "/decal/homework/hw5/#the-scene",
    "relUrl": "/homework/hw5/#the-scene"
  },"55": {
    "doc": "Homework 5: Collisions, Raycasting, and Triggers",
    "title": "The Scene",
    "content": "Your job is to make the flare gun fire a visible projectile (a flare bullet) which is another GameObject. Unity physics will act on the flare to give it velocity and collisions with the world. When the flare hits the target, the target’s onHit() method should be called which will increment the scoreboard (this functionality has already been implemented for you as well). The models and controls are already setup for you, so your job is to handle all the scripting. The flare gun and the flare are separate entities and have their own scripts, so make sure you are separating their functions. For example, does the flare fun need to know anything about the target? Probably not, since the flare bullet will be what actually collides with and interacts with the target. Take a look at FlareGunFiring.cs and FlareBullet.cs for details in the code comments. Like the monster in the lab, remember to put a tag on the target! Feel free to mess around with the effects and sounds. Once you have the flare gun shooting and flare bullets and incrementing the hit counter, you have finished part 1! . ",
    "url": "/decal/homework/hw5/#the-scene-1",
    "relUrl": "/homework/hw5/#the-scene-1"
  },"56": {
    "doc": "Homework 5: Collisions, Raycasting, and Triggers",
    "title": "Part 2",
    "content": " ",
    "url": "/decal/homework/hw5/#part-2",
    "relUrl": "/homework/hw5/#part-2"
  },"57": {
    "doc": "Homework 5: Collisions, Raycasting, and Triggers",
    "title": "The Laser Gun",
    "content": "Instead of a projectile, the laser gun should fire a visible (or can be invisible) “ray” from the gun model which shoots out in a straight line and is unaffected by physics. Like the flare bullet, the laser gun should also call the target’s onHit() method when the ray hits the target. Look in LaserGunFiring.cs for an overview. The visuals of this ray are already created for you, but the mechanics are not. You should be editing the fireLaserGun() method. ",
    "url": "/decal/homework/hw5/#the-laser-gun",
    "relUrl": "/homework/hw5/#the-laser-gun"
  },"58": {
    "doc": "Homework 5: Collisions, Raycasting, and Triggers",
    "title": "Pressure Plate",
    "content": "For this part, you will write the code in StepTriggerScript.cs to call the steppedOnTrigger() method (already made for you) when the player steps on the green pad. Refer to the collision chart to decide which colliders will work for this. You will need to make a new method for this functionality. If you have the laser gun shooting and updating the target’s hit counter correctly, and the green pressure plate displaying ‘Stepped on Trigger!’, you have finished part 2. ",
    "url": "/decal/homework/hw5/#pressure-plate",
    "relUrl": "/homework/hw5/#pressure-plate"
  },"59": {
    "doc": "Homework 5: Collisions, Raycasting, and Triggers",
    "title": "Submission and Grading",
    "content": "Use simmer.io to submit your work to bCourses. ",
    "url": "/decal/homework/hw5/#submission-and-grading",
    "relUrl": "/homework/hw5/#submission-and-grading"
  },"60": {
    "doc": "Home / Announcements",
    "title": "Extended Reality Development DeCal",
    "content": "Similar to how mobile devices revolutionized the way we interact with our electronic devices, Virtual Reality and Augmented Reality represent another exciting paradigm shift in human computer interaction. XR stands for Extended Reality, which is the realm that encompasses both Virtual and Augmented Reality. This semester, the course will teach students to develop VR applications in headmounted displays using Unity. Students will get exposure to different kinds of VR/AR apps and work in teams to build their own from scratch. The course is designed for beginners with no prior VR/AR experience required! After completion of the course, we welcome interested students to join an existing project team with XR @ Berkeley or pitch their own project. This 3-unit course will be held on Monday’s or Tuesday’s 6:00 - 8:00 PM PST in-person at Jacobs 10C (basement). You will be assigned one section, and you do not need to attend the other day’s section. NOTE: The first class starts next monday, September 11th. The course consists of lectures, labs, homework, and a final project. Each class will include a lecture on VR/AR theories and practices, followed by a “follow-along” style lab. Homework will be weekly for the first half of the course and will consist of practical Unity assignments. Halfway through the semester, classes will transition to giving students time to work in teams on their final projects until the end of the semester. Click here for the full course syllabus. If you’re interested in making projects with a team, please apply to the XR@B club! https://xr.berkeley.edu/ . ",
    "url": "/decal/#extended-reality-development-decal",
    "relUrl": "/#extended-reality-development-decal"
  },"61": {
    "doc": "Home / Announcements",
    "title": "Announcements:",
    "content": "Applications for Fall 2023 are opened! Apply here. ",
    "url": "/decal/#announcements",
    "relUrl": "/#announcements"
  },"62": {
    "doc": "Home / Announcements",
    "title": "Home / Announcements",
    "content": " ",
    "url": "/decal/",
    "relUrl": "/"
  },"63": {
    "doc": "AR Foundation",
    "title": "AR Foundation Labs",
    "content": "These labs use Unity’s AR Foundation to implement AR apps to build to mobile devices. ",
    "url": "/decal/labs/AR%20Foundation/#ar-foundation-labs",
    "relUrl": "/labs/AR%20Foundation/#ar-foundation-labs"
  },"64": {
    "doc": "AR Foundation",
    "title": "AR Foundation",
    "content": " ",
    "url": "/decal/labs/AR%20Foundation/",
    "relUrl": "/labs/AR%20Foundation/"
  },"65": {
    "doc": "Oculus",
    "title": "Oculus Labs",
    "content": "These labs use UnityXR and an Oculus (Meta) headset. These labs are supposed to be done in small groups, and be started and finished in class. If you are not able to finish - as long as you have showed effort that you tried to finish the lab, you will get checked off. ",
    "url": "/decal/labs/Oculus/#oculus-labs",
    "relUrl": "/labs/Oculus/#oculus-labs"
  },"66": {
    "doc": "Oculus",
    "title": "Oculus",
    "content": " ",
    "url": "/decal/labs/Oculus/",
    "relUrl": "/labs/Oculus/"
  },"67": {
    "doc": "HTC Vive",
    "title": "HTC Vive Labs",
    "content": "These labs use Unity’s support for SteamVR and implements them using HTC Vive pc-tethered headsets. ",
    "url": "/decal/labs/HTC%20Vive/#htc-vive-labs",
    "relUrl": "/labs/HTC%20Vive/#htc-vive-labs"
  },"68": {
    "doc": "HTC Vive",
    "title": "HTC Vive",
    "content": " ",
    "url": "/decal/labs/HTC%20Vive/",
    "relUrl": "/labs/HTC%20Vive/"
  },"69": {
    "doc": "Labs",
    "title": "Labs",
    "content": "We will be doing the Oculus VR labs this semester. All labs will be done in class as they require a headset and a high-performance Windows computer. We will be using pc-tethered Oculus Rift S’s in class. ",
    "url": "/decal/labs/",
    "relUrl": "/labs/"
  },"70": {
    "doc": "Final Project",
    "title": "Final Project",
    "content": " ",
    "url": "/decal/final-project/",
    "relUrl": "/final-project/"
  },"71": {
    "doc": "Final Project",
    "title": "Table of contents",
    "content": ". | Quick Logistics | Project Overview | Group and Idea Formation | Grading | Resources | . The VR field and community has always been driven by rapid, project-based development. We wanted to reflect this in the course by giving you the opportunity to work on your own VR application. For your final project, you’ll be working on all aspects of developing a VR application, starting from forming teams and project ideas and culminating in showcasing it to others. ",
    "url": "/decal/final-project/#table-of-contents",
    "relUrl": "/final-project/#table-of-contents"
  },"72": {
    "doc": "Final Project",
    "title": "Quick Logistics",
    "content": ". | All deliverables for this project are due at the end of semester showcase. | The Preliminary Project Proposal is the first step of the process. | Groups and initial ideas are set during the in-class Mixer. | Final Project Proposals are assigned during the Mixer. | Groups must consist of 3-4 people from the class. | Projects must be applications built in Unity for the Oculus platform. | There will be an expo event at the end of the semester where you’ll be able to show off your work to each other, the XR@B club, and the general public! | . ",
    "url": "/decal/final-project/#quick-logistics",
    "relUrl": "/final-project/#quick-logistics"
  },"73": {
    "doc": "Final Project",
    "title": "Project Overview",
    "content": "Your project will be a Unity application built on the Oculus platform. We put emphasis on the word “application” - it must be something that someone else could find value in using. While the contents of your project are entirely up to you, we ask that you strive to meet the following design goals: . | You must be able to demo it. This means that you can put someone new to VR into your application and, with some external guidance by the one running the demo, have them experience/understand the gist of your project within 3 to 5 minutes. That isn’t to say that your entire content must be shown within that time frame, just that you should be able to get the selling points across. | It should bring something new to the table. There are many companies and studios out there able to spend millions of dollars refining the perfect survival wave shooter game. Come up with something that hasn’t been seen yet or adequately explored. It could be a new game mechanic, a untapped use case, or a novel way of storytelling. On the flip side, however, don’t worry if the cool thing you’ve come up with is already being done in some hackathon or startup somewhere - there are always multiple facets to the same idea. | It should benefit from being in VR. This class is all about tapping into VR’s potential, and that can’t be properly shown if what you build could have been done just as well as a web page or mobile app. Take advantage of this new medium! Always ask yourself the question, “Why VR?” | . These are difficult requirements to hit. You should be able to justify how you met each goal to us, but they also will not decide your grade alone. ",
    "url": "/decal/final-project/#project-overview",
    "relUrl": "/final-project/#project-overview"
  },"74": {
    "doc": "Final Project",
    "title": "Group and Idea Formation",
    "content": "The final project starts with the Preliminary Project Proposal. Individually fill out this form with an idea that you’d like to work on. This is due the day before the in-class Mixer. In class, we will be hold an “idea mixer” after lecture. Styled after similar events at hackathons, this time is to give you a chance to discuss project ideas with other students and form teams around promising ideas. We’ll start by giving everyone a minute to pitch their project proposal to the class, then give you time to talk and discuss with others. We will provide information from everyone’s submitted ideas so you can easily find people with similar interests. Groups should include 3-4 people from the class. By the end of class that day, we expect you to inform us of your team members and project idea. If there’s time remaining, facilitators will work with your team in refining the idea into something in scope for the class, as well as give you advice on how you might start implementing it. After your group has been formed, your team should fill out the Final Project Proposal form. This will go into more detail about your project idea and how you intend to implement it / distribute the workload. This form is due a week after the mixer. Important: If you are unable to attend class that day, we recommend you start early on finding a group, either in-class or on Ed. Otherwise, please let the facilitator team know and we’ll match you to a group. ",
    "url": "/decal/final-project/#group-and-idea-formation",
    "relUrl": "/final-project/#group-and-idea-formation"
  },"75": {
    "doc": "Final Project",
    "title": "Grading",
    "content": "From the syllabus, the final project is worth 30% of your total grade. This can be broken up into facilitator grades (20%), peer evaluations (5%), and the two proposal forms (2.5% each). This will be our rubric for judging projects: . | CRITERIA | DESCRIPTION | WEIGHT | . | Technical | - Consistent visuals (no missing textures, broken models, etc.) - Smooth performance (90 fps) - Bug free | 33.3% | . | User Experience | - Intuitive controls and interactions - No motion sickness - Immersion | 33.3% | . | Value | - Clear vision - Benefits from being in VR - Explores something new | 33.3% | . ",
    "url": "/decal/final-project/#grading",
    "relUrl": "/final-project/#grading"
  },"76": {
    "doc": "Final Project",
    "title": "Resources",
    "content": "Go here for a page containing various resources and tips for the final project. ",
    "url": "/decal/final-project/#resources",
    "relUrl": "/final-project/#resources"
  },"77": {
    "doc": "Homework",
    "title": "Homework",
    "content": "All homework will require a computer with Unity to complete. Your personal laptop should suffice. ",
    "url": "/decal/homework/",
    "relUrl": "/homework/"
  },"78": {
    "doc": "Lectures",
    "title": "Lectures",
    "content": ". | Lecture 0: Introduction to Virtual Reality . | Lecture 1: Fundamentals of Virtual Reality . | Lecture 2: Locomotion and Motion Sickness . | Lecture 3: Hardware and Input Schemes . | Lecture 4: Principles of VR Design . | Lecture 5: Social Implications of VR . | Special Topics: VR Status Quo . | . ",
    "url": "/decal/lectures/",
    "relUrl": "/lectures/"
  },"79": {
    "doc": "AR Foundation Lab 1: Project Setup / Building the Environment",
    "title": "AR Foundation Lab 1: Project Setup / Building the Environment",
    "content": " ",
    "url": "/decal/labs/AR%20Foundation/lab1/",
    "relUrl": "/labs/AR%20Foundation/lab1/"
  },"80": {
    "doc": "AR Foundation Lab 1: Project Setup / Building the Environment",
    "title": "Table of contents",
    "content": ". | The Game | Installation | Project Setup . | For iOS | For Android | . | Creating the Scene . | Place On Plane | . | . Welcome to Monster Shooter! Over the course of these labs, you’ll be building a game that looks something like this: . These labs will not be a comprehensive overview of everything that Unity and AR has to offer. However, they will touch upon a lot of different topics so that you get a taste of what is possible. The labs will also serve as practice for creating a project from start to finish, something that will be valuable for the final project. ",
    "url": "/decal/labs/AR%20Foundation/lab1/#table-of-contents",
    "relUrl": "/labs/AR%20Foundation/lab1/#table-of-contents"
  },"81": {
    "doc": "AR Foundation Lab 1: Project Setup / Building the Environment",
    "title": "The Game",
    "content": "Monster Shooter is a survival shooter game. Set in a small desert town, you use your trusty pistol to fend off hordes of monsters until you reach your eventual demise. We can divide the game into several distinct chunks. Each lab will focus on a single one. | The environment. The world that you see around you when you put on the headset. All the props, textures, skyboxes, models, etc. Most of it will be static and stationary for the game, with the sole exception of the gun. | The gun. Namely, being able to pick it up and shoot it. This sounds simple, but requires scripting, animations, particle effects, sound effects, and input management from the controller in order to create that split second experience when you pull the trigger. | The monsters. They must be able to navigate the environment and make their way towards the player, where they’ll attack when in range. | The manager. This manages the spawning of monsters over the course of the game, and also what happens when you take too much damage and die. | Image tracking. The gun will be programmed to follow an image in the real world. | . For this lab, we will focus on the initial setup of the project and the creation of the environment. This will be a quick tutorial on setting up Unity for AR Foundation, and iOS and android development, as well as setting up the scene in Unity. ",
    "url": "/decal/labs/AR%20Foundation/lab1/#the-game",
    "relUrl": "/labs/AR%20Foundation/lab1/#the-game"
  },"82": {
    "doc": "AR Foundation Lab 1: Project Setup / Building the Environment",
    "title": "Installation",
    "content": "Download Unity 2019.4.3f1. We recommend using Unity Hub because it allows you to easily manage multiple Unity versions. Add the modules: Android Build Support, IOS Build Support. If deploying to iOS, you will need to download XCode as well. ",
    "url": "/decal/labs/AR%20Foundation/lab1/#installation",
    "relUrl": "/labs/AR%20Foundation/lab1/#installation"
  },"83": {
    "doc": "AR Foundation Lab 1: Project Setup / Building the Environment",
    "title": "Project Setup",
    "content": "Begin by creating a new Unity 3D project on the proper version of unity. Note: This lab is designed to work on Unity 2019.4.3f1. (Other versions of Unity will probably work but have not been tested) . Then, we need to import the AR Foundation packages. Navigate to the package manager (Window &gt; Package Manager) . Import these packages: . | AR Foundation (required) . | AR Subsystems (installed as dependency with AR Foundation) | Check that AR Subsystems is installed | . | ARKit XR Plugin (if you are deploying onto iOS) | ARCore XR Plugin (if you are deploying onto Android) | . Feel free to explore other packages in the future for your final project. Download the project skeleton here. This is a unitypackage that contains all the assets and resources needed to build the project. Next, create a new project and import the downloaded unitypackage. You can do this through Assets &gt; Import Package &gt; Custom Package. Importing might take a while, as Unity will have to load and configure a lot of textures and libraries. Once it’s finished, you’ll see in your Project view a bunch of folders, which we’ll briefly give a rundown for below. | Animations: Contains animation data for the gun and monsters. | Materials: Contains the materials that help define what each object looks like in game. | Models: Contains the 3D models. | Prefabs: Premade objects that you can drop or spawn into a scene. Some of these are akin to just models, but others have other components or functionality attached. | Resources: Another auto-generated folder. This one only contains some data for the Oculus. | Scripts: Contains the scripts that help run and drive the game. | Sounds: Contains the sound files. | Textures: Contains the images that feed into the materials in the Materials folder. | . A final thing before we delve into creating the scene: go ahead and reset your editor layout via Window &gt; Layouts &gt; Default. Any screenshots shown (like the one above) will be using this layout and will make following along easier. This has no effect on the actual project, so if you prefer using a different layout, you are free to do so. Now, in the Unity hierarchy, delete the default Main Camera. We will use an AR camera so this main camera is not needed. Add an AR Session gameobject (right click in hierarchy &gt; XR &gt; AR Session). The AR Session must include an ARSession component on one of the GameObjects. By adding an AR Session GameObject, Unity adds a GameObject with the AR Session component automatically attached. The AR Sessions controls the lifecycle of an AR experience, enabling or disabling the AR on the target platform. The ARSession can be on any GameObject. If the Scene doesn’t contain an ARSession, the application will not be able to track features in its environment. Add an AR Session Origin gameobject (right click in hierarchy &gt; XR &gt; AR Session Origin). The purpose of the ARSessionOrigin is to transform trackable features (planar surfaces and feature points) into their final Pose (position &amp; orientation) and Scale in the Unity Scene. This enables virtual object interaction and manipulation with these transformed features. AR devices provide their data in session space, an unscaled space relative to the beginning of the AR session. As such, the ARSessionOrigin must transform this data so it is appropriate for the Unity application in Unity “space”. You can read the documentation here: https://docs.unity3d.com/Packages/com.unity.xr.arfoundation@2.0/manual/index.html . You can rename the scene to “lab” under the project view. (right-click &gt; rename) . Navigate to the build settings. (File &gt; Build Settings) Change the deployment target to either iOS or Android. Select your platform, either Android or iOS, then click switch platform. ",
    "url": "/decal/labs/AR%20Foundation/lab1/#project-setup",
    "relUrl": "/labs/AR%20Foundation/lab1/#project-setup"
  },"84": {
    "doc": "AR Foundation Lab 1: Project Setup / Building the Environment",
    "title": "For iOS",
    "content": "Adjust the player settings. (click player settings on the bottom left) . | Change the bundle identifier from the default. | You can change it to anything you want, just don’t leave it on the default. | We used “com.VRDecal.lab1” | . | Check Requires ARKit support. | Change the Target minimum iOS Version to 11.0 | Change Architecture to ARM64 | . Unity builds to an XCode project which you then use to build onto your device. In XCode you need to sign the app and then approve the developer on your iPhone. Select Unity-iPhone in file explorer, open the Signing &amp; Capabilities tab, check Automatically manage signing and select your team. You can add an account if there is no team yet. In iOS, (settings&gt;general&gt;device management) approve your developer profile. ",
    "url": "/decal/labs/AR%20Foundation/lab1/#for-ios",
    "relUrl": "/labs/AR%20Foundation/lab1/#for-ios"
  },"85": {
    "doc": "AR Foundation Lab 1: Project Setup / Building the Environment",
    "title": "For Android",
    "content": "Adjust the player settings. (click player settings on the bottom left) . | In the “Other Settings” dropdown menu, under Graphics APIs, remove Vulkan by clicking on it and clicking the minus (-) button on the bottom right corner. | Also in “Other Settings”, change the Minimum API Level to Android 7.0 ‘Nougat’ (API level 24). | Then, back to build settings, under Run Device, select the device you want to deploy the app to. | Click build and run, and after saving the apk somewhere on your computer, it will export onto your mobile device and will automatically run if your device is open. It will also appear like an app where all your other apps are as well. | . Now you should be able to build the project on your device. Please follow this tutorial for help. https://learn.unity.com/tutorial/building-for-mobile#5c7f8528edbc2a002053b4a1 . ",
    "url": "/decal/labs/AR%20Foundation/lab1/#for-android",
    "relUrl": "/labs/AR%20Foundation/lab1/#for-android"
  },"86": {
    "doc": "AR Foundation Lab 1: Project Setup / Building the Environment",
    "title": "Creating the Scene",
    "content": "At this point you should have your project setup and an empty scene with an AR Session and AR Session Origin. Next, we need to configure the AR Session Origin. Select the AR Session Origin in the hierarchy and click add component in the inspector. Add the following components: . | AR Raycast Manager | AR Plane Manager | AR Point Cloud Manager | . Now add the appropriate prefab to the AR Plane Manager and AR Point Cloud Manager. Under the Project window, open Assets/Prefabs. Drag the AR Plane Debug Visualizer into the AR Plane Manager’s Plane Prefab slot. Do the same with the AR Point Cloud Debug Visualizer and the AR Point Cloud Manager. These visualizers are pretty helpful for debugging and building the scene. In the future when we finish the game feel free to remove them by setting the prefab slot to None. ",
    "url": "/decal/labs/AR%20Foundation/lab1/#creating-the-scene",
    "relUrl": "/labs/AR%20Foundation/lab1/#creating-the-scene"
  },"87": {
    "doc": "AR Foundation Lab 1: Project Setup / Building the Environment",
    "title": "Place On Plane",
    "content": "Open the scripts folder and open the PlaceOnPlane script. You will fill in the update() function to place down our environment on a plane where we tap. The Update() function is called every frame and we need to check when the user taps the screen to perform a Raycast. We call m_RaycastManager.Raycast() which returns raycast hits sorted by distance. We use the closest hit to place our environment. Also create an s_hits arraylist outside the function to hold all the raycast hits. static List s_Hits = new List(); . void Update() { if (!TryGetTouchPosition(out Vector2 touchPosition)) return; if (m_RaycastManager.Raycast(touchPosition, s_Hits, TrackableType.PlaneWithinPolygon)) { // Raycast hits are sorted by distance, so the first one // will be the closest hit. var hitPose = s_Hits[0].pose; if (spawnedObject == null) { spawnedObject = Instantiate(m_PlacedPrefab, hitPose.position, hitPose.rotation); } } } . Next, we can now add the place on plane script to the AR Session origin. You can drag the script to the inspector or click add component and search Place on Plane. Then put the environment prefab in the placed prefab slot. Congratulations! We can now place our environment onto an AR plane where we tap. You can build the app onto your phone to check it out. ",
    "url": "/decal/labs/AR%20Foundation/lab1/#place-on-plane",
    "relUrl": "/labs/AR%20Foundation/lab1/#place-on-plane"
  },"88": {
    "doc": "Oculus Lab 1: Building the Environment",
    "title": "Oculus Lab 1: Building the Environment",
    "content": " ",
    "url": "/decal/labs/Oculus/lab1/",
    "relUrl": "/labs/Oculus/lab1/"
  },"89": {
    "doc": "Oculus Lab 1: Building the Environment",
    "title": "Table of contents",
    "content": ". | The Game | Project Setup | Creating the Scene | Putting in VR Support | Adding Hands and the Stand | Adding the Gun | Adding to the Environment | Check Off | . Welcome to Monster Shooter! Over the course of 4 lab sections, you’ll be building a game that looks like this: . These labs will not be a comprehensive overview of everything that Unity and VR has to offer. However, they will touch upon a lot of different topics so that you get a taste of what is possible. The labs will also serve as practice for creating a project from start to finish, something that will be valuable for the final project. ",
    "url": "/decal/labs/Oculus/lab1/#table-of-contents",
    "relUrl": "/labs/Oculus/lab1/#table-of-contents"
  },"90": {
    "doc": "Oculus Lab 1: Building the Environment",
    "title": "The Game",
    "content": "Monster Shooter is a survival shooter game. Set in a small desert town, you use your trusty pistol to fend off hordes of monsters until you reach your eventual demise. We can divide the game into several distinct chunks. Each lab will focus on a single one. | The environment. The world that you see around you when you put on the headset. All the props, textures, skyboxes, models, etc. Most of it will be static and stationary for the game, with the sole exception of the gun. | The gun. Namely, being able to pick it up and shoot it. This sounds simple, but requires scripting, animations, particle effects, sound effects, and input management from the controller in order to create that split second experience when you pull the trigger. | The monsters. They must be able to navigate the environment and make their way towards the player, where they’ll attack when in range. | The manager. This manages the spawning of monsters over the course of the game, and also what happens when you take too much damage and die. | . For this lab, we will focus on the initial setup of the project and the creation of the environment. ",
    "url": "/decal/labs/Oculus/lab1/#the-game",
    "relUrl": "/labs/Oculus/lab1/#the-game"
  },"91": {
    "doc": "Oculus Lab 1: Building the Environment",
    "title": "Project Setup",
    "content": "First, download the project skeleton here (or check if it’s already been downloaded onto your computer). This is a unitypackage that contains all the assets and resources needed to build the project. Next, create a new project and import the downloaded unitypackage. You can do this through Assets &gt; Import Package &gt; Custom Package. Importing might take a while, as Unity will have to load and configure a lot of textures and libraries. In particular, if you see Unity getting stuck importing something called “AvatarSurfaceShader”, don’t be alarmed - that particular asset will usually take a long time. Once it’s finished, you’ll see in your Project view a bunch of folders, which we’ll briefly give a rundown for below. | Animations: Contains animation data for the gun and monsters. | Materials: Contains the materials that help define what each object looks like in game. | Models: Contains the 3D models. | Prefabs: Premade objects that you can drop or spawn into a scene. Some of these are akin to just models, but others have other components or functionality attached. | Resources: Another auto-generated folder. This one only contains some data for the Oculus. | Scenes: Contains the scene for our labs. | Scripts: Contains the scripts that help run and drive the game. | Sounds: Contains the sound files. | Textures: Contains the images that feed into the materials in the Materials folder. | XR / XRI: Folders with XR-related settings and defaults . | . A final thing before we delve into creating the scene: go ahead and reset your editor layout via Window &gt; Layouts &gt; Default. Any screenshots shown (like the one above) will be using this layout and will make following along easier. This has no effect on the actual project, so if you prefer using a different layout, you are free to do so. ",
    "url": "/decal/labs/Oculus/lab1/#project-setup",
    "relUrl": "/labs/Oculus/lab1/#project-setup"
  },"92": {
    "doc": "Oculus Lab 1: Building the Environment",
    "title": "Creating the Scene",
    "content": "Let’s start by creating a new scene. Right-click some empty space within the Project view and select Create &gt; Scene, and call it “Lab”. Double-click your newly created scene to open it. The first thing you’ll want to do is delete the Main Camera and Directional Light objects that come part of the scene - we’ll add our own camera and lights in a bit. Now go into the Prefabs folder and look for a prefab called “Environment”. To save you a couple hours of work, we’ve created the physical map for you. Drag the prefab into the Hierarchy view on the left side to spawn an instance of it into your scene. Scene with the environment prefab dropped in. Make sure the environment’s transform component in the Inspector view is zeroed out in position and rotation, and has a xyz-scale of 1. If your values don’t match, click the gear in the top right and hit “Reset”. You’ll notice that the lighting is off - the buildings are way too dark and shadows aren’t being cast properly. We’ll fix that, but first we’ll change the skybox (the textures that surround the scene) to something that looks more like the night sky. Go to Window &gt; Rendering &gt; Lighting &gt; Environment, which will open a new window that contains all the lighting data for this scene. Look for the “Skybox Material” line under ‘Environment’, and click the little circle on its right side. This will open up a box that lets you select which skybox to use. Search for “nightsky2” and select it. With our skybox in we can now properly fix our lighting. To have Unity auto-generate lighting, go to the ‘Scene’ tab on the Lighting window. Select the asset for ‘Lighting Settings Asset’ to be LabLighting’. Then, you check “Auto Generate” and click “Generate Lighting” to start computing the proper lighting for the scene. ",
    "url": "/decal/labs/Oculus/lab1/#creating-the-scene",
    "relUrl": "/labs/Oculus/lab1/#creating-the-scene"
  },"93": {
    "doc": "Oculus Lab 1: Building the Environment",
    "title": "Putting in VR Support",
    "content": "If you try pressing play now, you’ll just get a black screen telling you that no cameras are rendering. This is because we removed the Main Camera GameObject that comes with every new scene. Let’s fix that now. First, our project does not have any packages that support XR functionality, so let us install them. Go to Window &gt; Package Manager and switch the top tab from “Packages: In Project” to “Packages: Unity Registry” to see all of the available packages. Install “XR Plugin Management”, “Oculus XR Plugin”, and “XR Interaction Toolkit”. Let the package manager restart your project to make changes if asked. Now we have the necessary packages to get started! . (If you don’t see XR Interaction Toolkit then click the “+” on the top left and “Add Package by Name…” and insert “com.unity.xr.interaction.toolkit”.) . Next, we need to define default inputs so when we make the GameObject for the player, it will have inputs mapped to the Rift S control set. To first set the defaults, go to XR &gt; XR Interaction Toolkit &gt; 2.1.1 &gt; Starter Assets, and select “XRI Default Left Controller” and select “Add to ActionBasedController default”. There is another default for the right controller, do the same for this one. As of now, there are two defaults for a single preset! To remedy this, go to Edit &gt; Project Settings &gt; Preset Manager, and for the right controller, add “right” to the filter, and do “left” for the left one. This will let unity differentiate between which defaults to apply: . Next, right-click anywhere on the GameObject Hierarchy, and select XR &gt; XR Origin (VR). This will place a GameObject that will be the game camera and interpret controls. Set its positional Transform values to (0,0,0) or by clicking “Reset” on the dropdown menu on the top right of the component. Think of this GameObject as the player. If you go from XR Origin &gt; Camera Offset &gt; …, you can see that the left and right controllers have actions that correspond to “LeftHand” or “RightHand” respective to its controller. Unity needs a way to read the values of a given action, so if we go to XR Interaction Manager in the hierarchy, click on Add Component on the Inspector panel and search for a “Input Action Manager”. Let us press on the “+” and select the “XRI Default Input Actions”. Ok! That solves inputs for controllers! . There’s one final thing we need to do before we can put on the headset. Go to Edit &gt; Project Settings &gt; XR Plug-in Management and check “Oculus” if it’s not already enabled. Then put on the headset and press play! . Note: If it looks like this image in the headset with red lasers, you’re all good! If you seem to be stuck in the ground, select your XR Origin within your hierarchy and, in the Inspector view, change Tracking Origin Mode from Not Specified to Floor Level. Now try it again. As you move your controllers around, you can see that there are red lasers coming from them. Let us disable these by disabling the “XR Ray Interactor” on both controllers. (As a reminder, you can find these controllers under XR Origin &gt; Camera Offset &gt; Left/RightHandController). ",
    "url": "/decal/labs/Oculus/lab1/#putting-in-vr-support",
    "relUrl": "/labs/Oculus/lab1/#putting-in-vr-support"
  },"94": {
    "doc": "Oculus Lab 1: Building the Environment",
    "title": "Adding Hands and the Stand",
    "content": "We now want to add hands and the gun to our game so we can build interactivity between the two. Before adding the gun, however, we’re going to add a stand to put the gun on so that it’s within arm’s reach when you start the game. Let’s start with your hands and input. First, go to the hierarchy and go to XR Origin &gt; Camera Offset &gt; LeftHand Controller. On the XR Controller component, we can see that there is a Model area with a “Model Prefab” field. This will be where we can put our hand model. To find the hand models, go to Prefabs &gt; XR Prefabs and assign LeftHand to the “Model Prefab” field. Do the same with the right-hand controller. Next, let’s create the two crates that make up the stand. If you look to the left of your starting location, you’ll notice there’s already a crate there we can use. Duplicate it off twice, and move the new objects out of the Environment object so that they’re parentless - this will make it easier to select and move them. Rename one to “Lower Crate” and the other to “Upper Crate”. Your hierarchy should now look like this. Use the movement (w), rotation (e), and scale (r) tools to position these crates into the shape shown in the first picture of the section. The lower crate should be just to the right of OVRCameraRig, and the upper crate should be smaller and sit on top of it. Don’t worry about being exact - just keep testing it with the headset on until the top of the upper crate is comfortably within arm’s reach. A tip: With the scale tool, dragging the white cube scales all axes. ",
    "url": "/decal/labs/Oculus/lab1/#adding-hands-and-the-stand",
    "relUrl": "/labs/Oculus/lab1/#adding-hands-and-the-stand"
  },"95": {
    "doc": "Oculus Lab 1: Building the Environment",
    "title": "Adding the Gun",
    "content": "Now we can create the gun. Start by right-clicking an empty spot within the hierarchy and clicking “Create Empty”. This will create an object with nothing but a transform component, which we’ll add to and flesh out over the course of these labs. Name it “Gun”, and reset its transform - we’ll move it later. Go into the Models folder and find the object called “makarov”. This is the 3D model for our gun. Go ahead and drag it onto our newly created empty object, which will parent it under Gun. Parenting is a concept in Unity that allows us to construct complex objects out of simpler ones and have them all move together as one. An object (call it the child) parented under another object (call it the parent) will have all its transform values defined as relative to that of its parent. This means when the parent moves, scales, or rotates, its child will change along with it. Let’s rename this newly childed object to “Model”. It’ll start out being far, far too large, so scale each of its axes to 0.025. Then select its parent Gun and move it around, which should now move the 3D model around as well. Position/rotate gameobject Gun so it sits on top of the upper crate. Next, we’re going to add physics functionality to our gun, so that players can throw it if they ever want to give up in style. With Gun selected, go to the Inspector view and use the Add Component button to add a Box Collider to our object. You’ll see a green box appear around the gun. This green box is a collider. Colliders represent the bounds of an object when doing physics calculations (like collisions), and in Unity are either boxes, sphere, or capsules. Of course, a box can’t perfectly capture the bounds of a complex model like our gun, but it’ll do for the circumstances. The default size of the box collider is neither the right size or shape. Change its size values so that X = 0.03, Y = 0.15, and Z = 0.2. The result should look like this: . Now, add a Rigidbody component to Gun. Rigidbodies are what define something as a moving, physical object. It tells Unity how to treat this object in its physics calculations with variables like weight and drag. Note that an object cannot have a rigidbody component without also having a collider (since Unity needs physical bounds to perform physics calculations). Let’s test whether or not our gun is a valid physics object. Raise it up a little in the inspector, then put on the headset and press play. You should see that the gun has fallen from its original location to rest on the upper box. Actually, it hovers a little above the crate. Why? . ",
    "url": "/decal/labs/Oculus/lab1/#adding-the-gun",
    "relUrl": "/labs/Oculus/lab1/#adding-the-gun"
  },"96": {
    "doc": "Oculus Lab 1: Building the Environment",
    "title": "Adding to the Environment",
    "content": "Look through the project directory and find out where the 3D models used for this project are stored. You’ll find a lot more than what we used in the scene! As a final exercise, drag in some of models and decorate the scene with them. ",
    "url": "/decal/labs/Oculus/lab1/#adding-to-the-environment",
    "relUrl": "/labs/Oculus/lab1/#adding-to-the-environment"
  },"97": {
    "doc": "Oculus Lab 1: Building the Environment",
    "title": "Check Off",
    "content": "This marks the end of lab 1! To check-off successfully, just let a facilitator see your current project and show them that you’ve completed all of the sections successfully. Additionally, answer the following questions: . | Why does the gun hover over the crate? What’s a potential solution to fix this and what would the drawbacks of that solution be? | What additions did you make to the scene? | . ",
    "url": "/decal/labs/Oculus/lab1/#check-off",
    "relUrl": "/labs/Oculus/lab1/#check-off"
  },"98": {
    "doc": "Vive Lab 1: Building the Environment",
    "title": "Vive Lab 1: Building the Environment",
    "content": " ",
    "url": "/decal/labs/HTC%20Vive/lab1/",
    "relUrl": "/labs/HTC%20Vive/lab1/"
  },"99": {
    "doc": "Vive Lab 1: Building the Environment",
    "title": "Table of contents",
    "content": ". | The Game | Project Setup | Creating the Scene | Putting in VR Support | Adding Hands and the Stand | Adding the Gun | . Welcome to Monster Shooter! Over the course of 4 lab sections, you’ll be building a game that looks like this: . These labs will not be a comprehensive overview of everything that Unity and VR has to offer. However, they will touch upon a lot of different topics so that you get a taste of what is possible. The labs will also serve as practice for creating a project from start to finish, something that will be valuable for the final project. ",
    "url": "/decal/labs/HTC%20Vive/lab1/#table-of-contents",
    "relUrl": "/labs/HTC%20Vive/lab1/#table-of-contents"
  },"100": {
    "doc": "Vive Lab 1: Building the Environment",
    "title": "The Game",
    "content": "Monster Shooter is a survival shooter game. Set in a small desert town, you use your trusty pistol to fend off hordes of monsters until you reach your eventual demise. We can divide the game into several distinct chunks. Each lab will focus on a single one. | The environment. The world that you see around you when you put on the headset. All the props, textures, skyboxes, models, etc. Most of it will be static and stationary for the game, with the sole exception of the gun. | The gun. Namely, being able to pick it up and shoot it. This sounds simple, but requires scripting, animations, particle effects, sound effects, and input management from the controller in order to create that split second experience when you pull the trigger. | The monsters. They must be able to navigate the environment and make their way towards the player, where they’ll attack when in range. | The manager. This manages the spawning of monsters over the course of the game, and also what happens when you take too much damage and die. | . For this lab, we will focus on the initial setup of the project and the creation of the environment. ",
    "url": "/decal/labs/HTC%20Vive/lab1/#the-game",
    "relUrl": "/labs/HTC%20Vive/lab1/#the-game"
  },"101": {
    "doc": "Vive Lab 1: Building the Environment",
    "title": "Project Setup",
    "content": "First, download the project skeleton here. This is a unitypackage that contains all the assets and resources needed to build the project. Next, create a new project and import the downloaded unitypackage. You can do this through Assets &gt; Import Package &gt; Custom Package. Importing might take a while, as Unity will have to load and configure a lot of textures and libraries. In particular, if you see Unity getting stuck importing something called “AvatarSurfaceShader”, don’t be alarmed - that particular asset will usually take a long time. Once it’s finished, you’ll see in your Project view a bunch of folders, which we’ll briefly give a rundown for below. The folders you start off with. | Animations: Contains animation data for the gun and monsters. | Materials: Contains the materials that help define what each object looks like in game. | Models: Contains the 3D models. | SteamVR: Library folder that provide support for the HTC Vive. | Prefabs: Premade objects that you can drop or spawn into a scene. Some of these are akin to just models, but others have other components or functionality attached. | Scripts: Contains the scripts that help run and drive the game. | Sounds: Contains the sound files. | Textures: Contains the images that feed into the materials in the Materials folder. | . A final thing before we delve into creating the scene: go ahead and reset your editor layout via Window &gt; Layouts &gt; Default. Any screenshots shown (like the one above) will be using this layout and will make following along easier. This has no effect on the actual project, so if you prefer using a different layout, you are free to do so. ",
    "url": "/decal/labs/HTC%20Vive/lab1/#project-setup",
    "relUrl": "/labs/HTC%20Vive/lab1/#project-setup"
  },"102": {
    "doc": "Vive Lab 1: Building the Environment",
    "title": "Creating the Scene",
    "content": "Let’s start by creating a new scene. Right-click some empty space within the Project view and select Create &gt; Scene, and call it “Lab”. Double-click your newly created scene to open it. The first thing you’ll want to do is delete the Main Camera and Directional Light objects that come part of the scene - we’ll add our own camera and lights in a bit. Now go into the Prefabs folder and look for a prefab called “Environment”. To save you a couple hours of work, we’ve created the physical map for you. Drag the prefab into the Hierarchy view on the left side to spawn an instance of it into your scene. Scene with the environment prefab dropped in. Make sure the environment’s transform component in the Inspector view is zeroed out in position and rotation, and has a xyz-scale of 1. If your values don’t match, click the gear in the top right and hit “Reset”. You’ll notice that the lighting is off - the buildings are way too dark and shadows aren’t being cast properly. We’ll fix that, but first we’ll change the skybox (the textures that surround the scene) to something that looks more like the night sky. Go to Window &gt; Lighting &gt; Settings, which will open a new window that contains all the lighting data for this scene. Look for the “Skybox Material” line, and click the little circle on its right side. This will open up a box that lets you select which skybox to use. Search for “nightsky2” and select it. Scene with the skybox in. With our skybox in we can now properly fix our lighting. At the bottom of Lighting window, click “Generate Lighting” to start computing the proper lighting for the scene. You can also check “Auto Generate” so that any changes you make will automatically tell Unity to adjust lighting. ",
    "url": "/decal/labs/HTC%20Vive/lab1/#creating-the-scene",
    "relUrl": "/labs/HTC%20Vive/lab1/#creating-the-scene"
  },"103": {
    "doc": "Vive Lab 1: Building the Environment",
    "title": "Putting in VR Support",
    "content": "If you try pressing play now, you’ll just get a black screen telling you that no cameras are rendering. This is because we took out the Main Camera that comes with every new scene. Let’s fix that now. Go into the SteamVR/Prefabs folder to find the “SteamVR” and “CameraRig” prefabs and drag them into your hierarchy. This camera is from Steam’s SDK and connects to the display on the HTC Vive headset. Make sure its transform is also set to 0s and 1s, just like the environment prefab. There’s one final thing we need to do before we can put on the headset. Go to Edit &gt; Project Settings &gt; Player and check “Virtual Reality Supported” if it’s not already enabled. Then put on the headset and press play! . Notice how the camera automatically relates your height in physical space into Unity. This calibration is done when during the initial set-up / calibration of the HTC Vive. ",
    "url": "/decal/labs/HTC%20Vive/lab1/#putting-in-vr-support",
    "relUrl": "/labs/HTC%20Vive/lab1/#putting-in-vr-support"
  },"104": {
    "doc": "Vive Lab 1: Building the Environment",
    "title": "Adding Hands and the Stand",
    "content": "We now want to hands and the gun to our game so we can build interactivity between the two. Before adding the gun, however, we’re going to add a stand to put the gun on so that it’s within arm’s reach when you start the game. It’ll look like this. Let’s start with tracking the controllers. Fortunately, SteamVR, and more specifically the “cameraRig” prefab, have automatic tracking of the controllers. If you open the “cameraRig” game object in the hierarchy, you will be able to see 3 child objects, two of which are Controller (left) and Controller (right). These two objects have built in tracking through the script Steam_VR Tracked Object. When you press Play, you should be able to hold the controllers and see their movement translate to movement in Unity. Move the controllers and see the virtual controllers move with you. Next, let’s create the two crates that make up the stand. If you look to the left of your starting location, you’ll notice there’s already a crate there we can use. Duplicate it off twice, and move the new objects out of the Environment object so that they’re parentless - this will make it easier to select and move them. Rename one to “Lower Crate” and the other to “Upper Crate”. Use the movement (w), rotation (e), and scale (r) tools to position these crates into the shape shown in the first picture of the section. The lower crate should be just to the right of the center of CameraRig, and the upper crate should be smaller and sit on top of it. Don’t worry about being exact - just keep testing it with the headset on until the top of the upper crate is comfortably within arm’s reach. A tip: With the scale tool, dragging the white cube scales all axes. ",
    "url": "/decal/labs/HTC%20Vive/lab1/#adding-hands-and-the-stand",
    "relUrl": "/labs/HTC%20Vive/lab1/#adding-hands-and-the-stand"
  },"105": {
    "doc": "Vive Lab 1: Building the Environment",
    "title": "Adding the Gun",
    "content": "Now we can create the gun. Start by right-clicking an empty spot within the hierarchy and clicking “Create Empty”. This will create an object with nothing but a transform component, which we’ll add to and flesh out over the course of these labs. Name it “Gun”, and reset its transform - we’ll move it later. Go into the Models folder and find the object called “makarov”. This is the 3D model for our gun. Go ahead and drag it onto our newly created empty object, which will parent it under Gun. Parenting is a concept in Unity that allows us to construct complex objects out of simpler ones and have them all move together as one. An object (call it the child) parented under another object (call it the parent) will have all its transform values defined as relative to that of its parent. This means when the parent moves, scales, or rotates, its child will change along with it. Let’s rename this newly childed object to “Model”. It’ll start out being far, far too large, so scale each of its axes to 0.025. Then select its parent Gun and move it around, which should now move the 3D model around as well. Position/rotate gameobject Gun so it sits on top of the upper crate. The end result should look like this. Next, we’re going to add physics functionality to our gun, so that players can throw it if they ever want to give up in style. With Gun selected, go to the Inspector view and use the Add Component button to add a Box Collider to our object. You’ll see a green box appear around the gun. This green box is a collider. Colliders represent the bounds of an object when doing physics calculations (like collisions), and in Unity are either boxes, sphere, or capsules. Of course, a box can’t perfectly capture the bounds of a complex model like our gun, but it’ll do for the circumstances. The default size of the box collider is neither the right size or shape. Change its size values so that X = 0.03, Y = 0.15, and Z = 0.2. The result should look like this: . Now, add a Rigidbody component to Gun. Rigidbodies are what define something as a moving, physical object. It tells Unity how to treat this object in its physics calculations with variables like weight and drag. Note that an object cannot have a rigidbody component without also having a collider (since Unity needs physical bounds to perform physics calculations). Let’s test whether or not our gun is a valid physics object. Raise it up a little in the inspector, then put on the headset and press play. You should see that the gun has fallen from its original location to rest on the upper box. Actually, it hovers a little above the crate. See if you can figure out why and fix it. (optional) . This marks the end of lab 1! To check-off successfully, just let a facilitator see your current project and show them that you’ve completed all of the sections successfully. ",
    "url": "/decal/labs/HTC%20Vive/lab1/#adding-the-gun",
    "relUrl": "/labs/HTC%20Vive/lab1/#adding-the-gun"
  },"106": {
    "doc": "Vive Lab 2: Creating the Gun",
    "title": "Vive Lab 2: Creating the Gun",
    "content": " ",
    "url": "/decal/labs/HTC%20Vive/lab2/",
    "relUrl": "/labs/HTC%20Vive/lab2/"
  },"107": {
    "doc": "Vive Lab 2: Creating the Gun",
    "title": "Table of contents",
    "content": ". | Reading In Controller Input | Picking Up the Gun (Part 1) | Picking Up the Gun (Part 2) | Dropping the Gun | Firing the Gun | Sound | Animation | Visual Effect | . In this lab, we’ll focus completely on the gun. By the end of the lab, you should be able to pick up the gun, drop it, and fire it with the appropriate effects attached. How can we interact with our gun, anyway? If you hold an HTC Vive controller in your hand, you’ll notice that there are two main triggers that we can press. One is with the middle finger, called the Grip Trigger, and the other is with the index finger, called the Hair Trigger. Image Source . For our gun, we want to implement the following functionality: . | Hovering over the gun and holding down the grip trigger picks up the gun. | While picked up, pressing the hair trigger fires the gun. | When the grip trigger is released, the gun is dropped and becomes a physics object. | . You can download the skeleton for this lab here - alternatively, you can directly start working off a completed Lab 1! This is a long lab, so please don’t hesitate to ask the facilitators questions or just reach out if you get stuck. We’re here to help! . ",
    "url": "/decal/labs/HTC%20Vive/lab2/#table-of-contents",
    "relUrl": "/labs/HTC%20Vive/lab2/#table-of-contents"
  },"108": {
    "doc": "Vive Lab 2: Creating the Gun",
    "title": "Reading In Controller Input",
    "content": "The triggers on the Touch controllers are like buttons, which only have an on and off state. Because of this, input for the triggers comes as a boolean that is either true or false, where the meaning of the values depend on which function from the Steam SDK is being used. In our case, true will mean we are holding the trigger down, and false will mean the opposite. We’re going to read in this data from Steam’s SDK and store it, once per frame. Let’s start this off by creating our first script. Go into the Scripts folder, right-click an empty space within, select Create &gt; C# Script, and name it “Hand”. Double-click the file to open it (likely in Visual Studio). Unity automatically starts you out with some boilerplate code. You can delete the Start function, as we won’t be using it. We’ll put in a private variable that represents the controller this hand is attached to. It will be initialized using the Awake() function. We’ll also use a variable to store the hair trigger value of the previous frame, for reasons we’ll explain later. public class Hand : MonoBehaviour { // Reference to trackObj script. Keeps track of controllers private SteamVR_TrackedObject trackedObj; // Keeps track of controllers. Also which controller (L/R) private SteamVR_Controller.Device Controller { get { return SteamVR_Controller.Input((int)trackedObj.index); } } private bool indexTriggerState = false; private bool handTriggerState = false; private bool oldIndexTriggerState = false; void Awake() { trackedObj = GetComponent&lt;SteamVR_TrackedObject&gt; (); } ... } . The ellipses represent omitted code. The public and private keywords have the same meanings they do in other programmings languages, like Java. However, public variables can be seen and set in the Unity editor, while private ones cannot. Next, using the Update() function, every frame we’ll read controller input and store it in the variables we just defined for later use. void Update() { oldIndexTriggerState = indexTriggerState; indexTriggerState = Controller.GetHairTriggerDown (); handTriggerState = Controller.GetPressDown (SteamVR_Controller.ButtonMask.Grip); } . The magic happens in the second and third lines, where we use Steam’s API to query for controller state using the GetHairTriggerDown() and GetPressDown() functions. The parameters should be fairly intuitive, but you can get extra practice with SteamVR input with this tutorial here. Next, add the following lines to the end of the Update() function so we can later test our code. print(\"Hand-Trigger State: \" + indexTriggerState); print(\"Grip State: \" + handTriggerState); . Switch back to Unity now. We’re going to add an instance of our new Hand script to each of our hands. To do so, look for CameraRig’s children, Controller (left) and Controller (right) These represent your controllers in the game. Add the script as a component to both of them (you can use the same Add Component button to search for “Hand”). Your Inspector view for these objects should now look like this: . Finally, run your project but don’t put on the headset, and open the Console tab (next to Project). You should be able to play with the controller triggers and see the values change on the console. ",
    "url": "/decal/labs/HTC%20Vive/lab2/#reading-in-controller-input",
    "relUrl": "/labs/HTC%20Vive/lab2/#reading-in-controller-input"
  },"109": {
    "doc": "Vive Lab 2: Creating the Gun",
    "title": "Picking Up the Gun (Part 1)",
    "content": "Now that we’re successfully reading in input, let’s implement our first bit of functionality: picking up the gun. Before we do anything, we’ll add two variables to our Hand class: boolean holdingGun, which stores whether or not we’re holding a gun, and GameObject gun, which stores the gun if we’re holding one. private bool holdingGun = false; private GameObject gun = null; . There are three requirements that must be met for us to try and pick up the gun: . | Our hand must be touching/inside the gun. | We must hold down on the grip trigger for that grip’s controller . | We must not already be holding a gun. | . Let’s start with the first requirement. How can we detect whether or not our hand touching the gun? The answer is with triggers. You might remember from the roll-a-ball tutorial that triggers are a type of collider. Objects with trigger colliders do not collide with other things normally. They freely pass through them and this can be detected via code. For our purposes, we’ll attach a trigger collider to our hands, then detect collisions in script and check if the other collider is a gun. In Unity, shift-select both Controller (left) and Controller (right) so that we can edit them simultaneously. Add a Cube Collider to the front of them - they’ll represent our hands in physics calculations. Change their side lengths to 0.075 so they more accurately bound to the tip of the controllers. Switch back to Hand.cs in Visual Studio. Add the following function to the class: . void OnTriggerStay(Collider other) { } . This function automatically gets called every frame our hand touches a valid object. To delve into what counts as a “valid” object, see the chart below: . Our hand has no rigidbody (making it static) and has a trigger collider, so it counts as a Static Trigger Collider. By the chart, it’ll send trigger messages upon colliding with our gun, which is a Rigidbody Collider. So now we have a function that gets called when we touch the gun. However, this function could get called when it collides with other things as well, so we need a way to identify whether parameter other is actually the collider attached to our gun. We’ll use tags to do so. void OnTriggerStay(Collider other) { if (other.CompareTag(\"Gun\")) { } } . Now that we know we’re dealing with a gun, let’s check if requirements two and three are met. If they are, we can grab the gun! You’ll also want to comment out or delete the print statements in Update() so that your print message can be seen. void OnTriggerStay(Collider other) { if (other.CompareTag(\"Gun\")) { if (handTriggerState &amp;&amp; !holdingGun) { print(\"Grabbing gun.\"); } } } . Our code is now ready to test, but there’s one thing we need to do in Unity first: set the tag on the gun. Select your Gun object in the hierarchy, and in Inspector view go to Tag &gt; Add Tag. Press the plus button and create a new tag called “Gun”. Then select your Gun again and tag it as “Gun”. Try it out! Stick your hand into the gun and hold down the hand trigger, and check that you’re repeatedly printing out “Grabbing gun.” when you do so. ",
    "url": "/decal/labs/HTC%20Vive/lab2/#picking-up-the-gun-part-1",
    "relUrl": "/labs/HTC%20Vive/lab2/#picking-up-the-gun-part-1"
  },"110": {
    "doc": "Vive Lab 2: Creating the Gun",
    "title": "Picking Up the Gun (Part 2)",
    "content": "The next thing to do is replace that print statement with actual functionality. Let’s remove that line and instead stub in the Grab() function. void OnTriggerStay(Collider other) { if (other.CompareTag(\"Gun\")) { if (handTriggerState &amp;&amp; !holdingGun) { Grab(other.gameObject); } } } void Grab(GameObject obj) { } . other.gameObject simply returns the GameObject attached to the collider - in this case, our gun. Let’s now consider everything that needs to happen when you grab the gun. | Variables holdingGun and gun need to be updated appropriately. | The gun should be parented under our hand so that the two will move together. | The position and rotation of the gun should snap our hand’s grip. | The gun should no longer get influenced by gravity or other outside forces, so that it doesn’t get knocked out of our hand somehow. | . Item 1 and 2 are easy enough. transform by itself refers to the transform of whatever gameobject this script is attached to, which in this case is our hand. The reason we’re referring to the transform of each gameobject (as opposed to the gameobject itself) is because parenting only operates between transforms. void Grab(GameObject obj) { holdingGun = true; gun = obj; gun.transform.parent = transform; } . To do item 3, we’re going to introduce two new public Vector3 variables, holdPosition and holdRotation. Vector3s are just lists of length 3, and can hold x/y/z or yaw/pitch/roll values. These will determine the position and rotation of the gun, relative to our hand. We’ve experimentally determined these values for you already. private Vector3 holdPosition = new Vector3(0, -0.05f, -0.03f); private Vector3 holdRotation = new Vector3(-45, 180, 0); . Now we’ll use those values to position/rotate the gun properly when we grab it. void Grab(GameObject obj) { ... gun.transform.localPosition = holdPosition; gun.transform.localEulerAngles = holdRotation; } . localPosition and localEulerAngles represent the position and yaw/pitch/roll respectively of the object (the gun), relative to that of its parent (the hand). And finally, for item 4 we simply have to modify the gun’s rigidbody (which as you recall defines how our object gets influenced by physics forces). We’ll disable gravity and enable IsKinematic, which will prevent our gun from getting influenced by collisions or normal physics forces. void Grab(GameObject obj) { ... gun.GetComponent&lt;Rigidbody&gt;().useGravity = false; gun.GetComponent&lt;Rigidbody&gt;().isKinematic = true; } . Note the syntax for getting a specific component attached to an object (here the rigidbody attached to the gun). We’ll be using this a lot in the future. Go ahead and try it now! You should be able to reach over and, holding down the hand trigger on the controller, get the gun to snap to your hand. As you may have noticed, when picking up the gun, the HTC Vive controller doesn’t disappear, and as a consequence, clashes with the gun model. We don’t want that. In order to make the controller graphically disappear when we pick up the gun, add the following code to the Hand script and appropriately reference it. //Should ideally make the HTC Vive controller visible or not depending on input // @source //https://answers.unity.com/questions/1177557/hiding-steamvr-vive-controller-models.html void SetControllerVisible(GameObject controller, bool visible) { foreach (SteamVR_RenderModel model in controller.GetComponentsInChildren&lt;SteamVR_RenderModel&gt;()) { foreach (var child in model.GetComponentsInChildren&lt;MeshRenderer&gt;()) child.enabled = visible; } } void Grab(GameObject obj) { ... SetControllerVisible (this.gameObject, false); } . ",
    "url": "/decal/labs/HTC%20Vive/lab2/#picking-up-the-gun-part-2",
    "relUrl": "/labs/HTC%20Vive/lab2/#picking-up-the-gun-part-2"
  },"111": {
    "doc": "Vive Lab 2: Creating the Gun",
    "title": "Dropping the Gun",
    "content": "Now that we can pick up the gun, let’s implement the ability to release it. Unlike before, the requirements for us to drop the gun are much looser: . | We must be holding the gun. | We must release the grip trigger.. | . Since these requirements could happen at any time, we’ll put a check for it in our Update() function so it gets checked every frame and stub in Release(). We’re also going to divide the checks into separate if cases as it’ll come in handy later. void Update() { ... if (holdingGun) { if (handTriggerState) { Release (); } else { } } ... } void Release() { } . Now, what happens when you release the gun? Basically, undoing everything we did before. | The gun should be unparented from our hand so the two no longer move together. | The gun should get influenced by gravity and outside forces. | The gun should be given the same velocity that our hand had when it got released (so we can throw it). | Variables holdingGun and gun need to be updated appropriately. | After the gun is completely disconnected, we want to be able to see our controllers again. | . Item 1 is simple enough. void Release() { handTriggerState = false; gun.transform.parent = null; } . Items 2 and 3 will require the rigidbody, so we’ll turn that into its own local variable for easy access. While we’re at it, we’ll complete item 2 by reverting the flags on the rigidbody we had set before. void Release() { handTriggerState = false; gun.transform.parent = null; Rigidbody rigidbody = gun.GetComponent&lt;Rigidbody&gt;(); rigidbody.useGravity = true; rigidbody.isKinematic = false; } . To do item 3, we need to know the velocity and rotation our hand is moving the moment we release the gun. We could do this with a bit of math, but there’s an easier method: SteamVR’s SDK SteamVR_Controller.Device tracks the velocities and rotations of the physical controllers for you. We’ll take that value and assign it to our gun’s rigidbody. void Release() { ... rigidbody.velocity = Controller.velocity; rigidbody.angularVelocity = Controller.angularVelocity; } . We’ll update our variables to complete item 4. Note that setting gun to null had to be the last step; otherwise we wouldn’t have had a reference to our gun for the other items. void Release() { ... rigidbody.velocity = Controller.velocity; holdingGun = false; gun = null; } . Finally, to complete item 5, we simply add the appropriate reference to SetControllerVisible. void Release() { ... SetControllerVisible (this.gameObject, true); } . Give it a shot! You should now be able to drop or throw a held gun by simply releasing the hand trigger. Be careful not to hit anyone or anything while doing this. ",
    "url": "/decal/labs/HTC%20Vive/lab2/#dropping-the-gun",
    "relUrl": "/labs/HTC%20Vive/lab2/#dropping-the-gun"
  },"112": {
    "doc": "Vive Lab 2: Creating the Gun",
    "title": "Firing the Gun",
    "content": "We’ve finally reached the most exciting part of the lab: firing the gun. As always, let’s first consider the requirements that need to be met for the gun to fire: . | We must be holding the gun. | We must press down on the hair trigger . | But it shouldn’t constantly fire as we hold it down. | . | . We’re already checking for item 1 in Update() of Hand.cs, so we’ll move on to item 2. Since don’t want the gun to fire constantly while we hold the button down, we have to check that our hair trigger state in the previous frame was false. This will force us to release the trigger in order to fire the gun again. This is why we put in oldIndexTriggerState at the very beginning of the lab. Since oldIndexTriggerState represents the index trigger value of the previous frame, we can just check if it’s false and if indexTriggerState is greater than true. In Hand.cs, do the proper checks... private GameObject gun = null; void Update() { ... if (holdingGun) { if (handTriggerState) { Release (); } else { Gun gunScript = gun.GetComponent&lt;Gun&gt; (); gunScript.SetTriggerRotation (indexTriggerState); if (indexTriggerState &amp;&amp; !oldIndexTriggerState) { gunScript.Fire (); } } } } . And in Gun.cs, stub in the new public function Fire(): . public class Gun : MonoBehaviour { ... public void Fire() { print(\"Pew!\"); } } . If you try the project now, you should be able to print “Pew!” by pressing the index trigger. The only thing left is to replace this print statement with proper behaviour. Let’s list out all the things that need to happen when we fire the gun: . | Gunshot sound plays. | Recoil animation plays. | Gunshot explosion visual effect (VFX) plays. | . All three of these things will require use of different Unity components. ",
    "url": "/decal/labs/HTC%20Vive/lab2/#firing-the-gun",
    "relUrl": "/labs/HTC%20Vive/lab2/#firing-the-gun"
  },"113": {
    "doc": "Vive Lab 2: Creating the Gun",
    "title": "Sound",
    "content": "In Unity, add an AudioSource component to gameobject Gun. AudioSources are what play sounds in Unity. Turn off “Play On Awake” since we don’t want to hear a gunshot every time we start the game. Then assign the clip “Gunshot” to the Audio Clip field (you can either drag it in from the Sounds folder or click the circle on the right). Next in Gun.cs, create a private variable of type AudioSource called audioSource. Then in Start(), initialize that value to reference the component we just created. public class Gun : MonoBehaviour { ... AudioSource audioSource; // Use this for initialization void Start () { audioSource = GetComponent&lt;AudioSource&gt;(); } ... } . Now that we have a reference to the component, we can use it in our Fire() function. To play the clip attached to an AudioSource, call audioSource.PlayOneShot(). Unity also has a function called audioSource.Play(), but it can’t play multiple sounds simultaneously. This would be problematic as we can fire the gun faster than the length of the gunshot clip. public void Fire() { audioSource.PlayOneShot(audioSource.clip); } . Firing the gun now should give you a satisfying sound effect. ",
    "url": "/decal/labs/HTC%20Vive/lab2/#sound",
    "relUrl": "/labs/HTC%20Vive/lab2/#sound"
  },"114": {
    "doc": "Vive Lab 2: Creating the Gun",
    "title": "Animation",
    "content": "We won’t be getting into the details of animation in this class. If you wish to learn more about it, I recommend first going through some of Unity’s videos on the topic here. Instead I’ll give a quick overview of the system. If you wish to skip this part and go straight to the next instruction, just look for the next bolded sentence. On a high level, Unity’s animation system consists of two parts: controllers and motions. Motions (also called animations) are pieces of data that show how a particular object changes over time; they’re made in either Unity or some other software like Maya or 3DS Max. Controllers, on the other hand, are animation state machines; they contain the logic that dictates what animation plays when, based off of a set of external flags called parameters. Parameters are defined in the controller and can be accessed/modified via script. This is mostly how we’ll be interacting with the animation system during the labs. Take a look at the Animations folder and double-click the “Gun” controller to open up the Animator window. Note there are only two “real” states that are connected, Idle and Gun-Anim, and if you click on the Idle state you’ll see it doesn’t have a motion attached in the inspector. The Gun-Anim state does, however: the recoil animation. The green “Entry” state points to what state we start off on. Next, look at the arrow going from Idle to Gun-Anim. This is a transition, and tells us that our Gun could possibly move from the Idle to Gun-Anim state. In the inspector, you’ll see a box labeled “Conditions”. Conditions list out all the parameter requirements that need to be met for a transition to be taken. This box contains only a single parameter: “Fire”. You can view all possible parameters by clicking the word “Parameters” on the left side of the window. The open circle next to the Fire parameter indicates that parameter Fire is a trigger type parameter. When it gets set to true (via script or some other means), it’ll stay true for one frame and then automatically set itself to false again. There are other types of parameters too, such as int, float, or bool. What this means is that if our Gun is in the Idle state and we set the Fire parameter to true, it’ll move to the Gun-Anim state and start playing the motion stored there (the recoil animation). If you now click on the arrow going from Gun-Anim to Idle, you’ll notice there’s no conditions listed. Does this mean we’re stuck in the state once we get there? Not quite. The checked box “Has Exit Time” above tells Unity that when the motion in the starting state is finished, it should automatically take this arrow. So no other condition is needed to return to Idle. Let’s put all of this together now. Our gun starts off in the Idle state, and when we set parameter Fire to true, it moves to the Gun-Anim state and plays the recoil animation. Once the recoil animation is finished, it automatically moves back to the Idle state. Instruction starts again here. First off, add an Animator component to Gun’s child, Model, and set its controller to Gun (you could also just drag Gun.controller in the animations folder into Model’s inspector view). The animator must go on Model since that’s the 3D model that actually gets animated. Now in order to start the recoil animation, we need to set the “Fire” parameter in the Animator component, which we can do in code. Switch to editing Gun.cs. We’ll start off by creating a private variable that holds our animator and initializing it in Start(). Since our animator component is on Model, not Gun, we’ll need to get a reference to Model. transform.Find() looks for a specifically named object in all of the base object’s children... private AudioSource audioSource; private Animator animator; // Use this for initialization void Start () { audioSource = GetComponent&lt;AudioSource&gt;(); animator = transform.Find(\"Model\").GetComponent&lt;Animator&gt;(); } ... Then in our Fire() function, we’ll set the parameter to trigger the animation. Unity’s Animator class has a different set function for each parameter type. In this case, we’re setting a trigger type parameter so we’ll use SetTrigger() and feed it the name of the parameter we want set. public void Fire() { audioSource.PlayOneShot(audioSource.clip); animator.SetTrigger(\"Fire\"); } . Firing the gun now should play a short recoil animation. ",
    "url": "/decal/labs/HTC%20Vive/lab2/#animation",
    "relUrl": "/labs/HTC%20Vive/lab2/#animation"
  },"115": {
    "doc": "Vive Lab 2: Creating the Gun",
    "title": "Visual Effect",
    "content": "Just like with animation, Unity has its own complex system for creating and manipulating visual effects that won’t be in scope for this class. If you wish to learn more about it, I recommend starting with Unity’s video on the topic. In folder Prefabs/Particle Systems, we’ve provided a gunshot VFX for you called “MuzzleFlashEffect”. Drag it into the editor as a child of Gun. It should already be positioned correctly in front of the gun barrel (where the VFX will play). If not, change its transform to what’s shown below. All that’s left is to play the VFX here in script. Switch to editing Gun.cs. Like the previous two sections, we’ll start by creating and initializing a variable that’ll reference the Particle System... private AudioSource audioSource; private Animator animator; private ParticleSystem particleSystem; // Use this for initialization void Start () { audioSource = GetComponent&lt;AudioSource&gt;(); animator = transform.Find(\"Model\").GetComponent&lt;Animator&gt;(); particleSystem = transform.Find(\"MuzzleFlashEffect\").GetComponent&lt;ParticleSystem&gt;(); } ... Then in our function Fire() we’ll make the VFX play. public void Fire() { audioSource.PlayOneShot(audioSource.clip); animator.SetTrigger(\"Fire\"); particleSystem.Play(); } . Firing the gun should now create a spark of muzzle flash at the front of the gun. This marks the end of lab 2! To check-off successfully, let a facilitator see your current project and show them that you can pick up, drop/throw, and fire the gun properly. ",
    "url": "/decal/labs/HTC%20Vive/lab2/#visual-effect",
    "relUrl": "/labs/HTC%20Vive/lab2/#visual-effect"
  },"116": {
    "doc": "AR Foundation Lab 2: Building the Gun",
    "title": "AR Foundation Lab 2: Building the Gun",
    "content": " ",
    "url": "/decal/labs/AR%20Foundation/lab2/",
    "relUrl": "/labs/AR%20Foundation/lab2/"
  },"117": {
    "doc": "AR Foundation Lab 2: Building the Gun",
    "title": "Table of contents",
    "content": ". | Adding the Gun | Firing the Gun | Sound | Animation | Visual Effect | . In this lab, we’ll focus completely on the gun. By the end of the lab, you should be able to fire the gun by pressing on the screen, and when the gun fires, there is an animation, sound effects, and particles coming from the gun. As an extra lab, we also change the gun from being static on screen to being tracked on the back of a playing card. If you’re interested in experimenting with image tracking, we encourage you to do the extra lab as well. ",
    "url": "/decal/labs/AR%20Foundation/lab2/#table-of-contents",
    "relUrl": "/labs/AR%20Foundation/lab2/#table-of-contents"
  },"118": {
    "doc": "AR Foundation Lab 2: Building the Gun",
    "title": "Adding the Gun",
    "content": "Now we can create the gun. We want the gun to be statically on our screen as we move around our device. As such, we want the gun to be tied to the AR Camera. Start by right-clicking the AR Camera game object (under AR Session Origin) in the hierarchy and clicking “Create Empty”. This will create an object with nothing but a transform component, which we’ll add to and flesh out over the course of these labs. Rename the empty GameObject to “Gun”, and reset its transform (right click on the transform component &gt; reset) if it is not in default position - we’ll move it later. Go into the Models folder and find the object called “makarov”. This is the 3D model for our gun. Go ahead and drag it onto our newly created empty object, which will parent it under Gun. Parenting is a concept in Unity that allows us to construct complex objects out of simpler ones and have them all move together as one. An object (call it the child) parented under another object (call it the parent) will have all its transform values defined as relative to that of its parent. This means when the parent moves, scales, or rotates, its child will change along with it. Let’s rename this newly childed object to “Model”. It’ll start out being far, far too large, so we select its parent, Gun, and scale each of its axes to 0.025. We can move the Gun object around in the scene, which should now move the 3D model around as well. Position/rotate gameobject Gun so it’s about here on the game screen: . We used this transform on the “Gun” game object: . Depending on your device’s camera/screen, the best gun positioning will vary. It is also possible to script the gun object so that it is scaled in relation to the device’s view so that the gun, on any device, will be in the same position, but we are not going to bother with that in these labs. Let’s try to build the project on our device now. Do you notice anything a little off? You may notice that the camera is zoomed in and the gun is closer than it is on the Game scene in Unity. That is why we have the gun more close to the center than to the right of the screen. The “zoomed” look of the camera image might be the result of the AR Camera Manager. AR Foundation’s camera rendering applies additional image scaling so that the camera image can entirely fill the device screen. This scaling is necessary (and mathematically correct) in order to avoid image distortion due to the different aspect ratio of cameras with respect to the screen. It also avoids black side bands (i.e. letterboxing) from appearing at the top / bottom (or left/right) of the rendered image. But otherwise, the scene on your device should have the gun in it now! . ",
    "url": "/decal/labs/AR%20Foundation/lab2/#adding-the-gun",
    "relUrl": "/labs/AR%20Foundation/lab2/#adding-the-gun"
  },"119": {
    "doc": "AR Foundation Lab 2: Building the Gun",
    "title": "Firing the Gun",
    "content": "We’ve finally reached the most exciting part of the lab: firing the gun. In a future lab, we will add a button so that when the button is pressed, it will fire; but for now we will program it so that the gun fires when we tap on the screen. Create a new script called “Gun” and attach it to your Gun gameobject. We want to fire the gun every time we tap on the screen. public class Gun : MonoBehaviour { ... void Update() { if (Input.touchCount &gt; 0) { Touch touch = Input.GetTouch(0); if (touch.phase == TouchPhase.Began) { Fire(); } } } } . Now, we have to write our Fire() function. Let’s list out all the things that need to happen when we fire the gun: . | Gunshot sound plays. | Recoil animation plays. | Gunshot explosion visual effect (VFX) plays. | . All three of these things will require use of different Unity components. ",
    "url": "/decal/labs/AR%20Foundation/lab2/#firing-the-gun",
    "relUrl": "/labs/AR%20Foundation/lab2/#firing-the-gun"
  },"120": {
    "doc": "AR Foundation Lab 2: Building the Gun",
    "title": "Sound",
    "content": "In Unity, add an AudioSource component to gameobject Gun. AudioSources are what play sounds in Unity. Turn off “Play On Awake” since we don’t want to hear a gunshot every time we start the game. Then assign the clip “Gunshot” to the Audio Clip field (you can either drag it in from the Sounds folder or click the circle on the right). Next, in Gun.cs, create a private variable of type AudioSource called audioSource. Then in Start(), initialize that value to reference the component we just created. public class Gun : MonoBehaviour { ... AudioSource audioSource; // Use this for initialization void Start () { audioSource = GetComponent&lt;AudioSource&gt;(); } ... Now that we have a reference to the component, we can use it in our Fire() function. To play the clip attached to an AudioSource, call audioSource.PlayOneShot(). Unity also has a function called audioSource.Play(), but it can’t play multiple sounds simultaneously. This would be problematic as we can fire the gun faster than the length of the gunshot clip. public void Fire() { audioSource.PlayOneShot(audioSource.clip); } . We can try to build the app now. Firing the gun now should give you a satisfying sound effect. ",
    "url": "/decal/labs/AR%20Foundation/lab2/#sound",
    "relUrl": "/labs/AR%20Foundation/lab2/#sound"
  },"121": {
    "doc": "AR Foundation Lab 2: Building the Gun",
    "title": "Animation",
    "content": "We won’t be getting into the details of animation in this class. If you wish to learn more about it, I recommend first going through some of Unity’s videos on the topic here. Instead I’ll give a quick overview of the system. On a high level, Unity’s animation system consists of two parts: controllers and motions. Motions (also called animations) are pieces of data that show how a particular object changes over time; they’re made in either Unity or some other software like Maya or 3DS Max. Controllers, on the other hand, are animation state machines; they contain the logic that dictates what animation plays when, based off of a set of external flags called parameters. Parameters are defined in the controller and can be accessed/modified via script. This is mostly how we’ll be interacting with the animation system during the labs. Take a look at the Animations folder and double-click the “Gun” controller to open up the Animator window. Note there are only two “real” states that are connected, Idle and Gun-Anim, and if you click on the Idle state you’ll see it doesn’t have a motion attached in the inspector. The Gun-Anim state does, however: the recoil animation. The green “Entry” state points to what state we start off on. Next, look at the arrow going from Idle to Gun-Anim. This is a transition, and tells us that our Gun could possibly move from the Idle to Gun-Anim state. In the inspector, you’ll see a box labeled “Conditions”. Conditions list out all the parameter requirements that need to be met for a transition to be taken. This box contains only a single parameter: “Fire”. You can view all possible parameters by clicking the word “Parameters” on the left side of the window. The open circle next to the Fire parameter indicates that parameter Fire is a trigger type parameter. When it gets set to true (via script or some other means), it’ll stay true for one frame and then automatically set itself to false again. There are other types of parameters too, such as int, float, or bool. What this means is that if our Gun is in the Idle state and we set the Fire parameter to true, it’ll move to the Gun-Anim state and start playing the motion stored there (the recoil animation). If you now click on the arrow going from Gun-Anim to Idle, you’ll notice there’s no conditions listed. Does this mean we’re stuck in the state once we get there? Not quite. The checked box “Has Exit Time” above tells Unity that when the motion in the starting state is finished, it should automatically take this arrow. So no other condition is needed to return to Idle. Let’s put all of this together now. Our gun starts off in the Idle state, and when we set parameter Fire to true, it moves to the Gun-Anim state and plays the recoil animation. Once the recoil animation is finished, it automatically moves back to the Idle state. First off, add an Animator component to Gun’s child, Model, and set its controller to Gun (you could also just drag Gun.controller in the animations folder into Model’s inspector view). The animator must go on Model since that’s the 3D model that actually gets animated. Now in order to start the recoil animation, we need to set the “Fire” parameter in the Animator component, which we can do in code. Switch to editing Gun.cs. We’ll start off by creating a private variable that holds our animator and initializing it in Start(). Since our animator component is on Model, not Gun, we’ll need to get a reference to Model. transform.Find() looks for a specifically named object in all of the base object’s children... private AudioSource audioSource; private Animator animator; // Use this for initialization void Start () { audioSource = GetComponent&lt;AudioSource&gt;(); animator = transform.Find(\"Model\").GetComponent&lt;Animator&gt;(); } ... Then in our Fire() function, we’ll set the parameter to trigger the animation. Unity’s Animator class has a different set function for each parameter type. In this case, we’re setting a trigger type parameter so we’ll use SetTrigger() and feed it the name of the parameter we want set. public void Fire() { audioSource.PlayOneShot(audioSource.clip); animator.SetTrigger(\"Fire\"); } . Firing the gun now should play a short recoil animation. ",
    "url": "/decal/labs/AR%20Foundation/lab2/#animation",
    "relUrl": "/labs/AR%20Foundation/lab2/#animation"
  },"122": {
    "doc": "AR Foundation Lab 2: Building the Gun",
    "title": "Visual Effect",
    "content": "Just like with animation, Unity has its own complex system for creating and manipulating visual effects that won’t be in scope for this class. If you wish to learn more about it, I recommend starting with Unity’s video on the topic. In folder Prefabs/Particle Systems, we’ve provided a gunshot VFX for you called “MuzzleFlashEffect”. Drag it into the editor as a child of Gun. Position the MuzzleFlashEffect in front of the gun barrel (where the VFX will play). The size of the particle effect is also extremely small, so we scale the size to 50. The MuzzleFlashEffect should be around here in front of the gun barrel: . All that’s left is to play the VFX here in script. Switch to editing Gun.cs. Like the previous two sections, we’ll start by creating and initializing a variable that’ll reference the Particle System... private AudioSource audioSource; private Animator animator; private ParticleSystem particleSystem; // Use this for initialization void Start () { audioSource = GetComponent&lt;AudioSource&gt;(); animator = transform.Find(\"Model\").GetComponent&lt;Animator&gt;(); particleSystem = transform.Find(\"MuzzleFlashEffect\").GetComponent&lt;ParticleSystem&gt;(); } ... Then in our function Fire() we’ll make the VFX play. public void Fire() { audioSource.PlayOneShot(audioSource.clip); animator.SetTrigger(\"Fire\"); particleSystem.Play(); } . Firing the gun should now create a spark of muzzle flash at the front of the gun. This marks the end of lab 2! . ",
    "url": "/decal/labs/AR%20Foundation/lab2/#visual-effect",
    "relUrl": "/labs/AR%20Foundation/lab2/#visual-effect"
  },"123": {
    "doc": "Oculus Lab 2: Building the Gun",
    "title": "Oculus Lab 2: Building the Gun",
    "content": " ",
    "url": "/decal/labs/Oculus/lab2/",
    "relUrl": "/labs/Oculus/lab2/"
  },"124": {
    "doc": "Oculus Lab 2: Building the Gun",
    "title": "Table of contents",
    "content": ". | Grabbing the Gun with XR Interaction Toolkit | Firing the Gun (Part 1) | Firing the Gun (Part 2) | Sound | Animation | Visual Effect | Check Off | . In this lab, we’ll focus completely on the gun. By the end of the lab, you should be able to pick up the gun, drop it, and fire it with the appropriate effects attached. How can we interact with our gun, anyway? If you hold an Oculus controller in your hand, you’ll notice that there are two triggers that we can press. One is with the middle finger, called the Hand Trigger, and the other is with the index finger, called the Index Trigger. Pictured below is the control scheme for any Oculus Controller. For our gun, we want to implement the following functionality: . | Hovering over the gun and holding down the hand trigger / grip picks up the gun. | While picked up, the gun no longer collides with objects and follows the hand. | While picked up, pressing the index trigger fires the gun. | When the hand trigger is released, the gun is dropped and becomes a physics object. | . You can download the skeleton for this lab here - alternatively, you can directly start working off a completed Lab 1! This is a long lab, so please don’t hesitate to ask the facilitators questions or just reach out if you get stuck. We’re here to help! . After initializing the new project with the skeleton, you will need to install the XR packages again through Window &gt; Package Manager &gt; (on the top) Packages: Unity Registry: . | Oculus XR Plugin | XR Plugin Management | XR Interaction Toolkit (if not there: on the top left of the package manager, click the plus and add by name “com.unity.xr.interaction.toolkit”) | . ",
    "url": "/decal/labs/Oculus/lab2/#table-of-contents",
    "relUrl": "/labs/Oculus/lab2/#table-of-contents"
  },"125": {
    "doc": "Oculus Lab 2: Building the Gun",
    "title": "Grabbing the Gun with XR Interaction Toolkit",
    "content": "Because of the XR Interaction Toolkit package, we can easily grab objects only using the component system. First, go to the LeftHandController (XR Origin &gt; Camera Offset &gt; LeftHand Controller) and in the inspector, click Add Component, and add XR Direct Interactor with Hide Controller on Select box ticked and Sphere Collider with a radius of 0.2 and check the “Is Trigger” box. Repeat this with the RightHandController. Next, go to the Gun in the hierarchy and add the XR Grab Interactable component. Under Movement Type, select Kinematic. You can try to grab the gun with the grip buttons and feel free to move the boxes in the editor if you cannot reach it. You will immediately notice that there is a rotation problem upon grabbing the gun which prevents accurate shooting. Let’s fix that by adding an offset to the attach transform field on the gun XR Grab Interactable. Create an empty GameObject with the name “Attach Transform” with rotation values x = -10, y = -165, z = 0, and drag this child GameObject to the Attach Transform field in the XR Grab Interactable Component. Ok! Now we can grab and aim the gun correctly. Now let us implement the firing of the gun. Because there are no available The outline of this is as follows: . | A controller script to read the trigger input from any controller and call a function from the Gun. | A gun script with a function called Fire() that fires the gun. | . First, we need to define what a “trigger” is. Because we use an Action-based control scheme (this is Unity’s input handler), we need to define a “Trigger” action. To define, go to Assets &gt; XR &gt; XR Interaction Toolkit &gt; 2.1.1 &gt; Starter Assets and double-click on the XRI Default Input Actions (the lightning symbol). Now we have the “list” of actions that we can use as input. Under Action Maps, select “XRI LeftHand Interaction”. To the right Actions window, we can see that there are actions such as Select that read the button press from the corresponding inputs (this is what let us grab earlier). Click the plus on the Actions window and name it Trigger. Next, click on “\" and on the Binding Properties window, select **XR Controller &gt; XR Controller (Left Hand) &gt; Optional Controls &gt; triggerPressed** which will set this action to correspond with the controller's respective trigger button. Lastly, go back to the Trigger action and on the properties window, select Action Type as \"Button\". It should look like the image below for the left controller. Do the same for the right controller (ensure the action is for the right controller) and we now have Input Action References that correspond to trigger buttons! . Now that we can read the trigger, let’s make our first script. Go to the Scripts folder and right-click in the folder and Create &gt; C# Script with the name Hand.cs. We’ll put in a public variable that represents the controller this hand is attached to (that’ll be set in the editor). using UnityEngine; using UnityEngine.InputSystem; using UnityEngine.XR.Interaction.Toolkit; public class Hand : MonoBehaviour { [SerializeField] public InputActionReference controllerActionTrigger; void Update() { if (controllerActionTrigger.action.ReadValue&lt;float&gt;() != 0) { Debug.Log(\"Trigger from \" + this.gameObject.name.ToString()); } } } . Here, the update function reads the value from the editor-specified InputActionReference and if pressed (!=0), then print the name of the GameObject for that frame. The public and private keywords have the same meanings they do in other programming languages, like Java. However, public variables can be seen and set in the Unity editor, while private ones cannot. Now that we have this public value which we can edit in the Unity Editor, go to the Left Hand and Right Hand GameObject in the XR Origin and add the Hand script as a component. We can see a field for “Controller Action Trigger” where we can select the corresponding action reference (click the circle on the right of the field and search for “Trigger”; select the one for the corresponding controller). Press play and try pressing the triggers. Something like “Trigger from LeftHand/RightHand Controller” should be printed into the console whenever the trigger is pressed. ",
    "url": "/decal/labs/Oculus/lab2/#grabbing-the-gun-with-xr-interaction-toolkit",
    "relUrl": "/labs/Oculus/lab2/#grabbing-the-gun-with-xr-interaction-toolkit"
  },"126": {
    "doc": "Oculus Lab 2: Building the Gun",
    "title": "Firing the Gun (Part 1)",
    "content": "Now that we’re successfully reading in input, let’s implement our first bit of functionality: picking up the gun. Before we do anything, we’ll add two variables to our Hand class: XRDirectInteractor interactor which references the controller interactable in the same GameObject. We can access the gun and other variables from this interactor. // This should be after the public declaration of InputActionReference private XRDirectInteractor interactor; private void Start() { interactor = GetComponent&lt;XRDirectInteractor&gt;(); } . There are three requirements that must be met for us to try and pick up the gun: . | Our hand must be touching/inside the gun. | We must hold down on the hand trigger for that hand’s controller. | We must not already be holding a gun. | . Let’s start with the first requirement. How can we detect whether or not our hand touching the gun via script? The answer is with triggers and checking the Interactor we implemented earlier. You might remember from the roll-a-ball tutorial that triggers are a type of collider. Objects with trigger colliders do not collide with other things normally. They freely pass through them and this can be detected via code. For our purposes, we already have a trigger collider when we were setting up the grab interactable where we can detect collisions in the script and check if the other collider is a gun. Switch back to Hand.cs in Visual Studio. Add the following function to the class: . void OnTriggerStay(Collider other) { } . This function automatically gets called every frame our hand touches a valid object. To delve into what counts as a “valid” object, see the chart below: . Our hand has no rigidbody (making it static) and has a trigger collider, so it counts as a Static Trigger Collider. By the chart, it’ll send trigger messages upon colliding with our gun, which is a Rigidbody Collider. So now we have a function that gets called when we touch the gun. However, this function could get called when it collides with other things as well, so we need a way to identify whether parameter other is actually the collider attached to our gun. We’ll use tags to do so. void OnTriggerStay(Collider other) { if (other.CompareTag(\"Gun\")) { } } . Now that we know we’re dealing with a gun, let’s check if requirements two and three are met by checking if the Interactor has a grab selection (if the gun is grabbed by the interactor). If they are, we can certify we can grab the gun via a script! You might want to comment out or delete the Debug.Log statements in Update() so that your Log message can be seen clearly. void OnTriggerStay(Collider other) { if (other.CompareTag(\"Gun\")) { if (interactor.hasSelection) { print(\"Grabbing gun.\"); } } } . Our code is now ready to test, but there’s one thing we need to do in Unity first: set the tag on the gun. Select your Gun object in the hierarchy, and in the Inspector view go to Tag &gt; Add Tag. Press the plus button and create a new tag called “Gun”. Then select your Gun again and tag it as “Gun”. Try it out! Stick your hand into the gun and hold down the grab trigger, and check that you’re repeatedly printing out “Grabbing gun.” when you do so. Now with this verified via script, we can now access the exact Gun’s GameObject through the other collider passed through OnTriggerStay. Note: This exercise doesn’t actually need the OnTriggerStay since we can verify grabbing and also access the gun through the XR Interactor. We found it necessary to practice the trigger collider system since it is ubiquitous in Unity development. ",
    "url": "/decal/labs/Oculus/lab2/#firing-the-gun-part-1",
    "relUrl": "/labs/Oculus/lab2/#firing-the-gun-part-1"
  },"127": {
    "doc": "Oculus Lab 2: Building the Gun",
    "title": "Firing the Gun (Part 2)",
    "content": "We’ve finally reached the most exciting part of the lab: firing the gun. As always, let’s first consider the requirements that need to be met for the gun to fire: . | We must be holding the gun. | We must press down on the index trigger . | But it shouldn’t constantly fire as we hold it down. | . | . We’re already checking for item 1 when OnTriggerStay is called, so let us read the trigger value here. void Update() { } void OnTriggerStay(Collider other) { if (other.CompareTag(\"Gun\")) { if (interactor.hasSelection) { float trigger = controllerActionTrigger.action.ReadValue&lt;float&gt;(); Debug.Log(\"Grabbing gun.\"); Debug.Log(\"Trigger value: \" + trigger); } } } . When we press play, we can see that the trigger value can either be a 1 or a 0. Since we should not be able to hold the trigger and keep firing, we need to wait until the trigger value reaches 0 before firing again. Let’s save the trigger value for each frame to reference and overwrite in the next with a float prevTrigger: . public class Hand : MonoBehaviour { [SerializeField] public InputActionReference controllerActionTrigger; private GameObject gun = null; private XRDirectInteractor interactor; private float prevTrigger = 0f; ... void OnTriggerStay(Collider other) { if (other.CompareTag(\"Gun\")) { if (interactor.hasSelection) { float trigger = controllerActionTrigger.action.ReadValue&lt;float&gt;(); Debug.Log(\"Grabbing gun.\"); if (trigger != 0 &amp;&amp; prevTrigger == 0) { Debug.Log(\"Fire!\"); } prevTrigger = trigger; } } } . Ok we can now verify we can hold the trigger and we only fire once! . But right now, the script only calls functions inside the controller GameObject. Since we can access the Gun GameObject with the interactors, let us first make a new C# script with the name “Gun” with a single public function Fire(). using UnityEngine; public class Gun : MonoBehaviour { public void Fire() { Debug.Log(\"Pew\"); } } . To call this function from the Hand script, we need to obtain the GameObject inside OnTriggerStay. We know that the collider’s GameObject is the Gun, so: . void OnTriggerStay(Collider other) { if (other.CompareTag(\"Gun\")) { if (interactor.hasSelection) { float trigger = controllerActionTrigger.action.ReadValue&lt;float&gt;(); Debug.Log(\"Grabbing gun.\"); if (trigger != 0 &amp;&amp; prevTrigger == 0) { other.gameObject.GetComponent&lt;Gun&gt;().Fire(); } prevTrigger = trigger; } } } . If you try the project now, you should be able to print “Pew!” by pressing the index trigger. The only thing left is to replace this print statement with proper behaviour. Let’s list out all the things that need to happen when we fire the gun: . | Gunshot sound plays. | Recoil animation plays. | Gunshot explosion visual effect (VFX) plays. | . All three of these things will require use of different Unity components. ",
    "url": "/decal/labs/Oculus/lab2/#firing-the-gun-part-2",
    "relUrl": "/labs/Oculus/lab2/#firing-the-gun-part-2"
  },"128": {
    "doc": "Oculus Lab 2: Building the Gun",
    "title": "Sound",
    "content": "In Unity, add an AudioSource component to gameobject Gun. AudioSources are what play sounds in Unity. Turn off “Play On Awake” since we don’t want to hear a gunshot every time we start the game. Then assign the clip “Gunshot” to the Audio Clip field (you can either drag it in from the Sounds folder or click the circle on the right). Next in Gun.cs, create a private variable of type AudioSource called audioSource. Then in Start(), initialize that value to reference the component we just created. public class Gun : MonoBehaviour { ... AudioSource audioSource; // Use this for initialization void Start () { audioSource = GetComponent&lt;AudioSource&gt;(); } ... Now that we have a reference to the component, we can use it in our Fire() function. To play the clip attached to an AudioSource, call audioSource.PlayOneShot(). Unity also has a function called audioSource.Play(), but it can’t play multiple sounds simultaneously. This would be problematic as we can fire the gun faster than the length of the gunshot clip. public void Fire() { audioSource.PlayOneShot(audioSource.clip); } . Firing the gun now should give you a satisfying sound effect. ",
    "url": "/decal/labs/Oculus/lab2/#sound",
    "relUrl": "/labs/Oculus/lab2/#sound"
  },"129": {
    "doc": "Oculus Lab 2: Building the Gun",
    "title": "Animation",
    "content": "We won’t be getting into the details of animation in this class. If you wish to learn more about it, I recommend first going through some of Unity’s videos on the topic here. Instead I’ll give a quick overview of the system. This is optional: if you wish to skip this part and go straight to the next instruction, just look for the next bolded sentence. On a high level, Unity’s animation system consists of two parts: controllers and motions. Motions (also called animations) are pieces of data that show how a particular object changes over time; they’re made in either Unity or some other software like Maya or 3DS Max. Controllers, on the other hand, are animation state machines; they contain the logic that dictates what animation plays when, based off of a set of external flags called parameters. Parameters are defined in the controller and can be accessed/modified via script. This is mostly how we’ll be interacting with the animation system during the labs. Take a look at the Animations folder and double-click the “Gun” controller to open up the Animator window. Note there are only two “real” states that are connected, Idle and Gun-Anim, and if you click on the Idle state you’ll see it doesn’t have a motion attached in the inspector. The Gun-Anim state does, however: the recoil animation. The green “Entry” state points to what state we start off on. Next, look at the arrow going from Idle to Gun-Anim. This is a transition, and tells us that our Gun could possibly move from the Idle to Gun-Anim state. In the inspector, you’ll see a box labeled “Conditions”. Conditions list out all the parameter requirements that need to be met for a transition to be taken. This box contains only a single parameter: “Fire”. You can view all possible parameters by clicking the word “Parameters” on the left side of the window. The open circle next to the Fire parameter indicates that parameter Fire is a trigger type parameter. When it gets set to true (via script or some other means), it’ll stay true for one frame and then automatically set itself to false again. There are other types of parameters too, such as int, float, or bool. What this means is that if our Gun is in the Idle state and we set the Fire parameter to true, it’ll move to the Gun-Anim state and start playing the motion stored there (the recoil animation). If you now click on the arrow going from Gun-Anim to Idle, you’ll notice there’s no conditions listed. Does this mean we’re stuck in the state once we get there? Not quite. The checked box “Has Exit Time” above tells Unity that when the motion in the starting state is finished, it should automatically take this arrow. So no other condition is needed to return to Idle. Let’s put all of this together now. Our gun starts off in the Idle state, and when we set parameter Fire to true, it moves to the Gun-Anim state and plays the recoil animation. Once the recoil animation is finished, it automatically moves back to the Idle state. The optional section ends here. First off, add an Animator component to Gun’s child, Model, and set its controller to Gun (you could also just drag Gun.controller in the animations folder into Model’s inspector view). The animator must go on Model since that’s the 3D model that actually gets animated. Now in order to start the recoil animation, we need to set the “Fire” parameter in the Animator component, which we can do in code. Switch to editing Gun.cs. We’ll start off by creating a private variable that holds our animator and initializing it in Start(). Since our animator component is on Model, not Gun, we’ll need to get a reference to Model. transform.Find() looks for a specifically named object in all of the base object’s children... private AudioSource audioSource; private Animator animator; // Use this for initialization void Start () { audioSource = GetComponent&lt;AudioSource&gt;(); animator = transform.Find(\"Model\").GetComponent&lt;Animator&gt;(); } ... Then in our Fire() function, we’ll set the parameter to trigger the animation. Unity’s Animator class has a different set function for each parameter type. In this case, we’re setting a trigger type parameter so we’ll use SetTrigger() and feed it the name of the parameter we want set. public void Fire() { audioSource.PlayOneShot(audioSource.clip); animator.SetTrigger(“Fire”); } . Firing the gun now should play a short recoil animation. ",
    "url": "/decal/labs/Oculus/lab2/#animation",
    "relUrl": "/labs/Oculus/lab2/#animation"
  },"130": {
    "doc": "Oculus Lab 2: Building the Gun",
    "title": "Visual Effect",
    "content": "Just like with animation, Unity has its own complex system for creating and manipulating visual effects that won’t be in scope for this class. If you wish to learn more about it, I recommend starting with Unity’s video on the topic. In folder Prefabs/Particle Systems, we’ve provided a gunshot VFX for you called “MuzzleFlashEffect”. Drag it into the editor as a child of Gun. It should already be positioned correctly in front of the gun barrel (where the VFX will play). If not, change its transform to what’s shown below. All that’s left is to play the VFX here in script. Switch to editing Gun.cs. Like the previous two sections, we’ll start by creating and initializing a variable that’ll reference the Particle System... private AudioSource audioSource; private Animator animator; private ParticleSystem particleSystem; // Use this for initialization void Start () { audioSource = GetComponent&lt;AudioSource&gt;(); animator = transform.Find(\"Model\").GetComponent&lt;Animator&gt;(); particleSystem = transform.Find(\"MuzzleFlashEffect\").GetComponent&lt;ParticleSystem&gt;(); } ... Then in our function Fire() we’ll make the VFX play. public void Fire() { audioSource.PlayOneShot(audioSource.clip); animator.SetTrigger(\"Fire\"); particleSystem.Play(); } . Firing the gun should now create a spark of muzzle flash at the front of the gun. ",
    "url": "/decal/labs/Oculus/lab2/#visual-effect",
    "relUrl": "/labs/Oculus/lab2/#visual-effect"
  },"131": {
    "doc": "Oculus Lab 2: Building the Gun",
    "title": "Check Off",
    "content": "This marks the end of lab 2! To check-off successfully, let a facilitator see your current project and show them that you can pick up, drop/throw, and fire the gun properly. ",
    "url": "/decal/labs/Oculus/lab2/#check-off",
    "relUrl": "/labs/Oculus/lab2/#check-off"
  },"132": {
    "doc": "AR Foundation Lab 3: The Monster",
    "title": "AR Foundation Lab 3: The Monster",
    "content": " ",
    "url": "/decal/labs/AR%20Foundation/lab3/",
    "relUrl": "/labs/AR%20Foundation/lab3/"
  },"133": {
    "doc": "AR Foundation Lab 3: The Monster",
    "title": "Table of contents",
    "content": ". | The Monster Prefab | Creating the Navmesh | Moving the Monster | Attacking the Player | Shooting the Monster | Hurting the Monster | Killing the Monster | . In this lab, we’ll focus on the main antagonist of our game: the monster. Before we jump into it, let’s list out all the things that this monster has to do: . | Move towards the player while avoiding obstacles. | Attack the player when it’s close enough. | Die after getting shot, then disappear. | Do all of the above with appropriate animations and sounds. | . ",
    "url": "/decal/labs/AR%20Foundation/lab3/#table-of-contents",
    "relUrl": "/labs/AR%20Foundation/lab3/#table-of-contents"
  },"134": {
    "doc": "AR Foundation Lab 3: The Monster",
    "title": "The Monster Prefab",
    "content": "Open the provided Lab scene in the assets folder. Within the prefabs folder, we’ve provided a Monster prefab for you already. Double-click the environment prefab to open up the prefab and drag the monster prefab into the environment prefab hierarchy so that the monster is a child of the environment. Turn it around to face the player. As you’ll notice, the monster gameobject has two children already: hips and mesh_1. mesh_1 contains the mesh renderer that gives it the look it has, while the actual mesh itself is contained in the tree-like structure within hips, which contains the positions of all the bones in our monster’s skeletons (also called the rig). We won’t go into the 3D modeling details. If you wish to learn more, UCBUGG is a well-established and fantastically run decal on the subject. We’ll focus instead on how to use this 3D model in our project. ",
    "url": "/decal/labs/AR%20Foundation/lab3/#the-monster-prefab",
    "relUrl": "/labs/AR%20Foundation/lab3/#the-monster-prefab"
  },"135": {
    "doc": "AR Foundation Lab 3: The Monster",
    "title": "Creating the Navmesh",
    "content": "Moving our monster is a deceptively challenging task when there are obstacles in the way. There are a lot of ways to do it (if you’ve taken CS61B, you’ll remember Dijkstra’s algorithm or A* search, which can be adapted to work in this situation), but actually implementing one would be outside the scope of this course. Luckily, Unity already has a navigation infrastructure in place that we can take advantage of. What we’re going to do is build what’s called a navigation mesh, or navmesh for short. A navmesh is a map of the environment that enables supported agents, called navmesh agents, to traverse the environment. By building this map ahead of time, agents won’t have to repeatedly compute where they can and cannot go while the game is running. You can read more about Unity’s navigation system here. Unlike the VR lab we must bake the navmesh into the prefab so the navmesh will work when we place the environment down on an AR plane. Unity already has navmesh functionality but to help us we will be using the navmesh components library. https://github.com/Unity-Technologies/NavMeshComponents . This library provides us tools to work with navmeshes and even build them at runtime. Follow the instructions to clone the repo and copy the contents of Assets/NavMeshComponents into our lab project. (You can just download the file and import Assets/NavMeshComponents). Okay with the NavMeshComponents installed, open the environment prefab. (Select the environment prefab and double click on it) . To start off, we must mark the parts of the scene that our monster needs to traverse. Select the Environment object and in the top right of the inspector view, click the drop-down arrow next to the “Static” label and check “Navigation Static”. Say yes when it asks if you want to apply this to Environment’s children. This is us promising Unity that, for the purposes of navigation, we won’t be moving any of the objects within the Environment. Next, create a new gameobject in the environment prefab hierarchy named NavMesh. Add the component NavMeshSurface to this gameobject. In the inspector click on Agent Type &gt; Open Agent Settings. Navmeshes are built given certain assumptions about the agent traversing it. As you can see, Unity assumes our agent is a cylinder of certain radius and height. This will let you edit the characteristics of our agent. We’ll only change one of these settings: set Agent Radius to 0.4 to better fit our monster. In our game we will only have one type of agent running around the map. However, the navmesh supports many different agent types. You can create different agents with different heights, step heights, and abilities. For instance, you can have different agents navigate different parts of the map, lava monsters, flying characters, etc. Feel free to explore this when you make your own game! . Return to the inspector and click bake at the bottom of the NavMeshSurface component. This should build the navmesh into our prefab and you should now see a navmesh object in the prefabs folder. ",
    "url": "/decal/labs/AR%20Foundation/lab3/#creating-the-navmesh",
    "relUrl": "/labs/AR%20Foundation/lab3/#creating-the-navmesh"
  },"136": {
    "doc": "AR Foundation Lab 3: The Monster",
    "title": "Moving the Monster",
    "content": "Now that we have a navmesh, let’s turn our monster into a nav mesh agent and move it. Add a “nav mesh agent” component to our monster gameobject. This component interacts with the navmesh and allows whatever object it’s attached to to move intelligently. Change Speed to 0.75 (you don’t want the Monsters sprinting at you) and change Stopping Distance to 1.3. This indicates that once the monster gets within Stopping Distance of its target, it’ll stop moving - this will be useful once we incorporate attacks. Next, notice that we’re using the Humanoid agent type. Go to the Agents tab in the navigation window and change Radius to 0.4 to match the radius we used for the navmesh. Next, create a new script called “Monster” that we’ll use to control all functionality of the gameobject. Start off by creating and initializing variables for the player, nav mesh agent, and audio source component. Note that in order to utilize the NavMeshAgent class, we’ll have to import UnityEngine.AI. using System.Collections; using System.Collections.Generic; using UnityEngine; using UnityEngine.AI; . public class Monster : MonoBehaviour { private NavMeshAgent navMeshAgent; // Use this for initialization void Start () { navMeshAgent = GetComponent&lt;NavMeshAgent&gt;(); } // Update is called once per frame void Update () { } } . Then to get the monster moving, all we have to do is add this line to Update(), which will repeatedly set the destination of the monster to the player’s location. We use the AR Camera as the position of the player so make sure to tag the AR Camera as the MainCamera. void Update(){ Vector3 targetPos = GameObject.FindWithTag(\"MainCamera\").transform.position; navMeshAgent.SetDestination(targetPos); } . It looks a little odd to see our monster power-slide to its destination, so we’re going to add in animation support. Add an Animator component to the Monster. We’ve provided a Controller for you in Assets &gt; Animations &gt; Monster and an Avatar (the mapping between Unity’s normal bone structure and a special one) in Models &gt; Monster &gt; MonsterAvatar. Drag those into their fields. Take a look at the monster controller in the Animator window. It’s a little more complicated than the gun controller, but not by much. Notice that we start off in the “Walking” state. If you press play now, the monster should walk towards you with a lumbering walk animation. Before continuing, we’re going to add in sound support. Add an audio source component to the Monster and disable Play On Awake. Then in Monster.cs, declare/initialize it properly along with three audio clips, which we’ll use throughout the lab. Play the spawnClip in Start() to announce that this Monster has spawned. private NavMeshAgent navMeshAgent; private AudioSource audioSource; . public AudioClip spawnClip; public AudioClip hitClip; public AudioClip dieClip; . void Start () { navMeshAgent = GetComponent&lt;NavMeshAgent&gt;(); audioSource = GetComponent&lt;AudioSource&gt;(); audioSource.PlayOneShot(spawnClip); } . In Unity, you can find and fill in the appropriate clips in Assets &gt; Sounds. The spawnClip is grrr1, hitClip is hit1, and dieClip is (very surprisingly) called die. ",
    "url": "/decal/labs/AR%20Foundation/lab3/#moving-the-monster",
    "relUrl": "/labs/AR%20Foundation/lab3/#moving-the-monster"
  },"137": {
    "doc": "AR Foundation Lab 3: The Monster",
    "title": "Attacking the Player",
    "content": "The next thing we want to do is have the monster begin attacking the player once it gets in range. Looking at the monster controller again, we see that the state transitions from Walking to Attack when the “Attack” bool parameter is set to true. Let’s do just that in our Monster.cs script. We’ll need to add a check to make sure we’re in range to attack. First, add a public attackRange variable and set it to 1.3 in the editor. Then add and initialize the animator variable. public class Monster : MonoBehaviour { public float attackRange; private NavMeshAgent navMeshAgent; private AudioSource audioSource; private Animator animator; ... // Use this for initialization void Start () { navMeshAgent = GetComponent&lt;NavMeshAgent&gt;(); audioSource = GetComponent&lt;AudioSource&gt;(); audioSource.PlayOneShot(spawnClip); animator = GetComponent&lt;Animator&gt;(); } ... } . Then in update, compute the distance between the monster and the player. Since we only care about the 2D distance between the two, we’ll zero out the y component before computing the magnitude. void Update () { Vector3 targetPos = GameObject.FindWithTag(\"MainCamera\").transform.position; navMeshAgent.SetDestination(targetPos); Vector3 distanceVector = transform.position - targetPos; distanceVector.y = 0; float distance = distanceVector.magnitude; } . Use this distance to check whether or not we should transition into attacking. void Update () { ... if (distance &lt;= attackRange) { animator.SetBool(\"Attack\", true); } } . If you’d like save your work and place a monster down in the environment prefab. Build the project and the monster should walk towards you, then stop some distance away and start hitting you with its fists. Unity allows you to hook up animation events to certain points in time within an animation. These events take in a function name. When the animation plays in-game and reaches that point in time, Unity will look for that function and call it. In this case, there’s an animation event attached to the moment the monster’s fists hit the ground, with function name “Attack”. Since we don’t have a function called “Attack” yet, it raises this error. Stub in the Attack() function to fix this; we’ll just play the hitClip sound for now. public void Attack() { audioSource.PlayOneShot(hitClip); } . ",
    "url": "/decal/labs/AR%20Foundation/lab3/#attacking-the-player",
    "relUrl": "/labs/AR%20Foundation/lab3/#attacking-the-player"
  },"138": {
    "doc": "AR Foundation Lab 3: The Monster",
    "title": "Shooting the Monster",
    "content": "Now that the monster can attack us, it’s only far that we be able to fight back. On a high level, this is the procedure for shooting the monster: . | Player shoots gun. Invisible ray comes out of the gun and travels forward. | Ray hits an invisible collider on the monster, which calls a function. | Monster triggers its hurt animation, takes damage. | If monster loses all its health, kill it. | . Start by adding a capsule collider to the monster. Set the radius to 1, the height to 3, the center to 1.5, and mark it as a trigger so it doesn’t collide with the environment. It should just about encapsulate the monster. You can make the collider larger or smaller depending on how difficult you want hitting the monster to be. Next, switch to editing the Gun.cs script. We’re going to add a raycast check to Fire() to check if we’ve hit a monster. I won’t pretend to be able to explain raycasting better than Unity itself, so before looking at the code below, watch the first minute and a half of this video. Raycasts can be confusing intuitively, so don’t be afraid to ask for clarification! . public void Fire() { audioSource.PlayOneShot(audioSource.clip); animator.SetTrigger(\"Fire\"); particleSystem.Play(); RaycastHit hit; Vector3 origin = particleSystem.transform.position; Vector3 direction = particleSystem.transform.forward; if (Physics.Raycast(origin, direction, out hit, 100f)) { } } . We’re using the position/rotation of MuzzleFlashEffect (the gameobject particleSystem is attached to) for the origin of the raycast since it sits at the front of the gun where the bullet would come out of. The direction is set to “forward” direction because it’s the blue arrow in the scene view (which corresponds to the z axis) that points out of the gun barrel. We’ve defined a hit object to hold any data that comes through, and the ray itself lasts for 100 meters. The end result is that this if case returns true only if the fired raycast hit something, with whatever collider it hit stored in the “hit” variable. We’ll now check if that collider belonged to a monster. If it does, we’ll extract the Monster script from it and call an appropriate function. (If it seems like the gun is not affecting the monster. Try setting the direction to a different direction (such as particleSystem.transform.right). public void Fire() { ... if (Physics.Raycast(origin, direction, out hit, 100f)) { GameObject hitObject = hit.collider.gameObject; if (hitObject.CompareTag(\"Monster\")) { print(\"Hit a monster!\"); } } } . In Unity, assign the “Monster” tag to the monster gameobject, creating it if necessary. ",
    "url": "/decal/labs/AR%20Foundation/lab3/#shooting-the-monster",
    "relUrl": "/labs/AR%20Foundation/lab3/#shooting-the-monster"
  },"139": {
    "doc": "AR Foundation Lab 3: The Monster",
    "title": "Hurting the Monster",
    "content": "Before we start replacing the print message with proper damage-taking interaction, we need to go into details on the monster’s various gameplay states. Our monster can be in one of three states at any given point in time: . | ALIVE: In this state, the monster will move towards and attack you. | DYING: In this state, the monster has taken enough damage and is in the midst of doing its death animation. It will no longer move towards you and cannot take further damage. | SINKING: In this state, the monster has finished its death animation and is now sinking through the ground before finally getting removed from the game. | . To implement this in script, we’re going to use C#’s enum system to list the possible states and a variable to track which state we’re in. Switch to Monster.cs. public class Monster : MonoBehaviour { public enum State { ALIVE, DYING, SINKING } public State monsterState = State.ALIVE; ... } . Our monster should only be moving around if it’s in the ALIVE state. Encapsulate the code you’ve written in Update() so far in an if block checking for this. void Update () { if (monsterState == State.ALIVE) { ... } } . Next, we’re going to implement the monster’s health. Add a public int maxHealth (set that to 100 in Unity) and private int currHealth to the class. Initialize currHealth properly in Start(). Finally, stub in a public Hurt() function that we’ll be using soon. public int maxHealth; private int currHealth; . void Start () { ... currHealth = maxHealth; } ... public void Hurt(int damage) { } . Now switch back to editing Gun.cs. Add a public int damage, which will represent how much damage each bullet deals to a monster. public int damage; . Set it to 20 in Unity. Then in the raycast section, remove the print statement. In its place, extract out the monster script from the monster gameobject, and call the Hurt() function with the newly defined damage var as the parameter. RaycastHit hit; Vector3 origin = particleSystem.transform.position; Vector3 direction = particleSystem.transform.forward; if (Physics.Raycast(origin, direction, out hit, 100f)) { GameObject hitObject = hit.collider.gameObject; if (hitObject.CompareTag(\"Monster\")) { Monster monsterScript = hitObject.GetComponent&lt;Monster&gt;(); monsterScript.Hurt(damage); } } . Switch again to editing Monster.cs so we can fill out the Hurt() function. It’s fairly straightforward: we first check if the monster is still alive, and if so call the proper animation trigger (which you can view in the Monster’s animation controller. We also subtract the damage taken from its current health, and if it dips below 0 we’ll call Die(), which we’ll stub in with a print statement for now. public void Hurt(int damage) { if (monsterState == State.ALIVE) { animator.SetTrigger(\"Hurt\"); currHealth -= damage; if (currHealth &lt;= 0) Die(); } } void Die() { print(\"Monster died.\"); } . ",
    "url": "/decal/labs/AR%20Foundation/lab3/#hurting-the-monster",
    "relUrl": "/labs/AR%20Foundation/lab3/#hurting-the-monster"
  },"140": {
    "doc": "AR Foundation Lab 3: The Monster",
    "title": "Killing the Monster",
    "content": "Filling in the Die() function is fairly straightforward: . | Set the state appropriately. | Play the dying sound effect (dieClip). | Stop navigating towards the player. | Trigger the appropriate animation. void Die() { monsterState = State.DYING; audioSource.PlayOneShot(dieClip); navMeshAgent.isStopped = true; animator.SetTrigger(“Dead”); } . | . If you try the game now, you should be able to see all this happen after shooting the monster five times! You should also notice an error message in the console: . This is an animation event hooked up to the end of the death animation. If we were to just let the monster sit there forever, the corpses would end up glitching into one another and lagging the game. So we’re now going to use this animation event to make dead monsters sink through the floor and then disappear after dieing. Stub in the public StartSinking() function. public void StartSinking() { } . There are a couple things we need to do in this function: . | Set the state appropriately. | Disable the navigation component. The nav mesh agent component overrides movement control from other sources, so in order to make our monster sink through script we must disable this component first. | Set the monster to be destroyed after a set amount of time. We’ll use 5 seconds, which should be long enough for the monster to fully move through the floor. public void StartSinking() { monsterState = State.SINKING; navMeshAgent.enabled = false; Destroy(gameObject, 5); } . | . Next is to make the monster actually sink, which we’ll do in the Update() function. Add a public float sinkSpeed, which will represent how quickly the monster sinks through the ground. public float sinkSpeed; . Then in Update(), add an else if block for when our monster is in the sinking state. In it, we’ll calculate how far down the monster needs to move this frame and translate it downwards that much. Time.deltaTime returns the time between this frame and the previous. else if (monsterState == State.SINKING) { float sinkDistance = sinkSpeed * Time.deltaTime; transform.Translate(new Vector3(0, -sinkDistance, 0)); } . Set sinkSpeed to 0.15 in Unity, and give it a try! Killing the monster should now make it sink through the floor before disappearing from the scene. We’ll be building the monster spawning system in the next lab so for now you can just put a monster (or multiple) in the environment prefab. ",
    "url": "/decal/labs/AR%20Foundation/lab3/#killing-the-monster",
    "relUrl": "/labs/AR%20Foundation/lab3/#killing-the-monster"
  },"141": {
    "doc": "Vive Lab 3: The Monster",
    "title": "Vive Lab 3: The Monster",
    "content": " ",
    "url": "/decal/labs/HTC%20Vive/lab3/",
    "relUrl": "/labs/HTC%20Vive/lab3/"
  },"142": {
    "doc": "Vive Lab 3: The Monster",
    "title": "Table of contents",
    "content": ". | The Monster Prefab | Creating the Navmesh | Moving the Monster | Attacking the Player | Shooting the Monster | Hurting the Monster | Killing the Monster | . In this lab, we’ll focus on the main antagonist of our game: the monster. Before we jump into it, let’s list out all the things that this monster has to do: . Move towards the player while avoiding obstacles. Attack the player when it’s close enough. Die after getting shot, then disappear. Do all of the above with appropriate animations and sounds. You can download the skeleton assetpackage here. ",
    "url": "/decal/labs/HTC%20Vive/lab3/#table-of-contents",
    "relUrl": "/labs/HTC%20Vive/lab3/#table-of-contents"
  },"143": {
    "doc": "Vive Lab 3: The Monster",
    "title": "The Monster Prefab",
    "content": "Open the provided Lab scene in the assets folder. Within the prefabs folder, we’ve provided a Monster prefab for you already. Go ahead and drag it into the scene and turn it around to face the player. As you’ll notice, the monster gameobject has two children already: hips and mesh_1. mesh_1 contains the mesh renderer that gives it the look it has, while the actual mesh itself is contained in the tree-like structure within hips, which contains the positions of all the bones in our monster’s skeletons (also called the rig). We won’t go into the 3D modeling details. If you wish to learn more, UCBUGG is a well-established and fantastically run decal on the subject. We’ll focus instead on how to use this 3D model in our project. ",
    "url": "/decal/labs/HTC%20Vive/lab3/#the-monster-prefab",
    "relUrl": "/labs/HTC%20Vive/lab3/#the-monster-prefab"
  },"144": {
    "doc": "Vive Lab 3: The Monster",
    "title": "Creating the Navmesh",
    "content": "Moving our monster is a deceptively challenging task when there are obstacles in the way. There are a lot of ways to do it (if you’ve taken CS61B, you’ll remember Dijkstra’s algorithm or A* search, which can be adapted to work in this situation), but actually implementing one would be outside the scope of this course. Luckily, Unity already has a navigation infrastructure in place that we can take advantage of. What we’re going to do is build what’s called a navigation mesh, or navmesh for short. A navmesh is a map of the environment that enables supported agents, called navmesh agents, to traverse the environment. By building this map ahead of time, agents won’t have to repeatedly compute where they can and cannot go while the game is running. You can read more about Unity’s navigation system here. To start off, we must mark the parts of the scene that our monster needs to traverse. Select the Environment object and in the top right of the inspector view, click the drop-down arrow next to the “Static” label and check “Navigation Static”. Say yes when it asks if you want to apply this to Environment’s children. This is us promising Unity that, for the purposes of navigation, we won’t be moving any of the objects within Environment. Next, open up the navigation window via Window &gt; Navigation and click on the “Bake” tab. This tab is where we can “bake” a navmesh into the environment for later use. Navmeshes are built given certain assumptions about the agent traversing it. As you can see in the “Baked Agent Size” section, Unity assumes our agent is a cylinder of certain radius and height. We’ll only change one of these settings: set Agent Radius to 0.4 to better fit our monster. Then hit bake. You should see the map get covered in blue, representing all the traversable parts of the map. ",
    "url": "/decal/labs/HTC%20Vive/lab3/#creating-the-navmesh",
    "relUrl": "/labs/HTC%20Vive/lab3/#creating-the-navmesh"
  },"145": {
    "doc": "Vive Lab 3: The Monster",
    "title": "Moving the Monster",
    "content": "Now that we have a navmesh, let’s turn our monster into a nav mesh agent and move it. Add a “nav mesh agent” component to our monster gameobject. This component interacts with the navmesh and allows whatever object it’s attached to to move intelligently. Change Speed to 0.75 (you don’t want the Monsters sprinting at you) and change Stopping Distance to 1.3. This indicates that once the monster gets within Stopping Distance of its target, it’ll stop moving - this will be useful once we incorporate attacks. Next, notice that we’re using the Humanoid agent type. Go to the Agents tab in the navigation window and change Radius to 0.4 to match the radius we used for the navmesh. Next, create a new script called “Monster” that we’ll use to control all functionality of the gameobject. Start off by creating and initializing variables for the player, nav mesh agent, and audio source component. Note that in order to utilize the NavMeshAgent class, we’ll have to import UnityEngine.AI. using System.Collections; using System.Collections.Generic; using UnityEngine; using UnityEngine.AI; public class Monster : MonoBehaviour { public GameObject player; private NavMeshAgent navMeshAgent; // Use this for initialization void Start () { navMeshAgent = GetComponent&lt;NavMeshAgent&gt;(); } // Update is called once per frame void Update () { } } . Then to get the monster moving, all we have to do is add this line to Update(), which will repeatedly set the destination of the monster to the player’s location. void Update () { navMeshAgent.SetDestination(player.transform.position); } . In Unity, add this script to the Monster gameobject. For the player field, drag in CameraRig, which represents our headset. Press play, and you should see the monster move towards you. It looks a little odd to see our monster power-slide to its destination, so we’re going to add in animation support. Add an Animator component to the Monster. We’ve provided a Controller for you in Assets &gt; Animations &gt; Monster and an Avatar (the mapping between Unity’s normal bone structure and a special one) in Models &gt; Monster &gt; MonsterAvatar. Drag those into their fields. Take a look at the monster controller in the Animator window. It’s a little more complicated than the gun controller, but not by much. Notice that we start off in the “Walking” state. If you press play now, the monster should walk towards you with a lumbering walk animation. Before continuing, we’re going to add in sound support. Add an audio source component to the Monster and disable Play On Awake. Then in Monster.cs, declare/initialize it properly along with three audio clips, which we’ll use throughout the lab. Play the spawnClip in Start() to announce that this Monster has spawned. private NavMeshAgent navMeshAgent; private AudioSource audioSource; public AudioClip spawnClip; public AudioClip hitClip; public AudioClip dieClip; void Start () { navMeshAgent = GetComponent&lt;NavMeshAgent&gt;(); audioSource = GetComponent&lt;AudioSource&gt;(); audioSource.PlayOneShot(spawnClip); } . In Unity, you can find and fill in the appropriate clips in Assets &gt; Sounds. The spawnClip is grrr1, hitClip is hit1, and dieClip is (very surprisingly) called die. ",
    "url": "/decal/labs/HTC%20Vive/lab3/#moving-the-monster",
    "relUrl": "/labs/HTC%20Vive/lab3/#moving-the-monster"
  },"146": {
    "doc": "Vive Lab 3: The Monster",
    "title": "Attacking the Player",
    "content": "The next thing we want to do is have the monster begin attacking the player once it gets in range. Looking at the monster controller again, we see that the state transitions from Walking to Attack when the “Attack” bool parameter is set to true. Let’s do just that in our Monster.cs script. We’ll need to add a check to make sure we’re in range to attack. First, add a public attackRange variable and set it to 1.3 in the editor. Then add and initialize the animator variable. public class Monster : MonoBehaviour { public GameObject player; public float attackRange; private NavMeshAgent navMeshAgent; private AudioSource audioSource; private Animator animator; ... // Use this for initialization void Start () { navMeshAgent = GetComponent&lt;NavMeshAgent&gt;(); audioSource = GetComponent&lt;AudioSource&gt;(); audioSource.PlayOneShot(spawnClip); animator = GetComponent&lt;Animator&gt;(); } ... } . Then in update, compute the distance between the monster and the player. Since we only care about the 2D distance between the two, we’ll zero out the y component before computing the magnitude. void Update () { navMeshAgent.SetDestination(player.transform.position); Vector3 distanceVector = transform.position - player.transform.position; distanceVector.y = 0; float distance = distanceVector.magnitude; } . Use this distance to check whether or not we should transition into attacking. void Update () { ... if (distance &lt;= attackRange) { animator.SetBool(\"Attack\", true); } } . Save your work and try it in the editor. The monster should walk towards you, then stop some distance away and start hitting you with its fists. Whenever it hits you, an error should also pop up in the console: . Unity allows you to hook up animation events to certain points in time within an animation. These events take in a function name. When the animation plays in-game and reaches that point in time, Unity will look for that function and call it. In this case, there’s an animation event attached to the moment the monster’s fists hit the ground, with function name “Attack”. Since we don’t have a function called “Attack” yet, it raises this error. Stub in the Attack() function to fix this; we’ll just play the hitClip sound for now. public void Attack() { audioSource.PlayOneShot(hitClip); } . ",
    "url": "/decal/labs/HTC%20Vive/lab3/#attacking-the-player",
    "relUrl": "/labs/HTC%20Vive/lab3/#attacking-the-player"
  },"147": {
    "doc": "Vive Lab 3: The Monster",
    "title": "Shooting the Monster",
    "content": "Now that the monster can attack us, it’s only far that we be able to fight back. On a high level, this is the procedure for shooting the monster: . | Player shoots gun. Invisible ray comes out of the gun and travels forward. | Ray hits an invisible collider on the monster, which calls a function. | Monster triggers its hurt animation, takes damage. | If monster loses all its health, kill it. | . Start by adding a capsule collider to the monster. Set the radius to 1, the height to 3, the center to 1.5, and mark it as a trigger so it doesn’t collide with the environment. It should just about encapsulate the monster. Next, switch to editing the Gun.cs script. We’re going to add a raycast check to Fire() to check if we’ve hit a monster. I won’t pretend to be able to explain raycasting better than Unity itself, so before looking at the code below, watch the first minute and a half of this video. Raycasts can be confusing intuitively, so don’t be afraid to ask for clarification! . public void Fire() { audioSource.PlayOneShot(audioSource.clip); animator.SetTrigger(\"Fire\"); particleSystem.Play(); RaycastHit hit; Vector3 origin = particleSystem.transform.position; Vector3 direction = particleSystem.transform.right; if (Physics.Raycast(origin, direction, out hit, 100f)) { } } . We’re using the position/rotation of MuzzleFlashEffect (the gameobject particleSystem is attached to) for the origin of the raycast since it sits at the front of the gun where the bullet would come out of. The direction is set to its “right” direction because it’s the red arrow (which corresponds to the right direction) that points out of the gun barrel. We’ve defined a hit object to hold any data that comes through, and the ray itself lasts for 100 meters. The end result is that this if case returns true only if the fired raycast hit something, with whatever collider it hit stored in the “hit” variable. We’ll now check if that collider belonged to a monster. If it does, we’ll extract the Monster script from it and call an appropriate function. public void Fire() { ... if (Physics.Raycast(origin, direction, out hit, 100f)) { GameObject hitObject = hit.collider.gameObject; if (hitObject.CompareTag(\"Monster\")) { print(\"Hit a monster!\"); } } } . In Unity, assign the “Monster” tag to the monster gameobject, creating it if necessary. Press play, and shoot your gun at the monster. Does it trigger the print message? . ",
    "url": "/decal/labs/HTC%20Vive/lab3/#shooting-the-monster",
    "relUrl": "/labs/HTC%20Vive/lab3/#shooting-the-monster"
  },"148": {
    "doc": "Vive Lab 3: The Monster",
    "title": "Hurting the Monster",
    "content": "Before we start replacing the print message with proper damage-taking interaction, we need to go into details on the monster’s various gameplay states. Our monster can be in one of three states at any given point in time: . | ALIVE: In this state, the monster will move towards and attack you. | DYING: In this state, the monster has taken enough damage and is in the midst of doing its death animation. It will no longer move towards you and cannot take further damage. | SINKING: In this state, the monster has finished its death animation and is now sinking through the ground before finally getting removed from the game. | . To implement this in script, we’re going to use C#’s enum system to list the possible states and a variable to track which state we’re in. Switch to Monster.cs. public class Monster : MonoBehaviour { public enum State { ALIVE, DYING, SINKING } public State monsterState = State.ALIVE; ... } . Our monster should only be moving around if it’s in the ALIVE state. Encapsulate the code you’ve written in Update() so far in an if block checking for this. void Update () { if (monsterState == State.ALIVE) { ... } } . Next, we’re going to implement the monster’s health. Add a public int maxHealth (set that to 100 in Unity) and private int currHealth to the class. Initialize currHealth properly in Start(). Finally, stub in a public Hurt() function that we’ll be using soon. public int maxHealth; private int currHealth; void Start () { ... currHealth = maxHealth; } ... public void Hurt(int damage) { } . Now switch back to editing Gun.cs. Add a public int damage, which will represent how much damage each bullet deals to a monster. public int damage; . Set it to 20 in Unity. Then in the raycast section, remove the print statement. In its place, extract out the monster script from the monster gameobject, and call the Hurt() function with the newly defined damage var as the parameter. RaycastHit hit; Vector3 origin = particleSystem.transform.position; Vector3 direction = particleSystem.transform.right; if (Physics.Raycast(origin, direction, out hit, 100f)) { GameObject hitObject = hit.collider.gameObject; if (hitObject.CompareTag(\"Monster\")) { Monster monsterScript = hitObject.GetComponent&lt;Monster&gt;(); monsterScript.Hurt(damage); } } . Switch again to editing Monster.cs so we can fill out the Hurt() function. It’s fairly straightforward: we first check if the monster is still alive, and if so call the proper animation trigger (which you can view in the Monster’s animation controller. We also subtract the damage taken from its current health, and if it dips below 0 we’ll call Die(), which we’ll stub in with a print statement for now. public void Hurt(int damage) { if (monsterState == State.ALIVE) { animator.SetTrigger(\"Hurt\"); currHealth -= damage; if (currHealth &lt;= 0) Die(); } } void Die() { print(\"Monster died.\"); } . Try it out now. You should be able to shoot the Monster and trigger a small stagger animation, and after shooting it five times see the print statement. ",
    "url": "/decal/labs/HTC%20Vive/lab3/#hurting-the-monster",
    "relUrl": "/labs/HTC%20Vive/lab3/#hurting-the-monster"
  },"149": {
    "doc": "Vive Lab 3: The Monster",
    "title": "Killing the Monster",
    "content": "Filling in the Die() function is fairly straightforward: . | Set the state appropriately. | Play the dying sound effect (dieClip). | Stop navigating towards the player. | Trigger the appropriate animation. void Die() { . monsterState = State.DYING; audioSource.PlayOneShot(dieClip); navMeshAgent.isStopped = true; animator.SetTrigger(\"Dead\"); . } . | . If you try the game now, you should be able to see all this happen after shooting the monster five times! You should also notice an error message in the console: . This is an animation event hooked up to the end of the death animation. If we were to just let the monster sit there forever, the corpses would end up glitching into one another and lagging the game. So we’re now going to use this animation event to make dead monsters sink through the floor and then disappear after dieing. Stub in the public StartSinking() function. public void StartSinking() { } . There are a couple things we need to do in this function: . | Set the state appropriately. | Disable the navigation component. The nav mesh agent component overrides movement control from other sources, so in order to make our monster sink through script we must disable this component first. | Set the monster to be destroyed after a set amount of time. We’ll use 5 seconds, which should be long enough for the monster to fully move through the floor. public void StartSinking() { . monsterState = State.SINKING; navMeshAgent.enabled = false; Destroy(gameObject, 5); . } . | . Next is to make the monster actually sink, which we’ll do in the Update() function. Add a public float sinkSpeed, which will represent how quickly the monster sinks through the ground. public float sinkSpeed; . Then in Update(), add an else if block for when our monster is in the sinking state. In it, we’ll calculate how far down the monster needs to move this frame and translate it downwards that much. Time.deltaTime returns the time between this frame and the previous. else if (monsterState == State.SINKING) { float sinkDistance = sinkSpeed * Time.deltaTime; transform.Translate(new Vector3(0, -sinkDistance, 0)); } . Set sinkSpeed to 0.15 in Unity, and give it a try! Killing the monster should now make it sink through the floor before disappearing from the scene. This is the end of lab 3. To check off, show a facilitator that your monster will do the following: . | Spawn with a sound effect and move towards the player. | Stop moving when in range and begin attacking the player (with sound effect). | Stagger when shot by a gun. | Fall to the ground after taking enough damage (with sound effect) and sink through the floor before getting removed from the scene. | . ",
    "url": "/decal/labs/HTC%20Vive/lab3/#killing-the-monster",
    "relUrl": "/labs/HTC%20Vive/lab3/#killing-the-monster"
  },"150": {
    "doc": "Oculus Lab 3: The Monster",
    "title": "Oculus Lab 3: The Monster",
    "content": " ",
    "url": "/decal/labs/Oculus/lab3/",
    "relUrl": "/labs/Oculus/lab3/"
  },"151": {
    "doc": "Oculus Lab 3: The Monster",
    "title": "Table of contents",
    "content": ". | The Monster Prefab | Creating the Navmesh | Moving the Monster | Attacking the Player | Shooting the Monster | Hurting the Monster | Killing the Monster | Check Off | . In this lab, we’ll focus on the main antagonist of our game: the monster. Before we jump into it, let’s list out all the things that this monster has to do: . | Move towards the player while avoiding obstacles. | Attack the player when it’s close enough. | Die after getting shot, then disappear. | Do all of the above with appropriate animations and sounds. | . You can download the skeleton assetpackage here. After initializing the new project with the skeleton, you will need to install the XR packages again through Window &gt; Package Manager &gt; (on the top) Packages: Unity Registry: . | Oculus XR Plugin | XR Plugin Management | XR Interaction Toolkit | . ",
    "url": "/decal/labs/Oculus/lab3/#table-of-contents",
    "relUrl": "/labs/Oculus/lab3/#table-of-contents"
  },"152": {
    "doc": "Oculus Lab 3: The Monster",
    "title": "The Monster Prefab",
    "content": "Open the provided Lab scene in the assets folder. Within the prefabs folder, we’ve provided a Monster prefab for you already. Go ahead and drag it into the scene and turn it around to face the player. As you’ll notice, the monster gameobject has two children already: hips and mesh_1. mesh_1 contains the mesh renderer that gives it the look it has, while the actual mesh itself is contained in the tree-like structure within hips, which contains the positions of all the bones in our monster’s skeletons (also called the rig). We won’t go into the 3D modeling details. If you wish to learn more, UCBUGG is a well-established and fantastically run decal on the subject. We’ll focus instead on how to use this 3D model in our project. ",
    "url": "/decal/labs/Oculus/lab3/#the-monster-prefab",
    "relUrl": "/labs/Oculus/lab3/#the-monster-prefab"
  },"153": {
    "doc": "Oculus Lab 3: The Monster",
    "title": "Creating the Navmesh",
    "content": "Moving our monster is a deceptively challenging task when there are obstacles in the way. There are a lot of ways to do it (if you’ve taken CS61B, you’ll remember Dijkstra’s algorithm or A* search, which can be adapted to work in this situation), but actually implementing one would be outside the scope of this course. Luckily, Unity already has a navigation infrastructure in place that we can take advantage of. What we’re going to do is build what’s called a navigation mesh, or navmesh for short. A navmesh is a map of the environment that enables supported agents, called navmesh agents, to traverse the environment. By building this map ahead of time, agents won’t have to repeatedly compute where they can and cannot go while the game is running. You can read more about Unity’s navigation system here. Next, open up the navigation window via Window &gt; AI &gt; Navigation and click on the “Bake” tab. This tab is where we can “bake” a navmesh into the environment for later use. Navmeshes are built given certain assumptions about the agent traversing it. As you can see in the “Baked Agent Size” section, Unity assumes our agent is a cylinder of certain radius and height. We’ll only change one of these settings: set Agent Radius to 0.4 to better fit our monster. Then hit bake. You should see the map get covered in blue, representing all the traversable parts of the map. ",
    "url": "/decal/labs/Oculus/lab3/#creating-the-navmesh",
    "relUrl": "/labs/Oculus/lab3/#creating-the-navmesh"
  },"154": {
    "doc": "Oculus Lab 3: The Monster",
    "title": "Moving the Monster",
    "content": "Now that we have a navmesh, let’s turn our monster into a nav mesh agent and move it. Add a “nav mesh agent” component to our monster gameobject. This component interacts with the navmesh and allows whatever object it’s attached to to move intelligently. Change Speed to 0.75 (you don’t want the Monsters sprinting at you) and change Stopping Distance to 1.3. This indicates that once the monster gets within Stopping Distance of its target, it’ll stop moving - this will be useful once we incorporate attacks. Next, notice that we’re using the Humanoid agent type. Go to the Agents tab in the navigation window and change Radius to 0.4 to match the radius we used for the navmesh. Next, create a new script called “Monster” that we’ll use to control all functionality of the gameobject. Start off by creating and initializing variables for the player, nav mesh agent, and audio source component. Note that in order to utilize the NavMeshAgent class, we’ll have to import UnityEngine.AI. using System.Collections; using System.Collections.Generic; using UnityEngine; using UnityEngine.AI; public class Monster : MonoBehaviour { public GameObject player; private NavMeshAgent navMeshAgent; // Use this for initialization void Start () { navMeshAgent = GetComponent&lt;NavMeshAgent&gt;(); } // Update is called once per frame void Update () { } } . Then to get the monster moving, all we have to do is add this line to Update(), which will repeatedly set the destination of the monster to the player’s location. void Update () { navMeshAgent.SetDestination(player.transform.position); } . In Unity, add this script to the Monster gameobject. For the player field, drag in Main Camera which can be found under XR Origin &gt; Camera Offset, which represents our headset. Press play, and you should see the monster move towards you. It looks a little odd to see our monster power-slide to its destination, so we’re going to add in animation support. Add an Animator component to the Monster. We’ve provided a Controller for you in Assets &gt; Animations &gt; Monster and an Avatar (the mapping between Unity’s normal bone structure and a special one) in Models &gt; Monster &gt; MonsterAvatar. Drag those into their fields. Take a look at the monster controller in the Animator window. It’s a little more complicated than the gun controller, but not by much. Notice that we start off in the “Walking” state. If you press play now, the monster should walk towards you with a lumbering walk animation. Before continuing, we’re going to add in sound support. Add an audio source component to the Monster and disable Play On Awake. Then in Monster.cs, declare/initialize it properly along with three audio clips, which we’ll use throughout the lab. Play the spawnClip in Start() to announce that this Monster has spawned. private NavMeshAgent navMeshAgent; private AudioSource audioSource; public AudioClip spawnClip; public AudioClip hitClip; public AudioClip dieClip; void Start () { navMeshAgent = GetComponent&lt;NavMeshAgent&gt;(); audioSource = GetComponent&lt;AudioSource&gt;(); audioSource.PlayOneShot(spawnClip); } . In Unity, you can find and fill in the appropriate clips in Assets &gt; Sounds. The spawnClip is grrr1, hitClip is hit1, and dieClip is (very surprisingly) called die. ",
    "url": "/decal/labs/Oculus/lab3/#moving-the-monster",
    "relUrl": "/labs/Oculus/lab3/#moving-the-monster"
  },"155": {
    "doc": "Oculus Lab 3: The Monster",
    "title": "Attacking the Player",
    "content": "The next thing we want to do is have the monster begin attacking the player once it gets in range. Looking at the monster controller again, we see that the state transitions from Walking to Attack when the “Attack” bool parameter is set to true. Let’s do just that in our Monster.cs script. We’ll need to add a check to make sure we’re in range to attack. First, add a public attackRange variable and set it to 1.3 in the editor. Then add and initialize the animator variable. public class Monster : MonoBehaviour { public GameObject player; public float attackRange; private NavMeshAgent navMeshAgent; private AudioSource audioSource; private Animator animator; ... // Use this for initialization void Start () { navMeshAgent = GetComponent&lt;NavMeshAgent&gt;(); audioSource = GetComponent&lt;AudioSource&gt;(); audioSource.PlayOneShot(spawnClip); animator = GetComponent&lt;Animator&gt;(); } ... } . Then in update, compute the distance between the monster and the player. Since we only care about the 2D distance between the two, we’ll zero out the y component before computing the magnitude. void Update () { navMeshAgent.SetDestination(player.transform.position); Vector3 distanceVector = transform.position - player.transform.position; distanceVector.y = 0; float distance = distanceVector.magnitude; } . Use this distance to check whether or not we should transition into attacking. void Update () { ... if (distance &lt;= attackRange) { animator.SetBool(\"Attack\", true); } } . Save your work and try it in the editor. The monster should walk towards you, then stop some distance away and start hitting you with its fists. Whenever it hits you, an error should also pop up in the console: . Unity allows you to hook up animation events to certain points in time within an animation. These events take in a function name. When the animation plays in-game and reaches that point in time, Unity will look for that function and call it. In this case, there’s an animation event attached to the moment the monster’s fists hit the ground, with function name “Attack”. Since we don’t have a function called “Attack” yet, it raises this error. Stub in the Attack() function to fix this; we’ll just play the hitClip sound for now. public void Attack() { audioSource.PlayOneShot(hitClip); } . ",
    "url": "/decal/labs/Oculus/lab3/#attacking-the-player",
    "relUrl": "/labs/Oculus/lab3/#attacking-the-player"
  },"156": {
    "doc": "Oculus Lab 3: The Monster",
    "title": "Shooting the Monster",
    "content": "Now that the monster can attack us, it’s only fair that we are able to fight back. On a high level, this is the procedure for shooting the monster: . | Player shoots gun. Invisible ray comes out of the gun and travels forward. | Ray hits an invisible collider on the monster, which calls a function. | Monster triggers its hurt animation, takes damage. | If monster loses all its health, kill it. | . Start by adding a capsule collider to the monster. Set the radius to 1, the height to 3, the center to y=1.5, and mark it as a trigger so it doesn’t collide with the environment. It should just about encapsulate the monster. Next, switch to editing the Gun.cs script. We’re going to add a raycast check to Fire() to check if we’ve hit a monster. I won’t pretend to be able to explain raycasting better than Unity itself, so before looking at the code below, watch the first minute and a half of this video. Raycasts can be confusing intuitively, so don’t be afraid to ask for clarification! . public void Fire() { audioSource.PlayOneShot(audioSource.clip); particleSystem.Play(); RaycastHit hit; Vector3 origin = particleSystem.transform.position; Vector3 direction = particleSystem.transform.right; if (Physics.Raycast(origin, direction, out hit, 100f)) { } } . We’re using the position/rotation of MuzzleFlashEffect (the gameobject particleSystem is attached to) for the origin of the raycast since it sits at the front of the gun where the bullet would come out of. The direction is set to its “right” direction because it’s the red arrow (which corresponds to the right direction) that points out of the gun barrel. We’ve defined a hit object to hold any data that comes through, and the ray itself lasts for 100 meters. The end result is that this if case returns true only if the fired raycast hit something, with whatever collider it hit stored in the “hit” variable. We’ll now check if that collider belonged to a monster. If it does, we’ll extract the Monster script from it and call an appropriate function. public void Fire() { ... if (Physics.Raycast(origin, direction, out hit, 100f)) { GameObject hitObject = hit.collider.gameObject; if (hitObject.CompareTag(\"Monster\")) { print(\"Hit a monster!\"); } } } . In Unity, assign the “Monster” tag to the monster gameobject, creating it if necessary. Press play, and shoot your gun at the monster. Does it trigger the print message? . ",
    "url": "/decal/labs/Oculus/lab3/#shooting-the-monster",
    "relUrl": "/labs/Oculus/lab3/#shooting-the-monster"
  },"157": {
    "doc": "Oculus Lab 3: The Monster",
    "title": "Hurting the Monster",
    "content": "Before we start replacing the print message with proper damage-taking interaction, we need to go into details on the monster’s various gameplay states. Our monster can be in one of three states at any given point in time: . | ALIVE: In this state, the monster will move towards and attack you. | DYING: In this state, the monster has taken enough damage and is in the midst of doing its death animation. It will no longer move towards you and cannot take further damage. | SINKING: In this state, the monster has finished its death animation and is now sinking through the ground before finally getting removed from the game. | . To implement this in script, we’re going to use C#’s enum system to list the possible states and a variable to track which state we’re in. Switch to Monster.cs. public class Monster : MonoBehaviour { public enum State { ALIVE, DYING, SINKING } public State monsterState = State.ALIVE; ... } . Our monster should only be moving around if it’s in the ALIVE state. Encapsulate the code you’ve written in Update() so far in an if block checking for this. void Update () { if (monsterState == State.ALIVE) { } } . Next, we’re going to implement the monster’s health. Add a public int maxHealth (set that to 100 in Unity) and private int currHealth to the class. Initialize currHealth properly in Start(). Finally, stub in a public Hurt() function that we’ll be using soon. public int maxHealth; private int currHealth; void Start () { ... currHealth = maxHealth; } ... public void Hurt(int damage) { } . Now switch back to editing Gun.cs. Add a public int damage, which will represent how much damage each bullet deals to a monster. public int damage; . Set it to 20 in Unity. Then in the raycast section, remove the print statement. In its place, extract out the monster script from the monster gameobject, and call the Hurt() function with the newly defined damage var as the parameter. RaycastHit hit; Vector3 origin = particleSystem.transform.position; Vector3 direction = particleSystem.transform.right; if (Physics.Raycast(origin, direction, out hit, 100f)) { GameObject hitObject = hit.collider.gameObject; if (hitObject.CompareTag(\"Monster\")) { Monster monsterScript = hitObject.GetComponent&lt;Monster&gt;(); monsterScript.Hurt(damage); } } . Switch again to editing Monster.cs so we can fill out the Hurt() function. It’s fairly straightforward: we first check if the monster is still alive, and if so call the proper animation trigger (which you can view in the Monster’s animation controller. We also subtract the damage taken from its current health, and if it dips below 0 we’ll call Die(), which we’ll stub in with a print statement for now. public void Hurt(int damage) { if (monsterState == State.ALIVE) { animator.SetTrigger(\"Hurt\"); currHealth -= damage; if (currHealth &lt;= 0) Die(); } } void Die() { print(\"Monster died.\"); } . Try it out now. You should be able to shoot the Monster and trigger a small stagger animation, and after shooting it five times see the print statement (make sure to set Max Health to 100 in the Monster GameObject’s Monster component). ",
    "url": "/decal/labs/Oculus/lab3/#hurting-the-monster",
    "relUrl": "/labs/Oculus/lab3/#hurting-the-monster"
  },"158": {
    "doc": "Oculus Lab 3: The Monster",
    "title": "Killing the Monster",
    "content": "Filling in the Die() function is fairly straightforward: . | Set the state appropriately. | Play the dying sound effect (dieClip). | Stop navigating towards the player. | Trigger the appropriate animation. void Die() { monsterState = State.DYING; audioSource.PlayOneShot(dieClip); navMeshAgent.isStopped = true; animator.SetTrigger(“Dead”); } . | . If you try the game now, you should be able to see all this happen after shooting the monster five times! You should also notice an error message in the console: . This is an animation event hooked up to the end of the death animation. If we were to just let the monster sit there forever, the corpses would end up glitching into one another and lagging the game. So we’re now going to use this animation event to make dead monsters sink through the floor and then disappear after dieing. Stub in the public StartSinking() function. public void StartSinking() { } . There are a couple things we need to do in this function: . | Set the state appropriately. | Disable the navigation component. The nav mesh agent component overrides movement control from other sources, so in order to make our monster sink through script we must disable this component first. | Set the monster to be destroyed after a set amount of time. We’ll use 5 seconds, which should be long enough for the monster to fully move through the floor. public void StartSinking() { monsterState = State.SINKING; navMeshAgent.enabled = false; Destroy(gameObject, 5); } . | . Next is to make the monster actually sink, which we’ll do in the Update() function. Add a public float sinkSpeed, which will represent how quickly the monster sinks through the ground. public float sinkSpeed; . Then in Update(), add an else if block for when our monster is in the sinking state. In it, we’ll calculate how far down the monster needs to move this frame and translate it downwards that much. Time.deltaTime returns the time between this frame and the previous. else if (monsterState == State.SINKING) { float sinkDistance = sinkSpeed * Time.deltaTime; transform.Translate(new Vector3(0, -sinkDistance, 0)); } . Set sinkSpeed to 0.15 in Unity, and give it a try! Killing the monster should now make it sink through the floor before disappearing from the scene. ",
    "url": "/decal/labs/Oculus/lab3/#killing-the-monster",
    "relUrl": "/labs/Oculus/lab3/#killing-the-monster"
  },"159": {
    "doc": "Oculus Lab 3: The Monster",
    "title": "Check Off",
    "content": "This is the end of lab 3. To check off, show a facilitator that your monster will do the following: . | Spawn with a sound effect and move towards the player. | Stop moving when in range and begin attacking the player (with sound effect). | Stagger when shot by a gun. | Fall to the ground after taking enough damage (with sound effect) and sink through the floor before getting removed from the scene. | . ",
    "url": "/decal/labs/Oculus/lab3/#check-off",
    "relUrl": "/labs/Oculus/lab3/#check-off"
  },"160": {
    "doc": "AR Foundation Lab 4: Putting It All Together",
    "title": "AR Foundation Lab 4: Putting It All Together",
    "content": " ",
    "url": "/decal/labs/AR%20Foundation/lab4/",
    "relUrl": "/labs/AR%20Foundation/lab4/"
  },"161": {
    "doc": "AR Foundation Lab 4: Putting It All Together",
    "title": "Table of contents",
    "content": ". | Spawning Monsters | The Player | The Canvas | Main Menu | . In this lab, we’ll be taking all of the components you learned about and created thus far and put them together into a single cohesive experience. We’ll also take care of some odds and ends that we didn’t get to in the previous labs. Imagine the flow of the game, from start to finish. Here’s everything that needs to happen: . | Player can see through the camera on their device and have a working gun. Done. | Monsters start spawning periodically from preset locations and walk towards the player. We’ve done the latter, but not the former. | Players can shoot and kill monsters. Done. | Upon reaching the player, monsters will attack, causing the player to take damage. We’ve done the former, but not the latter. | Upon losing all health, the game restarts. Not done. | . ",
    "url": "/decal/labs/AR%20Foundation/lab4/#table-of-contents",
    "relUrl": "/labs/AR%20Foundation/lab4/#table-of-contents"
  },"162": {
    "doc": "AR Foundation Lab 4: Putting It All Together",
    "title": "Spawning Monsters",
    "content": "To start things off, let’s update our monster prefab so that when we spawn it via script it has all the functionality the monster in our scene has. Select the monster gameobject and click Overrides &gt; Apply All in its prefab options. If you made all the edits to the prefab directly you can skip this step. After you’ve done this, you can remove the monster within the scene - we don’t want to get assassinated the instant we start the game. Next, create a script called SpawnManager. This script will manage the spawning process for the monsters. Declare in it the following public variables and stub in the Spawn() function. public class SpawnManager : MonoBehaviour { public Transform[] spawnLocations; public float spawnTime; public GameObject monsterPrefab; ... public void Spawn() { } } . The variables are pretty self explanatory - spawnLocations will contain a list of locations (transforms) where monsters could spawn from, spawnTime is the time interval between spawns, and monsterPrefab is the gameobject that gets spawned. Let’s fill out Spawn(). Every time this function gets called, we’ll want to choose a random transform to spawn it at. We’ll instantiate the monster, then position and rotate it accordingly. public void Spawn() { Transform spawn = spawnLocations[Random.Range(0, spawnLocations.Length)]; GameObject monster = Instantiate(monsterPrefab, spawn.position, spawn.rotation); } . Random.Range(x, y) returns a random integer between x inclusive and y exclusive. As a side note, if you feed it two floats instead, it’ll return you a random float instead. Now we have to repeatedly call this function every couple seconds. While we could write a timer system in Update() using GetTime(), Unity actually has a function for this particular use case. Put the following line in the Start() function. void Start () { InvokeRepeating(\"Spawn\", spawnTime, spawnTime); } . InvokeRepeating is a Unity function that will call the function in the first argument after a certain amount of time, dictated by the second argument. It will then continue to call this function at set intervals (the third argument). In our case, Unity will call Spawn() after spawnTime seconds and continue to do so endlessly. Let’s add the SpawnManager script to our game. In the Prefabs folder, double click on the Environment prefab to open up this menu. In this, create a new empty gameobject called “ScriptManager”, and attach this script to it. Set Spawn Time to 5 and set the monster prefab correctly. To fill in Spawn Locations, we’re going to create empty gameobjects (which contain only transforms) and position them around the map where we want monsters to spawn. But where do we want to spawn them? The locations should be out of the player’s sight, so that we can’t see them pop into existence. They also have to be on the nav mesh, otherwise the spawned monster wouldn’t be able to navigate properly. To make sure we’re meeting these requirements, open up the navigation window, which should cause the blue navmesh to appear. Create a couple empty gameobjects and call them Spawn (you can number them if you wish). Position them around the map such that they’re on the navmesh and out of the player’s line of sight. Once you’re satisfied with your spawns, select ScriptManager and drag the spawns onto the Spawn Locations array to add to the list. Give it a shot! Starting the game now should cause a monster to spawn once every 5 seconds. ",
    "url": "/decal/labs/AR%20Foundation/lab4/#spawning-monsters",
    "relUrl": "/labs/AR%20Foundation/lab4/#spawning-monsters"
  },"163": {
    "doc": "AR Foundation Lab 4: Putting It All Together",
    "title": "The Player",
    "content": "We’re now going to create a script to deal with player specific logic. Create and begin editing a new script called “Player”. Similar to the monster, we’ll want to track the player’s state (either alive or dead) with enums and also store the player’s health. public enum State { ALIVE, DEAD } public State playerState = State.ALIVE; public int maxHealth; private int health; void Start () { health = maxHealth; } . There’s only one interaction we haven’t implemented yet for the player: getting hurt by monsters. Stub in the public Hurt() function. public void Hurt(int damage) { } . This function is nearly identical to the Hurt() function in Monster.cs. Fill it out and stub in a Die() function as well. public void Hurt(int damage) { if (playerState == State.ALIVE) { health -= damage; if (health &lt;= 0) { Die(); } } } void Die() { } . What happens when the player dies? There’s a lot of things we could do, but for simplicity we’ll just restart the level. Unity gives you the ability to load up a new scene in its library UnityEngine.SceneManagement, so import it at the top of the file. Then add a line in Die() to reload the scene. using UnityEngine.SceneManagement; . In Unity, add the player script to your ScriptManager gameobject and set Max Health to 100. All that’s left is to call Hurt() whenever the player gets attacked by a monster. Switch to editing Monster.cs, and in it declare a damage variable and a reference to the Player script you just wrote. public int damage; . Finally, modify the Attack() function (and potentially other parts of the code) so that it calls Hurt() appropriately to damage the player. We have left implementing this final part as an exercise to the reader. Again, here are some tips: . | For monsters to be able to hurt the player, there needs to be some link between the monster script on on a spawned monster and the player script in the scene that you just added. | Remember that all components are scripts and vice-versa, from the ones default to Unity like Rigidbody or AudioSource, to the ones you created and added to a gameobject yourself. | . Try it out! When monsters attack you up to 5 times now, the scene should restart (indicating that you’ve lost). ",
    "url": "/decal/labs/AR%20Foundation/lab4/#the-player",
    "relUrl": "/labs/AR%20Foundation/lab4/#the-player"
  },"164": {
    "doc": "AR Foundation Lab 4: Putting It All Together",
    "title": "The Canvas",
    "content": "By now you might be wondering about how to add UI to your game. Fortunately, Unity provides us the Canvas system that can handle UI interactions apart from the game. You can read more about it here. Create a canvas (right click hierarchy &gt; UI &gt; Canvas). First adjust the canvas scaler to Scale with Screen Size. Now add a button for firing the gun. (right click hierarchy &gt; UI &gt; Button) Move the button to the bottom right and anchor it to the corner. Adjust the button size to your liking and change the text to Fire (adjust the font size too). Also make the background for the button transparent. Now let’s link the button to the fire function of the gun. Drag the gun object from under AR Camera to the onclick function of button. Choose the Fire function from the gun. Also, remove the update function from Gun.cs so only clicking the fire button with fire the gun. ",
    "url": "/decal/labs/AR%20Foundation/lab4/#the-canvas",
    "relUrl": "/labs/AR%20Foundation/lab4/#the-canvas"
  },"165": {
    "doc": "AR Foundation Lab 4: Putting It All Together",
    "title": "Main Menu",
    "content": "Most games have some sort of main menu so we’ll also make a rudimentary one to get the concept. We will take the following steps to make this work. | Create a new scene called MainMenu | Make a start button to enter the game | Make a back button to return to the main menu | Return to the main menu when the player dies | . Start by creating a new Scene in the scenes folder. Create a canvas and place a Start button in the center. Feel free to customize the size, font, color, etc to you liking. You can also set the background of the scene to a solid color if you do not want the skybox as the background for your menu. To change the background, select the main camera and change clear flags from skybox to solid color, then change the color. Next, make a new script called SceneSelect and create a StartButtonPressed() function. Fill in the function to load the “lab” scene when called. We won’t provide the code for this since you can figure it out by now (hint: look at SceneManager documentation) . We created a new MenuManager gameobject undercanvas to attach this script to and link with the Start button. There are other ways to do it, so on your own link the new script you created to the start button. You should now be greeted with your MainMenu and clicking Start should launch the game! . Okay two more things to fix. | We should make a back button in the game to return to the main menu . | Return to the main menu once you die. | . For the back button, create a script called BackButton.cs. public class BackButton : MonoBehaviour { [SerializeField] GameObject m_BackButton; public GameObject backButton { get { return m_BackButton; } set { m_BackButton = value; } } void Start() { if (Application.CanStreamedLevelBeLoaded(\"MainMenu\")) { m_BackButton.SetActive(true); } } public void BackButtonPressed() { // YOUR CODE HERE (launch the main menu) } } . Now in the lab scene create a BackButtonManager gameobject under the canvas hierarchy. Create a button as a child of the BackButtonManager. (ignore the RuntimeHierarchy and RuntimeInspector) . Attach your BackButton script to the BackButtonManager and link the two together. Link the button with the script and link the button to the function. Lastly, make it so you return to the main menu when the player dies. (where did we code this in?) . Congratulations, you have completed the basic lab! You have also learned to use the canvas system in Unity and make UI elements for you game. ",
    "url": "/decal/labs/AR%20Foundation/lab4/#main-menu",
    "relUrl": "/labs/AR%20Foundation/lab4/#main-menu"
  },"166": {
    "doc": "Vive Lab 4: Putting It All Together",
    "title": "Vive Lab 4: Putting It All Together",
    "content": " ",
    "url": "/decal/labs/HTC%20Vive/lab4/",
    "relUrl": "/labs/HTC%20Vive/lab4/"
  },"167": {
    "doc": "Vive Lab 4: Putting It All Together",
    "title": "Table of contents",
    "content": ". | Spawning Monsters . | Debugging Exercise | . | The Player | Final Remarks | . In the final lab of this series, we’ll be taking all of the components you learned about and created thus far and put them together into a single cohesive experience. We’ll also take care of some odds and ends that we didn’t get to in the previous labs. Imagine the flow of the game, from initialization to finish. Here’s everything that needs to happen: . | Player puts on the headset and picks up the gun. Done. | Monsters start spawning periodically from preset locations and walk towards the player. We’ve done the latter, but not the former. | Players can shoot and kill monsters. Done. | Upon reaching the player, monsters will attack, causing the player to take damage. We’ve done the former, but not the latter. | Upon losing all health, the game restarts. Not done. | . You can download the skeleton package here. Important: Certain parts of this lab have been left without explicit instruction. This is on purpose, and those parts must be completed in order to finish the lab. ",
    "url": "/decal/labs/HTC%20Vive/lab4/#table-of-contents",
    "relUrl": "/labs/HTC%20Vive/lab4/#table-of-contents"
  },"168": {
    "doc": "Vive Lab 4: Putting It All Together",
    "title": "Spawning Monsters",
    "content": "To start things off, let’s update our monster prefab so that when we spawn it via script it has all the functionality the monster in our scene has. Select the monster gameobject and click Apply in its prefab options. After you’ve done this, you can remove the monster within the scene - we don’t want to get assassinated the instant we start the game. Next, create a script called SpawnManager. This script will manage the spawning process for the monsters. Declare in it the following public variables and stub in the Spawn() function. public class SpawnManager : MonoBehaviour { public Transform[] spawnLocations; public float spawnTime; public GameObject monsterPrefab; ... public void Spawn() { } } . The variables are pretty self explanatory - spawnLocations will contain a list of locations (transforms) where monsters could spawn from, spawnTime is the time interval between spawns, and monsterPrefab is the gameobject that gets spawned. Let’s fill out Spawn(). Every time this function gets called, we’ll want to choose a random transform to spawn it at. We’ll instantiate the monster, then position and rotate it accordingly. public void Spawn() { Transform spawn = spawnLocations[Random.Range(0, spawnLocations.Length)]; GameObject monster = Instantiate(monsterPrefab, spawn.position, spawn.rotation); } . Random.Range(x, y) returns a random integer between x inclusive and y exclusive. As a side note, if you feed it two floats instead, it’ll return you a random float instead. Now we have to repeatedly call this function every couple seconds. While we could write a timer system in Update() using GetTime(), Unity actually has a function for this particular use case. Put the following line in the Start() function. void Start () { InvokeRepeating(\"Spawn\", spawnTime, spawnTime); } . InvokeRepeating is a Unity function that will call the function in the first argument after a certain amount of time, dictated by the second argument. It will then continue to call this function at set intervals (the third argument). In our case, Unity will call Spawn() after spawnTime seconds and continue to do so endlessly. Let’s add the SpawnManager script to our game. Create a new empty gameobject called “SpawnManager”, and attach this script to it. Set Spawn Time to 5 and set the monster prefab correctly. To fill in Spawn Locations, we’re going to create empty gameobjects (which contain only transforms) and position them around the map where we want monsters to spawn. But where do we want to spawn them? The locations should be out of the player’s sight, so that they can’t see them pop into existence. They also have to be on the nav mesh, otherwise the spawned monster wouldn’t be able to navigate properly. To make sure we’re meeting these requirements, open up the navigation window, which should cause the blue navmesh to appear. Create a couple empty gameobjects and call them Spawn (you can number them if you wish). Position them around the map such that they’re on the navmesh and out of the player’s line of sight. Once you’re satisfied with your spawns, select SpawnManager and drag the spawns onto the Spawn Locations array to add to the list. Give it a shot! Starting the game now should cause a monster to spawn once every 5 seconds, and… walk in place. Time for an exercise in debugging. ",
    "url": "/decal/labs/HTC%20Vive/lab4/#spawning-monsters",
    "relUrl": "/labs/HTC%20Vive/lab4/#spawning-monsters"
  },"169": {
    "doc": "Vive Lab 4: Putting It All Together",
    "title": "Debugging Exercise",
    "content": "Before continuing on with the lab, figure out why the monsters are walking in place and fix it so that the newly spawned monsters successfully navigate the environment and walk towards you after spawning. You might want to refer back to lab 4 for implementation details. If you’re feeling lost, we’ve listed some tips below that might help. | Recall what you did during the last lab to make the monsters move. Since the monsters are playing their walk animation, it means they’re trying to move, but don’t know where to go. For what reason might this happen? . | Start the game, then switch back to scene view and select one of the monsters to view it in the inspector. Are any of the properties incorrect? . | Once you’ve isolated the cause, try to figure out why it’s happening (since your monster was working fine in the previous lab). What’s the difference between spawning a new monster from a prefab and having it in your scene in the first place? . | Finally, once you understand the problem, come up with a solution to fix it. Remember that all public properties can be viewed and modified from any script. | . Hint: Prefabs cannot access any gameobjects from a specific scene. This is because prefabs have to work across all scenes, and even across different projects. For that reason, they cannot use anything that’s tied to a single scene. ",
    "url": "/decal/labs/HTC%20Vive/lab4/#debugging-exercise",
    "relUrl": "/labs/HTC%20Vive/lab4/#debugging-exercise"
  },"170": {
    "doc": "Vive Lab 4: Putting It All Together",
    "title": "The Player",
    "content": "We’re now going to create a script to deal with player specific logic. Create and begin editing a new script called “Player”. Similar to the monster, we’ll want to track the player’s state (either alive or dead) with enums and also store the player’s health. public enum State { ALIVE, DEAD } public State playerState = State.ALIVE; public int maxHealth; private int health; void Start () { health = maxHealth; } . There’s only one interaction we haven’t implemented yet for the player: getting hurt by monsters. Stub in the public Hurt() function. public void Hurt(int damage) { } . This function is nearly identical to the Hurt() function in Monster.cs. Fill it out and stub in a Die() function as well. public void Hurt(int damage) { if (playerState == State.ALIVE) { health -= damage; if (health &lt;= 0) { Die(); } } } void Die() { } . What happens when the player dies? There’s a lot of things we could do, but for simplicity we’ll just restart the level. Unity gives you the ability to load up a new scene in its library UnityEngine.SceneManagement, so import it at the top of the file. using UnityEngine.SceneManagement; . Then in Die(), tell Unity to load up a new scene. We called our scene “Lab”, but make sure to feed in whatever you called your scene file. void Die() { SceneManager.LoadScene(\"Lab\"); } . In Unity, add the player script to your ScriptManager gameobject and set Max Health to 100. All that’s left is to call Hurt() whenever the player gets attacked by a monster. Switch to editing Monster.cs, and in it declare a damage variable and a reference to the Player script you just wrote. public int damage; . Finally, modify the Attack() function so that it calls Hurt() appropriately to damage the player. As with the debugging exercise earlier, we will leave the implementation open-ended. Again, here are some tips: . | We now have two things called “player” in our project. The first one, “player” is a property you defined in Monster.cs during the previous lab and represents an item that gives us the location of the player (CameraRig). The second is Player.cs is the script that you just created. Don’t get mixed up between the two. | For monsters to be able to hurt the player, there needs to be some link between the monster script on on a spawned monster and the player script in the scene that you just added. | Remember that all components are scripts and vice-versa, from the ones default to Unity like Rigidbody or AudioSource, to the ones you created and added to a gameobject yourself. | . Try it out! When monsters attack you up to 5 times now, the scene should restart (indicating that you’ve lost). ",
    "url": "/decal/labs/HTC%20Vive/lab4/#the-player",
    "relUrl": "/labs/HTC%20Vive/lab4/#the-player"
  },"171": {
    "doc": "Vive Lab 4: Putting It All Together",
    "title": "Final Remarks",
    "content": "Congratulations! You now have a fully implemented game that you’ve created for the HTC Vive. There are a ton of things that could be added and improved, of course, such as moving the trigger of the gun or and adding screen effects to the camera (for the curious, that’s what the Flash script is for). We hope that this lab series gave you enough knowledge and familiarity with Unity/HTC Vive to improve or kickstart your own projects. To check off, show a facilitator that the entire game works - that you can operate the gun, that monsters spawn and move towards you, that you can defeat monsters, and that they can defeat you. ",
    "url": "/decal/labs/HTC%20Vive/lab4/#final-remarks",
    "relUrl": "/labs/HTC%20Vive/lab4/#final-remarks"
  },"172": {
    "doc": "Oculus Lab 4: Putting It All Together",
    "title": "Oculus Lab 4: Putting It All Together",
    "content": " ",
    "url": "/decal/labs/Oculus/lab4/",
    "relUrl": "/labs/Oculus/lab4/"
  },"173": {
    "doc": "Oculus Lab 4: Putting It All Together",
    "title": "Table of contents",
    "content": ". | Spawning Monsters . | Debugging Exercise | . | The Player | Final Remarks | Check Off | . In the final lab of this series, we’ll be taking all of the components you learned about and created thus far and put them together into a single cohesive experience. We’ll also take care of some odds and ends that we didn’t get to in the previous labs. Imagine the flow of the game, from start to finish. Here’s everything that needs to happen: . | Player puts on the headset and picks up the gun. Done. | Monsters start spawning periodically from preset locations and walk towards the player. We’ve done the latter, but not the former. | Players can shoot and kill monsters. Done. | Upon reaching the player, monsters will attack, causing the player to take damage. We’ve done the former, but not the latter. | Upon losing all health, the game restarts. Not done. | . You can download the skeleton package here. Important: Certain parts of this lab have been left without explicit instruction. This is on purpose, and those parts must be completed in order to finish the lab. After initializing the new project with the skeleton, you will need to install the XR packages again through Window &gt; Package Manager &gt; (on the top) Packages: Unity Registry: . | Oculus XR Plugin | XR Plugin Management | XR Interaction Toolkit | . ",
    "url": "/decal/labs/Oculus/lab4/#table-of-contents",
    "relUrl": "/labs/Oculus/lab4/#table-of-contents"
  },"174": {
    "doc": "Oculus Lab 4: Putting It All Together",
    "title": "Spawning Monsters",
    "content": "To start things off, let’s update our monster prefab so that when we spawn it via script it has all the functionality the monster in our scene has. Select the monster gameobject and click Overrides &gt; Apply All in its prefab options. After you’ve done this, you can remove the monster within the scene - we don’t want to get assassinated the instant we start the game. Next, create a script called SpawnManager. This script will manage the spawning process for the monsters. Declare in it the following public variables and stub in the Spawn() function. public class SpawnManager : MonoBehaviour { public Transform[] spawnLocations; public float spawnTime; public GameObject monsterPrefab; ... public void Spawn() { } } . The variables are pretty self explanatory - spawnLocations will contain a list of locations (transforms) where monsters could spawn from, spawnTime is the time interval between spawns, and monsterPrefab is the gameobject that gets spawned. Let’s fill out Spawn(). Every time this function gets called, we’ll want to choose a random transform to spawn it at. We’ll instantiate the monster, then position and rotate it accordingly. public void Spawn() { Transform spawn = spawnLocations[Random.Range(0, spawnLocations.Length)]; GameObject monster = Instantiate(monsterPrefab, spawn.position, spawn.rotation); } . Random.Range(x, y) returns a random integer between x inclusive and y exclusive. As a side note, if you feed it two floats instead, it’ll return you a random float instead. Now we have to repeatedly call this function every couple seconds. While we could write a timer system in Update() using GetTime(), Unity actually has a function for this particular use case. Put the following line in the Start() function. void Start () { InvokeRepeating(\"Spawn\", spawnTime, spawnTime); } . InvokeRepeating is a Unity function that will call the function in the first argument after a certain amount of time, dictated by the second argument. It will then continue to call this function at set intervals (the third argument). In our case, Unity will call Spawn() after spawnTime seconds and continue to do so endlessly. Let’s add the SpawnManager script to our game. Create a new empty gameobject called “ScriptManager”, and attach this script to it. Set Spawn Time to 5 and set the monster prefab correctly. To fill in Spawn Locations, we’re going to create empty gameobjects (which contain only transforms) and position them around the map where we want monsters to spawn. But where do we want to spawn them? The locations should be out of the player’s sight, so that they can’t see them pop into existence. They also have to be on the nav mesh, otherwise the spawned monster wouldn’t be able to navigate properly. To make sure we’re meeting these requirements, open up the navigation window, which should cause the blue navmesh to appear. Create a couple empty gameobjects and call them Spawn (you can number them if you wish). Position them around the map such that they’re on the navmesh and out of the player’s line of sight. Once you’re satisfied with your spawns, select ScriptManager and drag the spawns onto the Spawn Locations array to add to the list. Give it a shot! Starting the game now should cause a monster to spawn once every 5 seconds, and… walk in place. We have left fixing this bug as an exercise for the reader (see the next section). ",
    "url": "/decal/labs/Oculus/lab4/#spawning-monsters",
    "relUrl": "/labs/Oculus/lab4/#spawning-monsters"
  },"175": {
    "doc": "Oculus Lab 4: Putting It All Together",
    "title": "Debugging Exercise",
    "content": "Before continuing on with the lab, figure out why the monsters are walking in place and fix it so that the newly spawned monsters successfully navigate the environment and walk towards you after spawning. If you’re feeling lost, we’ve listed some tips below that might help. | Recall what you did during the last lab to make the monsters move. Since the monsters are playing their walk animation, it means they’re trying to move, but don’t know where to go. For what reason might this happen? | Start the game, then switch back to scene view and select one of the monsters to view it in the inspector. Are any of the properties incorrect? | Once you’ve isolated the cause, try to figure out why it’s happening (since your monster was working fine in the previous lab). What’s the difference between spawning a new monster from a prefab and having it in your scene in the first place? | Finally, once you understand the problem, come up with a solution to fix it. Remember that all public properties can be viewed and modified from any script. | . Hint: Prefabs cannot access any gameobjects from a specific scene. This is because prefabs have to work across all scenes, and even across different projects. For that reason, they cannot use anything that’s tied to a single scene. ",
    "url": "/decal/labs/Oculus/lab4/#debugging-exercise",
    "relUrl": "/labs/Oculus/lab4/#debugging-exercise"
  },"176": {
    "doc": "Oculus Lab 4: Putting It All Together",
    "title": "The Player",
    "content": "We’re now going to create a script to deal with player specific logic. Create and begin editing a new script called “Player”. Similar to the monster, we’ll want to track the player’s state (either alive or dead) with enums and also store the player’s health. public enum State { ALIVE, DEAD } public State playerState = State.ALIVE; public int maxHealth; private int health; void Start () { health = maxHealth; } . There’s only one interaction we haven’t implemented yet for the player: getting hurt by monsters. Stub in the public Hurt() function. public void Hurt(int damage) { } . This function is nearly identical to the Hurt() function in Monster.cs. Fill it out and stub in a Die() function as well. public void Hurt(int damage) { if (playerState == State.ALIVE) { health -= damage; if (health &lt;= 0) { Die(); } } } void Die() { } . What happens when the player dies? There’s a lot of things we could do, but for simplicity we’ll just restart the level. Unity gives you the ability to load up a new scene in its library UnityEngine.SceneManagement, so import it at the top of the file. using UnityEngine.SceneManagement; . In Unity, add the player script to your ScriptManager gameobject and set Max Health to 100. All that’s left is to call Hurt() whenever the player gets attacked by a monster. Switch to editing Monster.cs, and in it declare a damage variable and a reference to the Player script you just wrote. public int damage; . Finally, modify the Attack() function (and potentially other parts of the code) so that it calls Hurt() appropriately to damage the player. Like with the debugging exercise earlier, we have left implementing this final part as an exercise to the reader. Again, here are some tips: . | We now have two things called “player” in our project. The first one, “player” is a property you defined in Monster.cs during the previous lab and represents an item that gives us the location of the player (CenterEyeAnchor). The second is Player.cs is the script that you just created. Don’t get mixed up between the two. | For monsters to be able to hurt the player, there needs to be some link between the monster script on on a spawned monster and the player script in the scene that you just added. | Remember that all components are scripts and vice-versa, from the ones default to Unity like Rigidbody or AudioSource, to the ones you created and added to a gameobject yourself. | . Try it out! When monsters attack you up to 5 times now, the scene should restart (indicating that you’ve lost). ",
    "url": "/decal/labs/Oculus/lab4/#the-player",
    "relUrl": "/labs/Oculus/lab4/#the-player"
  },"177": {
    "doc": "Oculus Lab 4: Putting It All Together",
    "title": "Final Remarks",
    "content": "Congratulations! You now have a fully implemented game that you’ve created for the Oculus Rift. There are a ton of things that could be added and improved, of course, such as moving the trigger of the gun or and adding screen effects to the camera (for the curious, that’s what the Flash script is for). We hope that this lab series gave you enough knowledge and familiarity with Unity/Oculus to kickstart your own final projects. ",
    "url": "/decal/labs/Oculus/lab4/#final-remarks",
    "relUrl": "/labs/Oculus/lab4/#final-remarks"
  },"178": {
    "doc": "Oculus Lab 4: Putting It All Together",
    "title": "Check Off",
    "content": "To check off, show a facilitator that the entire game works - that you can operate the gun, that monsters spawn and move towards you, that you can defeat monsters, and that they can defeat you. ",
    "url": "/decal/labs/Oculus/lab4/#check-off",
    "relUrl": "/labs/Oculus/lab4/#check-off"
  },"179": {
    "doc": "AR Foundation Lab 5: Image Tracking, Health Bar",
    "title": "AR Foundation Lab 5: Image Tracking, Health Bar",
    "content": " ",
    "url": "/decal/labs/AR%20Foundation/lab5/",
    "relUrl": "/labs/AR%20Foundation/lab5/"
  },"180": {
    "doc": "AR Foundation Lab 5: Image Tracking, Health Bar",
    "title": "Table of contents",
    "content": ". | Health Bar | Image Tracking | Final Remarks | . In this lab, we’ll focus on image tracking, particularly tracking an object in the physical space so that a virtual object is overlayed on it. We’ll be changing the gun from being static on screen to tracking the gun prefab on the back of a playing card. We will also be adding some more UI elements to the app as well. Extra UI elements to be added: . | Player health bar that reduces when hit. | . ",
    "url": "/decal/labs/AR%20Foundation/lab5/#table-of-contents",
    "relUrl": "/labs/AR%20Foundation/lab5/#table-of-contents"
  },"181": {
    "doc": "AR Foundation Lab 5: Image Tracking, Health Bar",
    "title": "Health Bar",
    "content": "Let’s start off with the health bar. Download this bar here. Add it to the textures folder in Unity, like you did with the image that you tracked in the previous section. Change the Texture Type to Sprite (2D and UI). In the textures folder, the Bar should look like this now: . Create a new UI &gt; Image object in the Canvas and rename it to “Border”. Take the bar sprite and drag it into the Source Image slot, and click Set Native Size to avoid any stretching. Then, create an empty game object in Canvas called “Health Bar” and change its width and height to 52 and 9 respectively, so that it matches the size of the border. This way, we can take our border and set it as a child of Health Bar. We will have the border and the fill of the health bar inside of this Health Bar object. To add the fill of the health bar, we right click on Health Bar &gt; UI &gt; Image and rename it to “Fill”. Make sure that the Fill is above Border so that the fill shows underneath the border. Change the image color to red. In the Rect Transform anchor presets, select the bottom right option while also holding down alt so that it sets the position as well. In the Border do the same thing, but DON’T hold down alt this time; we only want to set the anchors for the border. Now when you scale the Health Bar game object, the fill and the border scale with it. In the Health Bar game object, select the anchor preset, while holding alt, that sets the health bar to the top left. We also scaled the health bar so that it would be bigger. Now that everything is in place, we can implement the health going down! We are going to use a slider component to decrease the fill of the health bar. In the Health Bar game object, add a Slider component. Uncheck Interactable, set Transition to None, set Navigation to None. Drag in the Fill from the Health Bar to the Fill Rect area, and set the Max Value to 100. Try dragging the value slider left and right. You should see the red bar go up and down as you drag it! We are going to write a script to decrease the slider value as the player gets hit. Create a script and import the UnityEngine.UI library. In this script we only need to reference the slider and write a function that sets the slider’s value. public Slider slider; public void SetHealth(int health) { slider.value = health; } . Every time the monster attacks the player, the player loses health; we want that new health to be reflected in the health bar/slider value. We are leaving this implementation as an exercise to the reader. Think about what you need to add to the Attack() function in Monster.cs so that the slider.value matches the player’s health value. You might need to implement a getter function in Player.cs. When this is all implemented, try getting hit by the monsters! The health bar will go down as you get hit. ",
    "url": "/decal/labs/AR%20Foundation/lab5/#health-bar",
    "relUrl": "/labs/AR%20Foundation/lab5/#health-bar"
  },"182": {
    "doc": "AR Foundation Lab 5: Image Tracking, Health Bar",
    "title": "Image Tracking",
    "content": "First off, in the AR Session Origin, add a new component AR Tracked Image Manager. For our tracked image prefab, we want to use the gun, so we need to make the gun into a prefab first. Go to Assets &gt; Prefabs and drag the Gun object from the hierarchy into the project view in the prefabs folder to create a gun prefab. In the hierarchy view, the gun will now have the blue box icon next to it, indicating that it is a prefab. We can delete the Gun game object from the hierarchy now. Drag the Gun prefab into Tracked Image Prefab in the AR Tracked Image Manager component. Now we need to create a reference library for the images we will be tracking. For now, since only the gun will be tracked, we only need one image. For my image, I used the back of a playing card; the more complex the image is, the better it will be for tracking. The gun may be a little wonky though, since tracking a moving image while also moving the camera around makes it hard for the camera to properly track. In your final projects, if you are using image tracking, then it is most consistent with images and objects that are static/non-moving. Take a picture of your card and add it to the assets &gt; textures folder. Now, to create a reference library, we go back to the prefabs folder. Right click in the prefabs folder &gt; Create &gt; XR &gt; Reference Image Library. In the ReferenceImageLibrary, click Add Image and select the card. Specify the size as close as possible to the size of the object in the real world. Back to the AR Session Origin, drag the ReferenceImageLibrary into the Reference Library variable under the AR Tracked Image Manager component. Change the Max Number of Moving Images to 1. Try running the app on your device now. The gun should appear when you bring up the card now! It should look something like this: . One last thing. You may notice now that the button doesn’t work to fire the gun anymore. That’s because the button used to track the GameObject Gun, but now we have a Prefab Gun. Recall in the previous lab that prefabs cannot access or be accessed any gameobjects from a specific scene. This is because prefabs have to work across all scenes, and even across different projects. For that reason, they cannot use anything that’s tied to a single scene. Moreover, the Gun gameobject is now being created at runtime instead of already being in the scene, so the fire button component has no way to access the game object before runtime. There are ways around this, but for simplicity’s sake, we will just be going back to what we did in Lab 2 to fire - just tapping on the screen (even though we just created the fire button UI in the last lab lol). void Update() { if (Input.touchCount &gt; 0) { Touch touch = Input.GetTouch(0); if (touch.phase == TouchPhase.Began) { Fire(); } } } . The gun should be tracked by the card now and fire when you tap on the screen! . This marks the end of lab 5! . ",
    "url": "/decal/labs/AR%20Foundation/lab5/#image-tracking",
    "relUrl": "/labs/AR%20Foundation/lab5/#image-tracking"
  },"183": {
    "doc": "AR Foundation Lab 5: Image Tracking, Health Bar",
    "title": "Final Remarks",
    "content": "Congratulations! You now have a fully implemented game that you’ve created for your device in AR. There are still a ton of things that could be added and improved on, of course, and we encourage you to add stuff in your own time. We hope that this lab series gave you enough knowledge and familiarity with Unity/AR Foundation to kickstart your own final projects. ",
    "url": "/decal/labs/AR%20Foundation/lab5/#final-remarks",
    "relUrl": "/labs/AR%20Foundation/lab5/#final-remarks"
  },"184": {
    "doc": "Project Resources",
    "title": "Project Resources",
    "content": " ",
    "url": "/decal/final-project/project-resources/",
    "relUrl": "/final-project/project-resources/"
  },"185": {
    "doc": "Project Resources",
    "title": "Table of contents",
    "content": ". | Project Workflow . | Version Control | . | Tutorials . | Quick Oculus Project Setup | . | Resources | . This page contains a list of guides, tips, resources, and other helpful things that might be useful for the final project. ",
    "url": "/decal/final-project/project-resources/#table-of-contents",
    "relUrl": "/final-project/project-resources/#table-of-contents"
  },"186": {
    "doc": "Project Resources",
    "title": "Project Workflow",
    "content": ". As you are working in groups, you’ll have to establish some sort of workflow that lets everyone work efficiently. Do not be the group that shares various versions of the project through google drive or usb (trust me, we’ve been there). ",
    "url": "/decal/final-project/project-resources/#project-workflow",
    "relUrl": "/final-project/project-resources/#project-workflow"
  },"187": {
    "doc": "Project Resources",
    "title": "Version Control",
    "content": "Using version control with Unity isn’t exactly the same as using it for a “regular” cs project, since you have to deal with Unity’s binary files and invisible .meta files. But you have a couple options. | Plain old Git (&amp; Github). Unity works well for the most part with regular git procedure (for those unfamiliar with git, here’s a cool tutorial). There are special things you’ll want to keep in mind, described in this article. We’ve listed some of them below: . | Use the Unity .gitignore. This will avoid most unnecessary files (which are generated by your computer while you use a project) from getting pushed onto your repository. Keep in mind that the .gitignore assumes that the repository root is also the project root (the folder that contains the Assets folder) | Have only one person be editing a particular scene at a time. Scene files don’t play nicely with merges. | Watch out for large (&gt;50mb) files. If they get too large you’ll have to setup Git LFS to support the project. | You can use tools like Github Desktop or GitKraken if you don’t like using the command line. | . | Unity Teams/Unity Plastic/Unity Collab/Whatever they’re calling it now . | no don’t use this | . | . ",
    "url": "/decal/final-project/project-resources/#version-control",
    "relUrl": "/final-project/project-resources/#version-control"
  },"188": {
    "doc": "Project Resources",
    "title": "Tutorials",
    "content": "Tutorial Using Unity’s XR Interaction Toolkit . (Below tutorials are only for Oculus headsets and are a little outdated.) . Tutorial Using the Oculus SDK: See the first couple paragraphs of this tutorial to learn how setup a new Oculus Project. ",
    "url": "/decal/final-project/project-resources/#tutorials",
    "relUrl": "/final-project/project-resources/#tutorials"
  },"189": {
    "doc": "Project Resources",
    "title": "Quick Oculus Project Setup",
    "content": ". | Mark project as VR ready. Go to Edit &gt; Project Settings &gt; Player and check the box that enables VR support. | Download Oculus Integration from the Unity Asset Store. This is a comprehensive bundle with all of Oculus’ side add-ons. | Replace the Main Camera with the OVRCameraRig prefab. We recommend using the search bar to find the OVRCameraRig prefab. This prefab represents your VR setup. | Add in the LocalAvatar prefab. This prefab gives support to the first-person control scheme (e.g. Touch controllers). | . Note that the setup process will be different if you use a virtual reality framework like VRTK. ",
    "url": "/decal/final-project/project-resources/#quick-oculus-project-setup",
    "relUrl": "/final-project/project-resources/#quick-oculus-project-setup"
  },"190": {
    "doc": "Project Resources",
    "title": "Resources",
    "content": ". There are a lot of resources out there for you to take advantage of, many of them cheap or free. Don’t feel the need to reinvent the wheel - every hour saved by an SDK or assetpackage is an hour you can spend further prototyping your application. | Oculus Developer Center. The Unity Asset Store package should be sufficient for development purposes, but in the case you need newer versions or specific utilities, you can visit this site to download them. Some things you’ll find there: . | Oculus Utilities is the package you’ll need to start building for Oculus. | Oculus Avatar is used for social presence (hand models and interaction) | Oculus Platform is used for multiplayer applications (room management, voice chat) | Audio packages for ambisonics and 3D sound | Code snippets and demos | . | Unity Asset Store. The asset store is a marketplace for people to buy and sell all sorts of Unity assets: script packages, 3D models, 2D art, music, complete games, etc. There is a ton of content here, and a lot of it can be adapted to serve your needs. The picture above, for instance, was built entirely with store assets. | VRTK. The Virtual Reality Toolkit is a framework that implements a lot of common features in VR applications, including methods of locomotion, object grabbing/throwing, and controller interactions. | NewtonVR. This is also a VR framework, but one that focuses on object interactions and the physics behind it. It does less than VRTK, but because of it can be less restricting to use. | DevAssets. This site holds a lot of professional level 3D models../assets. It follows the old humble bundle approach: you pay what you want (including $0). Great for quick prototyping while still maintaining visual polish. | Photon. This is a multiplayer networking framework that builds on top of Unity’s own networking API (which is also perfectly usable). It supports their Photon Cloud service, which allows you to have up to 20 concurrent users on their dedicated servers, for free. | Poly. Poly is the content distribution platform for Google’s Blocks, a 3D modeling VR application. This is an incredible resource for well-regulated, decent quality, low-poly assets, and a lot of them come under a Creative Commons license! | Unity’s Create with VR Tutorial. There are also instructions here to set up a VR simulator so you don’t have to test things with the VR headset. Instructions are in: 1 - VR Basics -&gt; 1.1 VR Project Setup -&gt; 4 Run the app with the device simulator. | Jacobs Hall headset checkout. You can checkout Oculus Quest 2s for two weeks at a time from Jacob’s Hall. Pickup and drop-off are weekdays 11am-1pm. | . ",
    "url": "/decal/final-project/project-resources/#resources",
    "relUrl": "/final-project/project-resources/#resources"
  },"191": {
    "doc": "Schedule",
    "title": "Weekly Schedule",
    "content": ". | 9:00 AM | 9:30 AM | 10:00 AM | 10:30 AM | 11:00 AM | 11:30 AM | 12:00 PM | 12:30 PM | 1:00 PM | 1:30 PM | 2:00 PM | 2:30 PM | 3:00 PM | 3:30 PM | 4:00 PM | 4:30 PM | 5:00 PM | 5:30 PM | . | ",
    "url": "/decal/schedule/#weekly-schedule",
    "relUrl": "/schedule/#weekly-schedule"
  },"192": {
    "doc": "Schedule",
    "title": "Monday",
    "content": ". | Lecture 9:30 AM–10:30 AM 150 Wheeler | Section 11:30 AM–12:30 PM 310 Soda | Office Hours 12:30 PM–2:00 PM 271 Soda | . | ",
    "url": "/decal/schedule/",
    "relUrl": "/schedule/"
  },"193": {
    "doc": "Schedule",
    "title": "Tuesday",
    "content": "| ",
    "url": "/decal/schedule/",
    "relUrl": "/schedule/"
  },"194": {
    "doc": "Schedule",
    "title": "Wednesday",
    "content": ". | Lecture 9:30 AM–10:30 AM 150 Wheeler | Section 11:30 AM–12:30 PM 310 Soda | Office Hours 12:30 PM–2:00 PM 271 Soda | . | ",
    "url": "/decal/schedule/",
    "relUrl": "/schedule/"
  },"195": {
    "doc": "Schedule",
    "title": "Thursday",
    "content": "| ",
    "url": "/decal/schedule/",
    "relUrl": "/schedule/"
  },"196": {
    "doc": "Schedule",
    "title": "Friday",
    "content": ". | Lecture 9:30 AM–10:30 AM 150 Wheeler | Section 11:30 AM–12:30 PM 310 Soda | Office Hours 12:30 PM–2:00 PM 271 Soda | . | . ",
    "url": "/decal/schedule/",
    "relUrl": "/schedule/"
  },"197": {
    "doc": "Schedule",
    "title": "Schedule",
    "content": " ",
    "url": "/decal/schedule/",
    "relUrl": "/schedule/"
  },"198": {
    "doc": "Staff",
    "title": "Staff",
    "content": "Staff information is stored in the _staffers directory and rendered according to the layout file, _layouts/staffer.html. ",
    "url": "/decal/staff/",
    "relUrl": "/staff/"
  },"199": {
    "doc": "Staff",
    "title": "Instructors",
    "content": " ",
    "url": "/decal/staff/#instructors",
    "relUrl": "/staff/#instructors"
  }
}
